
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Leveraging BERT and a class-based TF-IDF to create easily interpretable topics.">
      
      
        <meta name="author" content="Maarten P. Grootendorst">
      
      
        <link rel="canonical" href="https://maartengr.github.io/BERTopic/getting_started/tips_and_tricks/tips_and_tricks.html">
      
      <link rel="icon" href="../../icon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.9">
    
    
      
        <title>Tips & Tricks - BERTopic</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.120efc48.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.9647289d.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#tips-tricks" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../index.html" title="BERTopic" class="md-header__button md-logo" aria-label="BERTopic" data-md-component="logo">
      
  <img src="../../icon_white.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BERTopic
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Tips & Tricks
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/MaartenGr/BERTopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../index.html" class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../algorithm/algorithm.html" class="md-tabs__link">
      The Algorithm
    </a>
  </li>

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../quickstart/quickstart.html" class="md-tabs__link md-tabs__link--active">
        Getting Started
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../faq.html" class="md-tabs__link">
      FAQ
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../api/bertopic.html" class="md-tabs__link">
        API
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../changelog.html" class="md-tabs__link">
      Changelog
    </a>
  </li>

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../index.html" title="BERTopic" class="md-nav__button md-logo" aria-label="BERTopic" data-md-component="logo">
      
  <img src="../../icon_white.png" alt="logo">

    </a>
    BERTopic
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/MaartenGr/BERTopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../index.html" class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../algorithm/algorithm.html" class="md-nav__link">
        The Algorithm
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Getting Started
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Getting Started" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Getting Started
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../quickstart/quickstart.html" class="md-nav__link">
        Quickstart
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../embeddings/embeddings.html" class="md-nav__link">
        Embedding Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../visualization/visualization.html" class="md-nav__link">
        Topic Visualization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../topicreduction/topicreduction.html" class="md-nav__link">
        Topic Reduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../topicrepresentation/topicrepresentation.html" class="md-nav__link">
        Topic Representation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../search/search.html" class="md-nav__link">
        Search Topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../parameter%20tuning/parametertuning.html" class="md-nav__link">
        Parameter tuning
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Tips & Tricks
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="tips_and_tricks.html" class="md-nav__link md-nav__link--active">
        Tips & Tricks
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#document-length" class="md-nav__link">
    Document length
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#removing-stop-words" class="md-nav__link">
    Removing stop words
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#diversify-topic-representation" class="md-nav__link">
    Diversify topic representation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#topic-term-matrix" class="md-nav__link">
    Topic-term matrix
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-compute-embeddings" class="md-nav__link">
    Pre-compute embeddings
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speed-up-umap" class="md-nav__link">
    Speed up UMAP
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-acceleration" class="md-nav__link">
    GPU acceleration
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finding-similar-topics-between-models" class="md-nav__link">
    Finding similar topics between models
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multi-model-data" class="md-nav__link">
    Multi-model data
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_9" type="checkbox" id="__nav_3_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_9">
          Sub-models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Sub-models" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_9">
          <span class="md-nav__icon md-icon"></span>
          Sub-models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../dim_reduction/dim_reduction.html" class="md-nav__link">
        Dimensionality Reduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../clustering/clustering.html" class="md-nav__link">
        Clustering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../countvectorizer/countvectorizer.html" class="md-nav__link">
        CountVectorizer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_10" type="checkbox" id="__nav_3_10" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_10">
          Variations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Variations" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_10">
          <span class="md-nav__icon md-icon"></span>
          Variations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../topicsperclass/topicsperclass.html" class="md-nav__link">
        Topics per Class
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../supervised/supervised.html" class="md-nav__link">
        (semi)-Supervised Topic Modeling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../topicsovertime/topicsovertime.html" class="md-nav__link">
        Dynamic Topic Modeling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../guided/guided.html" class="md-nav__link">
        Guided Topic Modeling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../hierarchicaltopics/hierarchicaltopics.html" class="md-nav__link">
        Hierarchical Topic Modeling
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../faq.html" class="md-nav__link">
        FAQ
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/bertopic.html" class="md-nav__link">
        BERTopic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/ctfidf.html" class="md-nav__link">
        cTFIDF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/mmr.html" class="md-nav__link">
        MMR
      </a>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_4" type="checkbox" id="__nav_5_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_4">
          Backends
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Backends" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_4">
          <span class="md-nav__icon md-icon"></span>
          Backends
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/backends/base.html" class="md-nav__link">
        Base
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/backends/word_doc.html" class="md-nav__link">
        Word Doc
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_5" type="checkbox" id="__nav_5_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_5">
          Plotting
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Plotting" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_5">
          <span class="md-nav__icon md-icon"></span>
          Plotting
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/barchart.html" class="md-nav__link">
        Barchart
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/documents.html" class="md-nav__link">
        Documents
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/dtm.html" class="md-nav__link">
        DTM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/hierarchical_documents.html" class="md-nav__link">
        Hierarchical documents
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/hierarchy.html" class="md-nav__link">
        Hierarchical topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/distribution.html" class="md-nav__link">
        Distribution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/heatmap.html" class="md-nav__link">
        Heatmap
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/term.html" class="md-nav__link">
        Term Scores
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/topics.html" class="md-nav__link">
        Topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/topics_per_class.html" class="md-nav__link">
        Topics per Class
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../changelog.html" class="md-nav__link">
        Changelog
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#document-length" class="md-nav__link">
    Document length
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#removing-stop-words" class="md-nav__link">
    Removing stop words
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#diversify-topic-representation" class="md-nav__link">
    Diversify topic representation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#topic-term-matrix" class="md-nav__link">
    Topic-term matrix
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-compute-embeddings" class="md-nav__link">
    Pre-compute embeddings
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speed-up-umap" class="md-nav__link">
    Speed up UMAP
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-acceleration" class="md-nav__link">
    GPU acceleration
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finding-similar-topics-between-models" class="md-nav__link">
    Finding similar topics between models
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multi-model-data" class="md-nav__link">
    Multi-model data
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
  <a href="https://github.com/MaartenGr/BERTopic/edit/master/docs/getting_started/tips_and_tricks/tips_and_tricks.md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



<h1 id="tips-tricks">Tips &amp; Tricks<a class="headerlink" href="#tips-tricks" title="Permanent link">&para;</a></h1>
<h2 id="document-length"><strong>Document length</strong><a class="headerlink" href="#document-length" title="Permanent link">&para;</a></h2>
<p>As a default, we are using sentence-transformers to embed our documents. However, as the name implies, the embedding model works best for either sentences or paragraphs. This means that whenever you have a set of documents, where each documents contains several paragraphs, BERTopic will struggle getting accurately extracting a topic from that document. Several paragraphs typically means several topics and BERTopic will assign only one topic to a document. </p>
<p>Therefore, it is advised to split up longer documents into either sentences or paragraphs before embedding them. That way, BERTopic will have a much easier job identifying topics in isolation. </p>
<h2 id="removing-stop-words"><strong>Removing stop words</strong><a class="headerlink" href="#removing-stop-words" title="Permanent link">&para;</a></h2>
<p>At times, stop words might end up in our topic representations. This is something we typically want to avoid as they contribute little to the interpretation of the topics. However, removing stop words as a preprocessing step is not advised as the transformer-based embedding models that we use need the full context in order to create accurate embeddings. </p>
<p>Instead, we can use the <code>CountVectorizer</code> to preprocess our documents <strong>after</strong> having generated embeddings and clustered 
our documents. Personally, I have found almost no disadvantages to using the <code>CountVectorizer</code> to remove stopwords and 
it is something I would strongly advise to try out:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer_model</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">vectorizer_model</span><span class="o">=</span><span class="n">vectorizer_model</span><span class="p">)</span>
</code></pre></div>
<h2 id="diversify-topic-representation"><strong>Diversify topic representation</strong><a class="headerlink" href="#diversify-topic-representation" title="Permanent link">&para;</a></h2>
<p>After having calculated our top <em>n</em> words per topic there might be many words that essentially 
mean the same thing. As a little bonus, we can use the <code>diversity</code> parameter in BERTopic to 
diversity words in each topic such that we limit the number of duplicate words we find in each topic. 
This is done using an algorithm called Maximal Marginal Relevance which compares word embeddings 
with the topic embedding. </p>
<p>We do this by specifying a value between 0 and 1, with 0 being not at all diverse and 1 being completely diverse:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">diversity</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div>
<p>Since MMR is using word embeddings to diversify the topic representations, it is necessary to pass the embedding model to BERTopic if you are using pre-computed embeddings:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">sentence_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">embedding_model</span><span class="o">=</span><span class="n">sentence_model</span><span class="p">,</span> <span class="n">diversity</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div>
<h2 id="topic-term-matrix"><strong>Topic-term matrix</strong><a class="headerlink" href="#topic-term-matrix" title="Permanent link">&para;</a></h2>
<p>Although BERTopic focuses on clustering our documents, the end result does contain a topic-term matrix. 
This topic-term matrix is calculated using c-TF-IDF, a TF-IDF procedure optimized for class-based analyses. </p>
<p>To extract the topic-term matrix (or c-TF-IDF matrix) with the corresponding words, we can simply do the following:</p>
<div class="highlight"><pre><span></span><code><span class="n">topic_term_matrix</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">c_tf_idf</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">vectorizer_model</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This only works if you have set <code>diversity=None</code>, for all other values the top <em>n</em> are 
further optimized using MMR which is not represented in the topic-term matrix as it does 
not optimize the entire matrix. </p>
</div>
<h2 id="pre-compute-embeddings"><strong>Pre-compute embeddings</strong><a class="headerlink" href="#pre-compute-embeddings" title="Permanent link">&para;</a></h2>
<p>Typically, we want to iterate fast over different versions of our BERTopic model whilst we are trying to optimize it to a specific use case. To speed up this process, we can pre-compute the embeddings, save them, 
and pass them to BERTopic so it does not need to calculate the embeddings each time: </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="c1"># Prepare embeddings</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span>  <span class="n">remove</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;headers&#39;</span><span class="p">,</span> <span class="s1">&#39;footers&#39;</span><span class="p">,</span> <span class="s1">&#39;quotes&#39;</span><span class="p">))[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">sentence_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Train our topic model using our pre-trained sentence-transformers embeddings</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">()</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<h2 id="speed-up-umap"><strong>Speed up UMAP</strong><a class="headerlink" href="#speed-up-umap" title="Permanent link">&para;</a></h2>
<p>At times, UMAP may take a while to fit on the embeddings that you have. This often happens when you have
the embeddings millions of documents that you want to reduce in dimensionality. There is a trick that 
can speed up this process somewhat: Initializing UMAP with rescaled PCA embeddings. </p>
<p>Without going in too much detail (look <a href="https://github.com/lmcinnes/umap/issues/771#issuecomment-931886015">here</a> for more information), you can reduce the embeddings using PCA 
and use that as a starting point. This can speed up the dimensionality reduction a bit: </p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">umap</span> <span class="kn">import</span> <span class="n">UMAP</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>


<span class="k">def</span> <span class="nf">rescale</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Rescale an embedding so optimization will not have convergence issues.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">inplace</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mi">10000</span>

    <span class="k">return</span> <span class="n">x</span>


<span class="c1"># Initialize and rescale PCA embeddings</span>
<span class="n">pca_embeddings</span> <span class="o">=</span> <span class="n">rescale</span><span class="p">(</span><span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embeddings</span><span class="p">))</span>

<span class="c1"># Start UMAP from PCA embeddings</span>
<span class="n">umap_model</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span>
    <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
    <span class="n">init</span><span class="o">=</span><span class="n">pca_embeddings</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Pass the model to BERTopic:</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">umap_model</span><span class="o">=</span><span class="n">umap_model</span><span class="p">)</span>
</code></pre></div>
<h2 id="gpu-acceleration"><strong>GPU acceleration</strong><a class="headerlink" href="#gpu-acceleration" title="Permanent link">&para;</a></h2>
<p>You can use <a href="https://rapids.ai/start.html#rapids-release-selector">cuML</a> to speed up both 
UMAP and HDBSCAN through GPU acceleration:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">cuml.cluster</span> <span class="kn">import</span> <span class="n">HDBSCAN</span>
<span class="kn">from</span> <span class="nn">cuml.manifold</span> <span class="kn">import</span> <span class="n">UMAP</span>

<span class="c1"># Create instances of GPU-accelerated UMAP and HDBSCAN</span>
<span class="n">umap_model</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">hdbscan_model</span> <span class="o">=</span> <span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gen_min_span_tree</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Pass the above models to be used in BERTopic</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">umap_model</span><span class="o">=</span><span class="n">umap_model</span><span class="p">,</span> <span class="n">hdbscan_model</span><span class="o">=</span><span class="n">hdbscan_model</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div>
<p>Depending on the embeddings you are using, you might want to normalize them first in order to 
force a cosine-related distance metric in UMAP:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">cuml.preprocessing</span> <span class="kn">import</span> <span class="n">normalize</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<h2 id="finding-similar-topics-between-models"><strong>Finding similar topics between models</strong><a class="headerlink" href="#finding-similar-topics-between-models" title="Permanent link">&para;</a></h2>
<p>Whenever you have trained seperate BERTopic models on different datasets, it might 
be worthful to find the similarities among these models. Is there overlap between 
topics in model A and topic in model B? In other words, can we find topics in model A that are similar to those in model B? </p>
<p>We can compare the topic representations of several models in two ways. First, by comparing the topic embeddings that are created when using the same embedding model across both fitted BERTopic instances. Second, we can compare the c-TF-IDF representations instead assuming we have fixed the vocabulary in both instances. </p>
<p>This example will go into the former, using the same embedding model across two BERTopic instances. To do this comparison, let's first create an example where I trained two models, one on an English dataset and one on a Dutch dataset:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">umap</span> <span class="kn">import</span> <span class="n">UMAP</span>

<span class="c1"># The same embedding model needs to be used for both topic models</span>
<span class="c1"># and since we are dealing with multiple languages, the model needs to be multi-lingual</span>
<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;paraphrase-multilingual-MiniLM-L12-v2&quot;</span><span class="p">)</span>

<span class="c1"># To make this example reproducible</span>
<span class="n">umap_model</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                  <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># English</span>
<span class="n">en_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;stsb_multi_mt&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span><span class="o">.</span><span class="n">sentence1</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">en_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">embedding_model</span><span class="o">=</span><span class="n">sentence_model</span><span class="p">,</span> <span class="n">umap_model</span><span class="o">=</span><span class="n">umap_model</span><span class="p">)</span>
<span class="n">en_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">en_dataset</span><span class="p">)</span>

<span class="c1"># Dutch</span>
<span class="n">nl_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;stsb_multi_mt&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;nl&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span><span class="o">.</span><span class="n">sentence1</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">nl_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">embedding_model</span><span class="o">=</span><span class="n">sentence_model</span><span class="p">,</span> <span class="n">umap_model</span><span class="o">=</span><span class="n">umap_model</span><span class="p">)</span>
<span class="n">nl_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">nl_dataset</span><span class="p">)</span>
</code></pre></div>
<p>In the code above, there is one important thing to note and that is the <code>sentence_model</code>. This model needs to be exactly the same in all BERTopic models, otherwise, it is not possible to compare topic models. </p>
<p>Next, we can calculate the similarity between topics in the English topic model <code>en_model</code> and the Dutch model <code>nl_model</code>. To do so, we can simply calculate the cosine similarity between the <code>topic_embedding</code> of both models: </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="n">sim_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">en_model</span><span class="o">.</span><span class="n">topic_embeddings</span><span class="p">,</span> <span class="n">nl_model</span><span class="o">.</span><span class="n">topic_embeddings</span><span class="p">)</span>
</code></pre></div>
<p>Now that we know which topics are similar to each other, we can extract the most similar topics. Let's say that we have topic 10 in the <code>en_model</code> which represents a topic related to trains:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">topic</span> <span class="o">=</span> <span class="mi">10</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">en_model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>
<span class="p">[(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="mf">0.2588080580844999</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;tracks&#39;</span><span class="p">,</span> <span class="mf">0.1392140438801078</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;station&#39;</span><span class="p">,</span> <span class="mf">0.12126454635946024</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;passenger&#39;</span><span class="p">,</span> <span class="mf">0.058057876475695866</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;engine&#39;</span><span class="p">,</span> <span class="mf">0.05123717127783682</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;railroad&#39;</span><span class="p">,</span> <span class="mf">0.048142847325312044</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;waiting&#39;</span><span class="p">,</span> <span class="mf">0.04098973702226946</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;track&#39;</span><span class="p">,</span> <span class="mf">0.03978248702913929</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;subway&#39;</span><span class="p">,</span> <span class="mf">0.03834661195748458</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;steam&#39;</span><span class="p">,</span> <span class="mf">0.03834661195748458</span><span class="p">)]</span>
</code></pre></div>
<p>To find the matching topic, we extract the most similar topic in the <code>sim_matrix</code>:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">most_similar_topic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">sim_matrix</span><span class="p">[</span><span class="n">topic</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nl_model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="n">most_similar_topic</span><span class="p">)</span>
<span class="p">[(</span><span class="s1">&#39;trein&#39;</span><span class="p">,</span> <span class="mf">0.24186603209316418</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;spoor&#39;</span><span class="p">,</span> <span class="mf">0.1338118418551581</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;sporen&#39;</span><span class="p">,</span> <span class="mf">0.07683661859111401</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;station&#39;</span><span class="p">,</span> <span class="mf">0.056990389779394225</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;stoommachine&#39;</span><span class="p">,</span> <span class="mf">0.04905829711711234</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;zilveren&#39;</span><span class="p">,</span> <span class="mf">0.04083879598477808</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;treinen&#39;</span><span class="p">,</span> <span class="mf">0.03534099197032758</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;treinsporen&#39;</span><span class="p">,</span> <span class="mf">0.03534099197032758</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;staat&#39;</span><span class="p">,</span> <span class="mf">0.03481332997324445</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;zwarte&#39;</span><span class="p">,</span> <span class="mf">0.03179591746822408</span><span class="p">)]</span>
</code></pre></div>
<p>It seems to be working as, for example, <code>trein</code> is a translation of <code>train</code> and <code>sporen</code> a translation of <code>tracks</code>! You can do this for every single topic to find out which topic in the <code>en_model</code> might belong to a model in the <code>nl_model</code>. </p>
<h2 id="multi-model-data"><strong>Multi-model data</strong><a class="headerlink" href="#multi-model-data" title="Permanent link">&para;</a></h2>
<p><a href="https://github.com/MaartenGr/Concept">Concept</a> is a variation 
of BERTopic for multi-modal data, such as images with captions. Although we can use that 
package for multi-modal data, we can perform a small trick with BERTopic to have a similar feature. </p>
<p>BERTopic is a relatively modular approach that attempts to isolate steps from one another. This means, 
for example, that you can use k-Means instead of HDBSCAN or PCA instead of UMAP as it does not make 
any assumptions with respect to the nature of the clustering. </p>
<p>Similarly, you can pass pre-calculated embeddings to BERTopic that represent the documents that you have. 
However, it does not make any assumption with respect to the relationship between those embeddings and 
the documents. This means that we could pass any metadata to BERTopic to cluster on instead of document 
embeddings. In this example, we can separate our embeddings from our documents so that the embeddings 
are generated from images instead of their corresponding images. Thus, we will cluster image embeddings but 
create the topic representation from the related captions. </p>
<p>In this example, we first need to fetch our data, namely the Flickr 8k dataset that contains images 
with captions:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span><span class="p">,</span> <span class="n">util</span>

<span class="c1"># Flickr 8k images</span>
<span class="n">img_folder</span> <span class="o">=</span> <span class="s1">&#39;photos/&#39;</span>
<span class="n">caps_folder</span> <span class="o">=</span> <span class="s1">&#39;captions/&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">img_folder</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">img_folder</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">img_folder</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;Flickr8k_Dataset.zip&#39;</span><span class="p">):</span>   <span class="c1">#Download dataset if does not exist</span>
        <span class="n">util</span><span class="o">.</span><span class="n">http_get</span><span class="p">(</span><span class="s1">&#39;https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip&#39;</span><span class="p">,</span> <span class="s1">&#39;Flickr8k_Dataset.zip&#39;</span><span class="p">)</span>
        <span class="n">util</span><span class="o">.</span><span class="n">http_get</span><span class="p">(</span><span class="s1">&#39;https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip&#39;</span><span class="p">,</span> <span class="s1">&#39;Flickr8k_text.zip&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">folder</span><span class="p">,</span> <span class="n">file</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">img_folder</span><span class="p">,</span> <span class="s1">&#39;Flickr8k_Dataset.zip&#39;</span><span class="p">),</span> <span class="p">(</span><span class="n">caps_folder</span><span class="p">,</span> <span class="s1">&#39;Flickr8k_text.zip&#39;</span><span class="p">)]:</span>
        <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zf</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">member</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">zf</span><span class="o">.</span><span class="n">infolist</span><span class="p">(),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Extracting&#39;</span><span class="p">):</span>
                <span class="n">zf</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">member</span><span class="p">,</span> <span class="n">folder</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;photos/Flicker8k_Dataset/*.jpg&#39;</span><span class="p">))</span>

<span class="c1"># Prepare dataframe</span>
<span class="n">captions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;captions/Flickr8k.lemma.token.txt&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;img_id&quot;</span><span class="p">,</span><span class="s2">&quot;img_caption&quot;</span><span class="p">])</span>
<span class="n">captions</span><span class="o">.</span><span class="n">img_id</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="s2">&quot;photos/Flicker8k_Dataset/&quot;</span> <span class="o">+</span> <span class="n">row</span><span class="o">.</span><span class="n">img_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.jpg&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.jpg&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">captions</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;img_id&quot;</span><span class="p">])[</span><span class="s2">&quot;img_caption&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">captions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">captions</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;img_id&quot;</span><span class="p">),</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;img_id&quot;</span><span class="p">)</span>

<span class="c1"># Extract images together with their documents/captions</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">img_id</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">img_caption</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
</code></pre></div>
<p>Now that we have our images and captions, we need to generate our image embeddings:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;clip-ViT-B-32&#39;</span><span class="p">)</span>

<span class="c1"># Prepare images</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">nr_iterations</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>

<span class="c1"># Embed images per batch</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nr_iterations</span><span class="p">)):</span>
    <span class="n">start_index</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span>
    <span class="n">end_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">batch_size</span>

    <span class="n">images_to_embed</span> <span class="o">=</span> <span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span> <span class="k">for</span> <span class="n">filepath</span> <span class="ow">in</span> <span class="n">images</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="n">end_index</span><span class="p">]]</span>
    <span class="n">img_emb</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">images_to_embed</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">embeddings</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">img_emb</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

    <span class="c1"># Close images</span>
    <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images_to_embed</span><span class="p">:</span>
        <span class="n">image</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<p>Finally, we can fit BERTopic the way we are used to, with documents and embeddings:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer_model</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">vectorizer_model</span><span class="o">=</span><span class="n">vectorizer_model</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
<span class="n">captions</span><span class="p">[</span><span class="s2">&quot;Topic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">topics</span>
</code></pre></div>
<p>After fitting our model, let's inspect a topic about skateboarders:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="p">[(</span><span class="s1">&#39;skateboard&#39;</span><span class="p">,</span> <span class="mf">0.09592033177340711</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;skateboarder&#39;</span><span class="p">,</span> <span class="mf">0.07792520092546491</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;trick&#39;</span><span class="p">,</span> <span class="mf">0.07481578896400298</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;ramp&#39;</span><span class="p">,</span> <span class="mf">0.056952605147927216</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;skate&#39;</span><span class="p">,</span> <span class="mf">0.03745127816149923</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;perform&#39;</span><span class="p">,</span> <span class="mf">0.036546213623432654</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;bicycle&#39;</span><span class="p">,</span> <span class="mf">0.03453483070441857</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;bike&#39;</span><span class="p">,</span> <span class="mf">0.033233021253898994</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;jump&#39;</span><span class="p">,</span> <span class="mf">0.026709362981948037</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;air&#39;</span><span class="p">,</span> <span class="mf">0.025422798170830936</span><span class="p">)]</span>
</code></pre></div>
<p>Based on the above output, we can take an image to see if the representation makes sense:</p>
<div class="highlight"><pre><span></span><code><span class="n">image</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">captions</span><span class="o">.</span><span class="n">Topic</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;img_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<p><img alt="" src="skateboarders.jpg" /></p>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../parameter%20tuning/parametertuning.html" class="md-footer__link md-footer__link--prev" aria-label="Previous: Parameter tuning" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Parameter tuning
            </div>
          </div>
        </a>
      
      
        
        <a href="../dim_reduction/dim_reduction.html" class="md-footer__link md-footer__link--next" aria-label="Next: Dimensionality Reduction" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Dimensionality Reduction
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2021 Maintained by <a href="https://github.com/MaartenGr">Maarten</a>.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.instant", "navigation.top", "navigation.tracking", "toc.follow"], "search": "../../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.6e54b5cd.min.js"></script>
      
    
  </body>
</html>