
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Leveraging BERT and a class-based TF-IDF to create easily interpretable topics.">
      
      
        <meta name="author" content="Maarten P. Grootendorst">
      
      
        <link rel="canonical" href="https://maartengr.github.io/BERTopic/faq.html">
      
      <link rel="icon" href="icon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.9">
    
    
      
        <title>FAQ - BERTopic</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.120efc48.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.9647289d.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="stylesheets/extra.css">
    
    <script>__md_scope=new URL(".",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#why-are-the-results-not-consistent-between-runs" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="BERTopic" class="md-header__button md-logo" aria-label="BERTopic" data-md-component="logo">
      
  <img src="icon_white.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BERTopic
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              FAQ
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/MaartenGr/BERTopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="index.html" class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="algorithm/algorithm.html" class="md-tabs__link">
      The Algorithm
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="getting_started/quickstart/quickstart.html" class="md-tabs__link">
        Getting Started
      </a>
    </li>
  

      
        
  
  
    
  


  <li class="md-tabs__item">
    <a href="faq.html" class="md-tabs__link md-tabs__link--active">
      FAQ
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="api/bertopic.html" class="md-tabs__link">
        API
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="changelog.html" class="md-tabs__link">
      Changelog
    </a>
  </li>

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="BERTopic" class="md-nav__button md-logo" aria-label="BERTopic" data-md-component="logo">
      
  <img src="icon_white.png" alt="logo">

    </a>
    BERTopic
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/MaartenGr/BERTopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="algorithm/algorithm.html" class="md-nav__link">
        The Algorithm
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Getting Started
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Getting Started" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Getting Started
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/quickstart/quickstart.html" class="md-nav__link">
        Quickstart
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/embeddings/embeddings.html" class="md-nav__link">
        Embedding Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/visualization/visualization.html" class="md-nav__link">
        Topic Visualization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/topicreduction/topicreduction.html" class="md-nav__link">
        Topic Reduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/topicrepresentation/topicrepresentation.html" class="md-nav__link">
        Topic Representation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/search/search.html" class="md-nav__link">
        Search Topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/parameter%20tuning/parametertuning.html" class="md-nav__link">
        Parameter tuning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/tips_and_tricks/tips_and_tricks.html" class="md-nav__link">
        Tips & Tricks
      </a>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_9" type="checkbox" id="__nav_3_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_9">
          Sub-models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Sub-models" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_9">
          <span class="md-nav__icon md-icon"></span>
          Sub-models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/dim_reduction/dim_reduction.html" class="md-nav__link">
        Dimensionality Reduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/clustering/clustering.html" class="md-nav__link">
        Clustering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/countvectorizer/countvectorizer.html" class="md-nav__link">
        CountVectorizer
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_10" type="checkbox" id="__nav_3_10" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_10">
          Variations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Variations" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_10">
          <span class="md-nav__icon md-icon"></span>
          Variations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/topicsperclass/topicsperclass.html" class="md-nav__link">
        Topics per Class
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/supervised/supervised.html" class="md-nav__link">
        (semi)-Supervised Topic Modeling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/topicsovertime/topicsovertime.html" class="md-nav__link">
        Dynamic Topic Modeling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="getting_started/guided/guided.html" class="md-nav__link">
        Guided Topic Modeling
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          FAQ
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="faq.html" class="md-nav__link md-nav__link--active">
        FAQ
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#why-are-the-results-not-consistent-between-runs" class="md-nav__link">
    Why are the results not consistent between runs?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#which-embedding-model-should-i-choose" class="md-nav__link">
    Which embedding model should I choose?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-do-i-reduce-topic-outliers" class="md-nav__link">
    How do I reduce topic outliers?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-can-i-speed-up-bertopic" class="md-nav__link">
    How can I speed up BERTopic?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#i-am-facing-memory-issues-help" class="md-nav__link">
    I am facing memory issues. Help!
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#i-have-only-a-few-topics-how-do-i-increase-them" class="md-nav__link">
    I have only a few topics, how do I increase them?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#i-have-too-many-topics-how-do-i-decrease-them" class="md-nav__link">
    I have too many topics, how do I decrease them?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-do-i-calculate-the-probabilities-of-all-topics-in-a-document" class="md-nav__link">
    How do I calculate the probabilities of all topics in a document?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#numpy-gives-me-an-error-when-running-bertopic" class="md-nav__link">
    Numpy gives me an error when running BERTopic
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-can-i-run-bertopic-without-an-internet-connection" class="md-nav__link">
    How can I run BERTopic without an internet connection?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#can-i-use-the-gpu-to-speed-up-the-model" class="md-nav__link">
    Can I use the GPU to speed up the model?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-can-i-use-bertopic-with-chinese-documents" class="md-nav__link">
    How can I use BERTopic with Chinese documents?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-does-it-take-so-long-to-import-bertopic" class="md-nav__link">
    Why does it take so long to import BERTopic?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#should-i-preprocess-the-data" class="md-nav__link">
    Should I preprocess the data?
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/bertopic.html" class="md-nav__link">
        BERTopic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/ctfidf.html" class="md-nav__link">
        cTFIDF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/mmr.html" class="md-nav__link">
        MMR
      </a>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_4" type="checkbox" id="__nav_5_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_4">
          Backends
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Backends" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_4">
          <span class="md-nav__icon md-icon"></span>
          Backends
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/backends/base.html" class="md-nav__link">
        Base
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/backends/word_doc.html" class="md-nav__link">
        Word Doc
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_5" type="checkbox" id="__nav_5_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_5">
          Plotting
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Plotting" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_5">
          <span class="md-nav__icon md-icon"></span>
          Plotting
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/plotting/barchart.html" class="md-nav__link">
        Barchart
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/plotting/distribution.html" class="md-nav__link">
        Distribution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/plotting/heatmap.html" class="md-nav__link">
        Heatmap
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/plotting/hierarchy.html" class="md-nav__link">
        Hierarchy
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/plotting/term.html" class="md-nav__link">
        Term Scores
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/plotting/topics.html" class="md-nav__link">
        Topics
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/plotting/dtm.html" class="md-nav__link">
        DTM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="api/plotting/topics_per_class.html" class="md-nav__link">
        Topics per Class
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="changelog.html" class="md-nav__link">
        Changelog
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#why-are-the-results-not-consistent-between-runs" class="md-nav__link">
    Why are the results not consistent between runs?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#which-embedding-model-should-i-choose" class="md-nav__link">
    Which embedding model should I choose?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-do-i-reduce-topic-outliers" class="md-nav__link">
    How do I reduce topic outliers?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-can-i-speed-up-bertopic" class="md-nav__link">
    How can I speed up BERTopic?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#i-am-facing-memory-issues-help" class="md-nav__link">
    I am facing memory issues. Help!
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#i-have-only-a-few-topics-how-do-i-increase-them" class="md-nav__link">
    I have only a few topics, how do I increase them?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#i-have-too-many-topics-how-do-i-decrease-them" class="md-nav__link">
    I have too many topics, how do I decrease them?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-do-i-calculate-the-probabilities-of-all-topics-in-a-document" class="md-nav__link">
    How do I calculate the probabilities of all topics in a document?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#numpy-gives-me-an-error-when-running-bertopic" class="md-nav__link">
    Numpy gives me an error when running BERTopic
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-can-i-run-bertopic-without-an-internet-connection" class="md-nav__link">
    How can I run BERTopic without an internet connection?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#can-i-use-the-gpu-to-speed-up-the-model" class="md-nav__link">
    Can I use the GPU to speed up the model?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-can-i-use-bertopic-with-chinese-documents" class="md-nav__link">
    How can I use BERTopic with Chinese documents?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#why-does-it-take-so-long-to-import-bertopic" class="md-nav__link">
    Why does it take so long to import BERTopic?
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#should-i-preprocess-the-data" class="md-nav__link">
    Should I preprocess the data?
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
  <a href="https://github.com/MaartenGr/BERTopic/edit/master/docs/faq.md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



  <h1>FAQ</h1>

<h2 id="why-are-the-results-not-consistent-between-runs"><strong>Why are the results not consistent between runs?</strong><a class="headerlink" href="#why-are-the-results-not-consistent-between-runs" title="Permanent link">&para;</a></h2>
<p>Due to the stochastic nature of UMAP, the results from BERTopic might differ even if you run the same code
multiple times. Using custom embeddings allows you to try out BERTopic several times until you find the 
topics that suit you best. You only need to generate the embeddings itself once and run BERTopic several times
with different parameters. </p>
<p>If you want to reproduce the results, at the expense of <a href="https://umap-learn.readthedocs.io/en/latest/reproducibility.html">performance</a>, you can set a <code>random_state</code> in UMAP to prevent 
any stochastic behavior:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">umap</span> <span class="kn">import</span> <span class="n">UMAP</span>

<span class="n">umap_model</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                  <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">umap_model</span><span class="o">=</span><span class="n">umap_model</span><span class="p">)</span>
</code></pre></div>
<h2 id="which-embedding-model-should-i-choose"><strong>Which embedding model should I choose?</strong><a class="headerlink" href="#which-embedding-model-should-i-choose" title="Permanent link">&para;</a></h2>
<p>Unfortunately, there is not a definitive list of the best models for each language, this highly depends 
on your data, the model, and your specific use-case. However, the default model in BERTopic 
(<code>"all-MiniLM-L6-v2"</code>) works great for <strong>English</strong> documents. In contrast, for <strong>multi-lingual</strong> 
documents or any other language, <code>"paraphrase-multilingual-MiniLM-L12-v2""</code> has shown great performance.  </p>
<p>If you want to use a model that provides a higher quality, but takes more compute time, then I would advise using <code>all-mpnet-base-v2</code> and <code>paraphrase-multilingual-mpnet-base-v2</code> instead. </p>
<p><strong>SentenceTransformers</strong><br />
<a href="https://www.sbert.net/docs/pretrained_models.html#sentence-embedding-models">SentenceTransformers</a> work typically quite well 
and are the preferred models to use. They are great at generating document embeddings and have several 
multi-lingual versions available.  </p>
<p><strong>ðŸ¤— transformers</strong><br />
BERTopic allows you to use any ðŸ¤— transformers model. These models  are typically embeddings created on 
a word/sentence level but can easily be pooled using Flair (see Guides/Embeddings). If you have a 
specific language for which you want to generate embeddings, you can choose the model <a href="https://huggingface.co/models">here</a>.</p>
<h2 id="how-do-i-reduce-topic-outliers"><strong>How do I reduce topic outliers?</strong><a class="headerlink" href="#how-do-i-reduce-topic-outliers" title="Permanent link">&para;</a></h2>
<p>There are two ways in reducing outliers. </p>
<p>First, the amount of datapoint classified as outliers is handled by the <code>min_samples</code> parameters in HDBSCAN. This value is automatically set to the 
same value of <code>min_cluster_size</code>. However, you can set it indepedently if you want to reduce the number of generated outliers. Lowering this value will 
result in less noise being generated. </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">hdbscan</span> <span class="kn">import</span> <span class="n">HDBSCAN</span>

<span class="n">hdbscan_model</span> <span class="o">=</span> <span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_cluster_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">,</span> 
                        <span class="n">cluster_selection_method</span><span class="o">=</span><span class="s1">&#39;eom&#39;</span><span class="p">,</span> <span class="n">prediction_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">hdbscan_model</span><span class="o">=</span><span class="n">hdbscan_model</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although this will lower outliers found in the data, this might force outliers to be put into topics where they do not belong. So make 
sure to strike a balance between keeping noise and reducing outliers. </p>
</div>
<p>Second, after training our BERTopic model, we can assign outliers to topics. By setting <code>calculate_probabilities=True</code>, we calculate the probability 
of a document belonging to any topic. That way, we can select, for each document, the topic with the the highest probability. Thus, although we do 
generate an outlier class in our BERTopic model, we can assign documents to an actual topic. </p>
<p>To do this, we can set a probability threshold and assign each document to a topic based on their probabilities:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">probability_threshold</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">new_topics</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span> <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">prob</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">probability_threshold</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span> <span class="k">for</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">probs</span><span class="p">]</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The topics assigned using the above method can result in topics different from using <code>.fit_transform()</code>. This is expected
behavior as HDBSCAN is merely trying to imitate soft clustering after fitting the model and it is not a core component
of assigning points to clusters. </p>
</div>
<h2 id="how-can-i-speed-up-bertopic"><strong>How can I speed up BERTopic?</strong><a class="headerlink" href="#how-can-i-speed-up-bertopic" title="Permanent link">&para;</a></h2>
<p>You can speed up BERTopic by either generating your embeddings beforehand or by 
setting <code>calculate_probabilities</code> to False. Calculating the probabilities is quite expensive and can 
significantly increase the computation time. Thus, only use it if you do not mind waiting a bit before 
the model is done running or if you have less than 50_000 documents. </p>
<p>Also, make sure to use a GPU when extracting the sentence/document embeddings. Transformer models 
typically require a GPU and using only a CPU can slow down computation time quite a lot. 
However, if you do not have access to a GPU, looking into quantization might help. </p>
<h2 id="i-am-facing-memory-issues-help"><strong>I am facing memory issues. Help!</strong><a class="headerlink" href="#i-am-facing-memory-issues-help" title="Permanent link">&para;</a></h2>
<p>There are several ways to perform computation with large datasets. 
First, you can set <code>low_memory</code> to True when instantiating BERTopic. 
This may prevent blowing up the memory in UMAP. </p>
<p>Second, setting <code>calculate_probabilities</code> to False when instantiating BERTopic prevents a huge document-topic 
probability matrix from being created. Moreover, HDBSCAN is quite slow when it tries to calculate probabilities on large datasets. </p>
<p>Third, you can set the minimum frequency of words in the CountVectorizer class to reduce the size of the resulting 
sparse c-TF-IDF matrix. You can do this as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer_model</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stop_words</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">vectorizer_model</span><span class="o">=</span><span class="n">vectorizer_model</span><span class="p">)</span>
</code></pre></div>
<p>The <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html">min_df</a> 
parameter is used to indicate the minimum frequency of words. Setting this value larger than 1 can significantly reduce memory.</p>
<p>If the problem persists, then this could be an issue related to your available memory. The processing of 
millions of documents is quite computationally expensive and sufficient RAM is necessary.  </p>
<h2 id="i-have-only-a-few-topics-how-do-i-increase-them"><strong>I have only a few topics, how do I increase them?</strong><a class="headerlink" href="#i-have-only-a-few-topics-how-do-i-increase-them" title="Permanent link">&para;</a></h2>
<p>There are several reasons why your topic model may result in only a few topics:</p>
<ul>
<li>
<p>First, you might only have a few documents (~1000). This makes it very difficult to properly 
extract topics due to the little amount of data available. Increasing the number of documents 
might solve your issues. </p>
</li>
<li>
<p>Second, <code>min_topic_size</code> might be simply too large for your number of documents. If you decrease 
the minimum size of topics, then you are much more likely to increase the number of topics generated.
You could also decrease the <code>n_neighbors</code> parameter used in <code>UMAP</code> if this does not work. </p>
</li>
<li>
<p>Third, although this does not happen very often, there simply aren't that many topics to be found 
in your documents. You can often see this when you have many <code>-1</code> topics, which is actually not a topic 
but a category of outliers.  </p>
</li>
</ul>
<h2 id="i-have-too-many-topics-how-do-i-decrease-them"><strong>I have too many topics, how do I decrease them?</strong><a class="headerlink" href="#i-have-too-many-topics-how-do-i-decrease-them" title="Permanent link">&para;</a></h2>
<p>If you have a large dataset, then it is possible to generate thousands of topics. Especially with large 
datasets, there is a good chance they actually contain many small topics. In practice, you might want 
a few hundred topics at most in order to interpret them nicely. </p>
<p>There are a few ways of increasing the number of generated topics: </p>
<ul>
<li>
<p>First, we can set the <code>min_topic_size</code> in the BERTopic initialization much higher (e.g., 300) 
to make sure that those small clusters will not be generated. This is a HDBSCAN parameter that 
specifies what the minimum number of documents are needed in a cluster. More documents in a cluster 
means less topics will be generated. </p>
</li>
<li>
<p>Second, you can create a custom UMAP model and set <code>n_neighbors</code> much higher than the default 15 (e.g., 200). 
This also prevents those micro clusters to be generated as it will needs quite a number of neighboring 
documents to create a cluster. </p>
</li>
<li>
<p>Third, we can set <code>nr_topics</code> to a value that seems logical to the user. Do note that topics are forced 
to merge together which might result in a lower quality of topics. In practice, I would advise using 
<code>nr_topic="auto"</code> as that will merge topics together that are very similar. Dissimilar topics will 
therefore remain separated. </p>
</li>
</ul>
<h2 id="how-do-i-calculate-the-probabilities-of-all-topics-in-a-document"><strong>How do I calculate the probabilities of all topics in a document?</strong><a class="headerlink" href="#how-do-i-calculate-the-probabilities-of-all-topics-in-a-document" title="Permanent link">&para;</a></h2>
<p>Although it is possible to calculate all the probabilities, the process of doing so is quite computationally 
inefficient and might significantly increase the computation time. To prevent this, the probabilities are 
not calculated as a default. In order to calculate, you will have to set <code>calculate_probabilities</code> to True:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">calculate_probabilities</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span> 
</code></pre></div>
<h2 id="numpy-gives-me-an-error-when-running-bertopic"><strong>Numpy gives me an error when running BERTopic</strong><a class="headerlink" href="#numpy-gives-me-an-error-when-running-bertopic" title="Permanent link">&para;</a></h2>
<p>With the release of Numpy 1.20.0, there have been significant issues with using that version (and previous) due 
to compilation issues and pypi.   </p>
<p>This is a known issue with the order of install using pypi. You can find more details about this issue 
<a href="https://github.com/lmcinnes/umap/issues/567">here</a> and <a href="https://github.com/scikit-learn-contrib/hdbscan/issues/457">here</a>.</p>
<p>I would suggest doing one of the following:</p>
<ul>
<li>Install the newest version from BERTopic (&gt;= v0.5).</li>
<li>You can install hdbscan with <code>pip install hdbscan --no-cache-dir --no-binary :all: --no-build-isolation</code> which might resolve the issue</li>
<li>Install BERTopic in a fresh environment using these steps. </li>
</ul>
<h2 id="how-can-i-run-bertopic-without-an-internet-connection"><strong>How can I run BERTopic without an internet connection?</strong><a class="headerlink" href="#how-can-i-run-bertopic-without-an-internet-connection" title="Permanent link">&para;</a></h2>
<p>The great thing about using sentence-transformers is that it searches automatically for an embedding model locally. 
If it cannot find one, it will download the pre-trained model from its servers. 
Make sure that you set the correct path for sentence-transformers to work. You can find a bit more about that 
<a href="https://github.com/UKPLab/sentence-transformers/issues/888">here</a>. </p>
<p>You can download the corresponding model <a href="https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/">here</a>
and unzip it. Then, simply use the following to create your embedding model:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="n">embedding_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;path/to/unzipped/model&#39;</span><span class="p">)</span>
</code></pre></div>
<p>Then, pass it to BERTopic:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">embedding_model</span><span class="o">=</span><span class="n">embedding_model</span><span class="p">)</span>
</code></pre></div>
<h2 id="can-i-use-the-gpu-to-speed-up-the-model"><strong>Can I use the GPU to speed up the model?</strong><a class="headerlink" href="#can-i-use-the-gpu-to-speed-up-the-model" title="Permanent link">&para;</a></h2>
<p>Yes and no. The GPU is automatically used when you use a SentenceTransformer or Flair embedding model. Using a CPU 
would then definitely slow things down. However, UMAP and HDBSCAN are not GPU-accelerated and are likely not so in 
the near future. For now, a GPU does help tremendously for extracting embeddings but does not speed up all 
aspects of BERtopic.   </p>
<h2 id="how-can-i-use-bertopic-with-chinese-documents"><strong>How can I use BERTopic with Chinese documents?</strong><a class="headerlink" href="#how-can-i-use-bertopic-with-chinese-documents" title="Permanent link">&para;</a></h2>
<p>Currently, CountVectorizer tokenizes text by splitting whitespace which does not work for Chinese. 
In order to get it to work, you will have to create a custom <code>CountVectorizer</code> with <code>jieba</code>:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
<span class="kn">import</span> <span class="nn">jieba</span>

<span class="k">def</span> <span class="nf">tokenize_zh</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">lcut</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">words</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenize_zh</span><span class="p">)</span>
</code></pre></div>
<p>Next, we pass our custom vectorizer to BERTopic and create our topic model:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">embedding_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vectorizer_model</span><span class="o">=</span><span class="n">vectorizer</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">=</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<h2 id="why-does-it-take-so-long-to-import-bertopic"><strong>Why does it take so long to import BERTopic?</strong><a class="headerlink" href="#why-does-it-take-so-long-to-import-bertopic" title="Permanent link">&para;</a></h2>
<p>The main culprit here seems to be UMAP. After running tests with <a href="https://github.com/nschloe/tuna">Tuna</a> we 
can see that most of the resources when importing BERTopic can be dedicated to UMAP:   </p>
<p><img src="img/tuna.png" /></p>
<p>Unfortunately, there currently is no fix for this issue. The most recent ticket regarding this 
issue can be found <a href="https://github.com/lmcinnes/umap/issues/631">here</a>.</p>
<h2 id="should-i-preprocess-the-data"><strong>Should I preprocess the data?</strong><a class="headerlink" href="#should-i-preprocess-the-data" title="Permanent link">&para;</a></h2>
<p>No. By using document embeddings there is typically no need to preprocess the data as all parts of a document 
are important in understanding the general topic of the document. Although this holds true in 99% of cases, if you 
have data that contains a lot of noise, for example, HTML-tags, then it would be best to remove them. HTML-tags 
typically do not contribute to the meaning of a document and should therefore be removed. However, if you apply 
topic modeling to HTML-code to extract topics of code, then it becomes important.</p>

              
            </article>
          </div>
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" data-md-state="hidden">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="getting_started/guided/guided.html" class="md-footer__link md-footer__link--prev" aria-label="Previous: Guided Topic Modeling" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Guided Topic Modeling
            </div>
          </div>
        </a>
      
      
        
        <a href="api/bertopic.html" class="md-footer__link md-footer__link--next" aria-label="Next: BERTopic" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              BERTopic
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2021 Maintained by <a href="https://github.com/MaartenGr">Maarten</a>.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": ".", "features": ["navigation.tabs", "navigation.sections", "navigation.instant", "navigation.top", "navigation.tracking", "toc.follow"], "search": "assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="assets/javascripts/bundle.6e54b5cd.min.js"></script>
      
    
  </body>
</html>