
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Leveraging BERT and a class-based TF-IDF to create easily interpretable topics.">
      
      
        <meta name="author" content="Maarten P. Grootendorst">
      
      
        <link rel="canonical" href="https://maartengr.github.io/BERTopic/getting_started/tips_and_tricks/tips_and_tricks.html">
      
      
        <link rel="prev" href="../parameter%20tuning/parametertuning.html">
      
      
        <link rel="next" href="../embeddings/embeddings.html">
      
      
      <link rel="icon" href="../../icon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.6">
    
    
      
        <title>Tips & Tricks - BERTopic</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.35e1ed30.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="black" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#tips-tricks" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../index.html" title="BERTopic" class="md-header__button md-logo" aria-label="BERTopic" data-md-component="logo">
      
  <img src="../../img/icon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BERTopic
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Tips & Tricks
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="black" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/MaartenGr/BERTopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../index.html" class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../algorithm/algorithm.html" class="md-tabs__link">
        
  
    
  
  The Algorithm

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../quickstart/quickstart.html" class="md-tabs__link">
          
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../faq.html" class="md-tabs__link">
        
  
    
  
  FAQ

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../usecases.html" class="md-tabs__link">
        
  
    
  
  Use Cases

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../api/bertopic.html" class="md-tabs__link">
          
  
  API

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../changelog.html" class="md-tabs__link">
        
  
    
  
  Changelog

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../index.html" title="BERTopic" class="md-nav__button md-logo" aria-label="BERTopic" data-md-component="logo">
      
  <img src="../../img/icon.png" alt="logo">

    </a>
    BERTopic
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/MaartenGr/BERTopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../algorithm/algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Algorithm
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Getting Started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../quickstart/quickstart.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../serialization/serialization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serialization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../search/search.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Search Topics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../best_practices/best_practices.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Best Practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" checked>
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    In-depth
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            In-depth
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5_1" >
        
          
          <label class="md-nav__link" for="__nav_3_5_1" id="__nav_3_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Visualizations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5_1">
            <span class="md-nav__icon md-icon"></span>
            Visualizations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../visualization/visualize_topics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../visualization/visualize_documents.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../visualization/visualize_terms.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Terms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../visualization/visualize_hierarchy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchy
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5_2" >
        
          
          <label class="md-nav__link" for="__nav_3_5_2" id="__nav_3_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Update Topics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5_2">
            <span class="md-nav__icon md-icon"></span>
            Update Topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../topicreduction/topicreduction.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topic Reduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../topicrepresentation/topicrepresentation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Update Topic Representations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../outlier_reduction/outlier_reduction.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Outlier reduction
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../parameter%20tuning/parametertuning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parameter tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Tips & Tricks
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="tips_and_tricks.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Tips & Tricks
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#document-length" class="md-nav__link">
    Document length
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#removing-stop-words" class="md-nav__link">
    Removing stop words
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#diversify-topic-representation" class="md-nav__link">
    Diversify topic representation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#topic-term-matrix" class="md-nav__link">
    Topic-term matrix
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-compute-embeddings" class="md-nav__link">
    Pre-compute embeddings
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speed-up-umap" class="md-nav__link">
    Speed up UMAP
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-acceleration" class="md-nav__link">
    GPU acceleration
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightweight-installation" class="md-nav__link">
    Lightweight installation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wordcloud" class="md-nav__link">
    WordCloud
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finding-similar-topics-between-models" class="md-nav__link">
    Finding similar topics between models
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multimodal-data" class="md-nav__link">
    Multimodal data
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#keybert-bertopic" class="md-nav__link">
    KeyBERT &amp; BERTopic
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
        
          
          <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Sub-models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            Sub-models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../embeddings/embeddings.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. Embeddings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../dim_reduction/dim_reduction.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. Dimensionality Reduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../clustering/clustering.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. Clustering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../vectorizers/vectorizers.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. Vectorizers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../ctfidf/ctfidf.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. c-TF-IDF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6_6" >
        
          
          <label class="md-nav__link" for="__nav_3_6_6" id="__nav_3_6_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    6. Fine-tune Topics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6_6">
            <span class="md-nav__icon md-icon"></span>
            6. Fine-tune Topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../representation/representation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6A. Representation Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../representation/llm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6B. LLM & Generative AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../multiaspect/multiaspect.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6C. Multiple Representations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
        
          
          <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Variations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            Variations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../topicsovertime/topicsovertime.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../hierarchicaltopics/hierarchicaltopics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchical Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../multimodal/multimodal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multimodal Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../online/online.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Online Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../merge/merge.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Merge Multiple Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7_6" >
        
          
          <label class="md-nav__link" for="__nav_3_7_6" id="__nav_3_7_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    (semi)-supervised
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_7_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7_6">
            <span class="md-nav__icon md-icon"></span>
            (semi)-supervised
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../semisupervised/semisupervised.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semi-supervised Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../supervised/supervised.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supervised Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../manual/manual.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Manual Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../guided/guided.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Guided Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../zeroshot/zeroshot.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Zero-shot Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../distribution/distribution.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topic Distributions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../topicsperclass/topicsperclass.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topics per Class
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../seed_words/seed_words.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Seed Words
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../faq.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../usecases.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Cases
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/bertopic.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BERTopic
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Sub-models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            Sub-models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_1" >
        
          
          <label class="md-nav__link" for="__nav_6_2_1" id="__nav_6_2_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Backends
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_1">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/backends/base.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/backends/word_doc.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Word Doc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/backends/openai.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenAI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/backends/cohere.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cohere
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2_2" id="__nav_6_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Dimensionality Reduction
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_2">
            <span class="md-nav__icon md-icon"></span>
            Dimensionality Reduction
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/dimensionality/base.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Base
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_3" >
        
          
          <label class="md-nav__link" for="__nav_6_2_3" id="__nav_6_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Clustering
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_3">
            <span class="md-nav__icon md-icon"></span>
            Clustering
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/cluster/base.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Base
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_4" >
        
          
          <label class="md-nav__link" for="__nav_6_2_4" id="__nav_6_2_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Vectorizers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_4">
            <span class="md-nav__icon md-icon"></span>
            Vectorizers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/ctfidf.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cTFIDF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/onlinecv.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OnlineCountVectorizer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_5" >
        
          
          <label class="md-nav__link" for="__nav_6_2_5" id="__nav_6_2_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Topic Representation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_5">
            <span class="md-nav__icon md-icon"></span>
            Topic Representation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/representation/base.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Base
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/representation/mmr.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MaximalMarginalRelevance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/representation/keybert.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KeyBERT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/representation/pos.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PartOfSpeech
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2_5_5" >
        
          
          <label class="md-nav__link" for="__nav_6_2_5_5" id="__nav_6_2_5_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Text Generation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_6_2_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_5_5">
            <span class="md-nav__icon md-icon"></span>
            Text Generation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/representation/generation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 Transformers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/representation/langchain.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LangChain
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/representation/cohere.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cohere
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/representation/openai.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OpenAI
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/representation/zeroshot.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Zero-shot Classification
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Plotting
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            Plotting
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/barchart.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Barchart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/documents.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/document_datamap.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documents with DataMapPlot
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/dtm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DTM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/hierarchical_documents.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchical documents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/hierarchy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchical topics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/distribution.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distribution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/heatmap.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Heatmap
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/term.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Term Scores
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/topics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../api/plotting/topics_per_class.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topics per Class
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../changelog.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Changelog
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#document-length" class="md-nav__link">
    Document length
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#removing-stop-words" class="md-nav__link">
    Removing stop words
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#diversify-topic-representation" class="md-nav__link">
    Diversify topic representation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#topic-term-matrix" class="md-nav__link">
    Topic-term matrix
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pre-compute-embeddings" class="md-nav__link">
    Pre-compute embeddings
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#speed-up-umap" class="md-nav__link">
    Speed up UMAP
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gpu-acceleration" class="md-nav__link">
    GPU acceleration
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lightweight-installation" class="md-nav__link">
    Lightweight installation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wordcloud" class="md-nav__link">
    WordCloud
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finding-similar-topics-between-models" class="md-nav__link">
    Finding similar topics between models
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multimodal-data" class="md-nav__link">
    Multimodal data
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#keybert-bertopic" class="md-nav__link">
    KeyBERT &amp; BERTopic
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="tips-tricks">Tips &amp; Tricks<a class="headerlink" href="#tips-tricks" title="Permanent link">&para;</a></h1>
<h2 id="document-length"><strong>Document length</strong><a class="headerlink" href="#document-length" title="Permanent link">&para;</a></h2>
<p>As a default, we are using sentence-transformers to embed our documents. However, as the name implies, the embedding model works best for either sentences or paragraphs. This means that whenever you have a set of documents, where each documents contains several paragraphs, the document is truncated and the topic model is only trained on a small part of the data. </p>
<p>One way to solve this issue is by splitting up longer documents into either sentences or paragraphs before embedding them. Another solution is to approximate the <a href="https://maartengr.github.io/BERTopic/getting_started/distribution/distribution.html">topic distributions</a> of topics after having trained your topic model. </p>
<h2 id="removing-stop-words"><strong>Removing stop words</strong><a class="headerlink" href="#removing-stop-words" title="Permanent link">&para;</a></h2>
<p>At times, stop words might end up in our topic representations. This is something we typically want to avoid as they contribute little to the interpretation of the topics. However, removing stop words as a preprocessing step is not advised as the transformer-based embedding models that we use need the full context in order to create accurate embeddings. </p>
<p>Instead, we can use the <code>CountVectorizer</code> to preprocess our documents <strong>after</strong> having generated embeddings and clustered 
our documents. Personally, I have found almost no disadvantages to using the <code>CountVectorizer</code> to remove stopwords and 
it is something I would strongly advise to try out:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer_model</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">vectorizer_model</span><span class="o">=</span><span class="n">vectorizer_model</span><span class="p">)</span>
</code></pre></div>
<p>We can also use the <code>ClassTfidfTransformer</code> to reduce the impact of frequent words. The end result is very similar to explicitly removing stopwords but this process does this automatically:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">bertopic.vectorizers</span> <span class="kn">import</span> <span class="n">ClassTfidfTransformer</span>

<span class="n">ctfidf_model</span> <span class="o">=</span> <span class="n">ClassTfidfTransformer</span><span class="p">(</span><span class="n">reduce_frequent_words</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">ctfidf_model</span><span class="o">=</span><span class="n">ctfidf_model</span><span class="p">)</span>
</code></pre></div>
<p>Lastly, we can use a KeyBERT-Inspired model to reduce the appearance of stop words. This also often improves the topic representation:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">KeyBERTInspired</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1"># Create your representation model</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">KeyBERTInspired</span><span class="p">()</span>

<span class="c1"># Use the representation model in BERTopic on top of the default pipeline</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>
<h2 id="diversify-topic-representation"><strong>Diversify topic representation</strong><a class="headerlink" href="#diversify-topic-representation" title="Permanent link">&para;</a></h2>
<p>After having calculated our top <em>n</em> words per topic there might be many words that essentially 
mean the same thing. As a little bonus, we can use <code>bertopic.representation.MaximalMarginalRelevance</code> in BERTopic to 
diversify words in each topic such that we limit the number of duplicate words we find in each topic. 
This is done using an algorithm called Maximal Marginal Relevance which compares word embeddings 
with the topic embedding. </p>
<p>We do this by specifying a value between 0 and 1, with 0 being not at all diverse and 1 being completely diverse:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">MaximalMarginalRelevance</span>

<span class="n">representation_model</span> <span class="o">=</span> <span class="n">MaximalMarginalRelevance</span><span class="p">(</span><span class="n">diversity</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>
<p>Since MMR is using word embeddings to diversify the topic representations, it is necessary to pass the embedding model to BERTopic if you are using pre-computed embeddings:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">MaximalMarginalRelevance</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">sentence_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">MaximalMarginalRelevance</span><span class="p">(</span><span class="n">diversity</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">embedding_model</span><span class="o">=</span><span class="n">sentence_model</span><span class="p">,</span> <span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>
<h2 id="topic-term-matrix"><strong>Topic-term matrix</strong><a class="headerlink" href="#topic-term-matrix" title="Permanent link">&para;</a></h2>
<p>Although BERTopic focuses on clustering our documents, the end result does contain a topic-term matrix. 
This topic-term matrix is calculated using c-TF-IDF, a TF-IDF procedure optimized for class-based analyses. </p>
<p>To extract the topic-term matrix (or c-TF-IDF matrix) with the corresponding words, we can simply do the following:</p>
<div class="highlight"><pre><span></span><code><span class="n">topic_term_matrix</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">c_tf_idf_</span>
<span class="n">words</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">vectorizer_model</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
</code></pre></div>
<h2 id="pre-compute-embeddings"><strong>Pre-compute embeddings</strong><a class="headerlink" href="#pre-compute-embeddings" title="Permanent link">&para;</a></h2>
<p>Typically, we want to iterate fast over different versions of our BERTopic model whilst we are trying to optimize it to a specific use case. To speed up this process, we can pre-compute the embeddings, save them, 
and pass them to BERTopic so it does not need to calculate the embeddings each time: </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="c1"># Prepare embeddings</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span>  <span class="n">remove</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;headers&#39;</span><span class="p">,</span> <span class="s1">&#39;footers&#39;</span><span class="p">,</span> <span class="s1">&#39;quotes&#39;</span><span class="p">))[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">sentence_model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Train our topic model using our pre-trained sentence-transformers embeddings</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">()</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<h2 id="speed-up-umap"><strong>Speed up UMAP</strong><a class="headerlink" href="#speed-up-umap" title="Permanent link">&para;</a></h2>
<p>At times, UMAP may take a while to fit on the embeddings that you have. This often happens when you have
the embeddings millions of documents that you want to reduce in dimensionality. There is a trick that 
can speed up this process somewhat: Initializing UMAP with rescaled PCA embeddings. </p>
<p>Without going in too much detail (look <a href="https://github.com/lmcinnes/umap/issues/771#issuecomment-931886015">here</a> for more information), you can reduce the embeddings using PCA 
and use that as a starting point. This can speed up the dimensionality reduction a bit: </p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">umap</span> <span class="kn">import</span> <span class="n">UMAP</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>


<span class="k">def</span> <span class="nf">rescale</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Rescale an embedding so optimization will not have convergence issues.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">inplace</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="mi">10000</span>

    <span class="k">return</span> <span class="n">x</span>


<span class="c1"># Initialize and rescale PCA embeddings</span>
<span class="n">pca_embeddings</span> <span class="o">=</span> <span class="n">rescale</span><span class="p">(</span><span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">embeddings</span><span class="p">))</span>

<span class="c1"># Start UMAP from PCA embeddings</span>
<span class="n">umap_model</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span>
    <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
    <span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
    <span class="n">init</span><span class="o">=</span><span class="n">pca_embeddings</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Pass the model to BERTopic:</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">umap_model</span><span class="o">=</span><span class="n">umap_model</span><span class="p">)</span>
</code></pre></div>
<h2 id="gpu-acceleration"><strong>GPU acceleration</strong><a class="headerlink" href="#gpu-acceleration" title="Permanent link">&para;</a></h2>
<p>You can use <a href="https://rapids.ai/start.html#rapids-release-selector">cuML</a> to speed up both 
UMAP and HDBSCAN through GPU acceleration:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">cuml.cluster</span> <span class="kn">import</span> <span class="n">HDBSCAN</span>
<span class="kn">from</span> <span class="nn">cuml.manifold</span> <span class="kn">import</span> <span class="n">UMAP</span>

<span class="c1"># Create instances of GPU-accelerated UMAP and HDBSCAN</span>
<span class="n">umap_model</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">hdbscan_model</span> <span class="o">=</span> <span class="n">HDBSCAN</span><span class="p">(</span><span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gen_min_span_tree</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">prediction_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Pass the above models to be used in BERTopic</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">umap_model</span><span class="o">=</span><span class="n">umap_model</span><span class="p">,</span> <span class="n">hdbscan_model</span><span class="o">=</span><span class="n">hdbscan_model</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div>
<p>Depending on the embeddings you are using, you might want to normalize them first in order to 
force a cosine-related distance metric in UMAP:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">cuml.preprocessing</span> <span class="kn">import</span> <span class="n">normalize</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As of the v0.13 release, it is not yet possible to calculate the topic-document probability matrix for unseen data (i.e., <code>.transform</code>) using cuML's HDBSCAN. 
However, it is still possible to calculate the topic-document probability matrix for the data on which the model was trained (i.e., <code>.fit</code> and <code>.fit_transform</code>).</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you want to install cuML together with BERTopic using Google Colab, you can run the following code:</p>
<div class="highlight"><pre><span></span><code>!pip<span class="w"> </span>install<span class="w"> </span>bertopic
!pip<span class="w"> </span>install<span class="w"> </span>cudf-cu11<span class="w"> </span>dask-cudf-cu11<span class="w"> </span>--extra-index-url<span class="o">=</span>https://pypi.nvidia.com
!pip<span class="w"> </span>install<span class="w"> </span>cuml-cu11<span class="w"> </span>--extra-index-url<span class="o">=</span>https://pypi.nvidia.com
!pip<span class="w"> </span>install<span class="w"> </span>cugraph-cu11<span class="w"> </span>--extra-index-url<span class="o">=</span>https://pypi.nvidia.com
!pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>cupy-cuda11x<span class="w"> </span>-f<span class="w"> </span>https://pip.cupy.dev/aarch64
</code></pre></div>
</div>
<h2 id="lightweight-installation"><strong>Lightweight installation</strong><a class="headerlink" href="#lightweight-installation" title="Permanent link">&para;</a></h2>
<p>The default embedding model in BERTopic is one of the amazing sentence-transformers models, namely <code>"all-MiniLM-L6-v2"</code>. Although this model performs well out of the box, it typically needs a GPU to transform the documents into embeddings in a reasonable time. Moreover, the installation requires <code>pytorch</code> which often results in a rather large environment, memory-wise. </p>
<p>Fortunately, it is possible to install BERTopic without <code>sentence-transformers</code> and use it as a lightweight solution instead. The installation can be done as follows:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>--no-deps<span class="w"> </span>bertopic
pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>numpy<span class="w"> </span>hdbscan<span class="w"> </span>umap-learn<span class="w"> </span>pandas<span class="w"> </span>scikit-learn<span class="w"> </span>tqdm<span class="w"> </span>plotly<span class="w"> </span>pyyaml
</code></pre></div>
<p>Then, we can use BERTopic without <code>sentence-transformers</code> as follows using a CPU-based embedding technique:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">TfidfVectorizer</span><span class="p">(),</span>
    <span class="n">TruncatedSVD</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">embedding_model</span><span class="o">=</span><span class="n">pipe</span><span class="p">)</span>
</code></pre></div>
<p>As a result, the entire package and resulting model can be run quickly on the CPU and no GPU is necessary!</p>
<h2 id="wordcloud"><strong>WordCloud</strong><a class="headerlink" href="#wordcloud" title="Permanent link">&para;</a></h2>
<p>To minimize the number of dependencies in BERTopic, it is not possible to generate wordclouds out-of-the-box. However, 
there is a minimal script that you can use to generate wordclouds in BERTopic. First, you will need to install 
the <a href="https://github.com/amueller/word_cloud">wordcloud</a> package with <code>pip install wordcloud</code>. Then, run the following code 
to generate the wordcloud for a specific topic:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">wordcloud</span> <span class="kn">import</span> <span class="n">WordCloud</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">create_wordcloud</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">topic</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="n">topic</span><span class="p">)}</span>
    <span class="n">wc</span> <span class="o">=</span> <span class="n">WordCloud</span><span class="p">(</span><span class="n">background_color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">,</span> <span class="n">max_words</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">wc</span><span class="o">.</span><span class="n">generate_from_frequencies</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">wc</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Show wordcloud</span>
<span class="n">create_wordcloud</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">topic</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p><img alt="" src="wordcloud.jpg" /></p>
<div class="admonition tip tip">
<p class="admonition-title">Tip</p>
<p>To increase the number of words shown in the wordcloud, you can increase the <code>top_n_words</code> 
parameter when instantiating BERTopic. You can also increase the number of words in a topic
after training the model using <code>.update_topics()</code>. </p>
</div>
<h2 id="finding-similar-topics-between-models"><strong>Finding similar topics between models</strong><a class="headerlink" href="#finding-similar-topics-between-models" title="Permanent link">&para;</a></h2>
<p>Whenever you have trained separate BERTopic models on different datasets, it might 
be worthful to find the similarities among these models. Is there overlap between 
topics in model A and topic in model B? In other words, can we find topics in model A that are similar to those in model B? </p>
<p>We can compare the topic representations of several models in two ways. First, by comparing the topic embeddings that are created when using the same embedding model across both fitted BERTopic instances. Second, we can compare the c-TF-IDF representations instead assuming we have fixed the vocabulary in both instances. </p>
<p>This example will go into the former, using the same embedding model across two BERTopic instances. To do this comparison, let's first create an example where I trained two models, one on an English dataset and one on a Dutch dataset:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">umap</span> <span class="kn">import</span> <span class="n">UMAP</span>

<span class="c1"># The same embedding model needs to be used for both topic models</span>
<span class="c1"># and since we are dealing with multiple languages, the model needs to be multi-lingual</span>
<span class="n">sentence_model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;paraphrase-multilingual-MiniLM-L12-v2&quot;</span><span class="p">)</span>

<span class="c1"># To make this example reproducible</span>
<span class="n">umap_model</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
                  <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># English</span>
<span class="n">en_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;stsb_multi_mt&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span><span class="o">.</span><span class="n">sentence1</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">en_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">embedding_model</span><span class="o">=</span><span class="n">sentence_model</span><span class="p">,</span> <span class="n">umap_model</span><span class="o">=</span><span class="n">umap_model</span><span class="p">)</span>
<span class="n">en_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">en_dataset</span><span class="p">)</span>

<span class="c1"># Dutch</span>
<span class="n">nl_dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;stsb_multi_mt&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;nl&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span><span class="o">.</span><span class="n">sentence1</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">nl_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">embedding_model</span><span class="o">=</span><span class="n">sentence_model</span><span class="p">,</span> <span class="n">umap_model</span><span class="o">=</span><span class="n">umap_model</span><span class="p">)</span>
<span class="n">nl_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">nl_dataset</span><span class="p">)</span>
</code></pre></div>
<p>In the code above, there is one important thing to note and that is the <code>sentence_model</code>. This model needs to be exactly the same in all BERTopic models, otherwise, it is not possible to compare topic models. </p>
<p>Next, we can calculate the similarity between topics in the English topic model <code>en_model</code> and the Dutch model <code>nl_model</code>. To do so, we can simply calculate the cosine similarity between the <code>topic_embedding</code> of both models: </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="n">sim_matrix</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">en_model</span><span class="o">.</span><span class="n">topic_embeddings_</span><span class="p">,</span> <span class="n">nl_model</span><span class="o">.</span><span class="n">topic_embeddings_</span><span class="p">)</span>
</code></pre></div>
<p>Now that we know which topics are similar to each other, we can extract the most similar topics. Let's say that we have topic 10 in the <code>en_model</code> which represents a topic related to trains:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">topic</span> <span class="o">=</span> <span class="mi">10</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">en_model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>
<span class="p">[(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="mf">0.2588080580844999</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;tracks&#39;</span><span class="p">,</span> <span class="mf">0.1392140438801078</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;station&#39;</span><span class="p">,</span> <span class="mf">0.12126454635946024</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;passenger&#39;</span><span class="p">,</span> <span class="mf">0.058057876475695866</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;engine&#39;</span><span class="p">,</span> <span class="mf">0.05123717127783682</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;railroad&#39;</span><span class="p">,</span> <span class="mf">0.048142847325312044</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;waiting&#39;</span><span class="p">,</span> <span class="mf">0.04098973702226946</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;track&#39;</span><span class="p">,</span> <span class="mf">0.03978248702913929</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;subway&#39;</span><span class="p">,</span> <span class="mf">0.03834661195748458</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;steam&#39;</span><span class="p">,</span> <span class="mf">0.03834661195748458</span><span class="p">)]</span>
</code></pre></div>
<p>To find the matching topic, we extract the most similar topic in the <code>sim_matrix</code>:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">most_similar_topic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">sim_matrix</span><span class="p">[</span><span class="n">topic</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">nl_model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="n">most_similar_topic</span><span class="p">)</span>
<span class="p">[(</span><span class="s1">&#39;trein&#39;</span><span class="p">,</span> <span class="mf">0.24186603209316418</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;spoor&#39;</span><span class="p">,</span> <span class="mf">0.1338118418551581</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;sporen&#39;</span><span class="p">,</span> <span class="mf">0.07683661859111401</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;station&#39;</span><span class="p">,</span> <span class="mf">0.056990389779394225</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;stoommachine&#39;</span><span class="p">,</span> <span class="mf">0.04905829711711234</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;zilveren&#39;</span><span class="p">,</span> <span class="mf">0.04083879598477808</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;treinen&#39;</span><span class="p">,</span> <span class="mf">0.03534099197032758</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;treinsporen&#39;</span><span class="p">,</span> <span class="mf">0.03534099197032758</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;staat&#39;</span><span class="p">,</span> <span class="mf">0.03481332997324445</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;zwarte&#39;</span><span class="p">,</span> <span class="mf">0.03179591746822408</span><span class="p">)]</span>
</code></pre></div>
<p>It seems to be working as, for example, <code>trein</code> is a translation of <code>train</code> and <code>sporen</code> a translation of <code>tracks</code>! You can do this for every single topic to find out which topic in the <code>en_model</code> might belong to a model in the <code>nl_model</code>. </p>
<h2 id="multimodal-data"><strong>Multimodal data</strong><a class="headerlink" href="#multimodal-data" title="Permanent link">&para;</a></h2>
<p><a href="https://github.com/MaartenGr/Concept">Concept</a> is a variation 
of BERTopic for multimodal data, such as images with captions. Although we can use that 
package for multimodal data, we can perform a small trick with BERTopic to have a similar feature. </p>
<p>BERTopic is a relatively modular approach that attempts to isolate steps from one another. This means, 
for example, that you can use k-Means instead of HDBSCAN or PCA instead of UMAP as it does not make 
any assumptions with respect to the nature of the clustering. </p>
<p>Similarly, you can pass pre-calculated embeddings to BERTopic that represent the documents that you have. 
However, it does not make any assumption with respect to the relationship between those embeddings and 
the documents. This means that we could pass any metadata to BERTopic to cluster on instead of document 
embeddings. In this example, we can separate our embeddings from our documents so that the embeddings 
are generated from images instead of their corresponding images. Thus, we will cluster image embeddings but 
create the topic representation from the related captions. </p>
<p>In this example, we first need to fetch our data, namely the Flickr 8k dataset that contains images 
with captions:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span><span class="p">,</span> <span class="n">util</span>

<span class="c1"># Flickr 8k images</span>
<span class="n">img_folder</span> <span class="o">=</span> <span class="s1">&#39;photos/&#39;</span>
<span class="n">caps_folder</span> <span class="o">=</span> <span class="s1">&#39;captions/&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">img_folder</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">img_folder</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">img_folder</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s1">&#39;Flickr8k_Dataset.zip&#39;</span><span class="p">):</span>   <span class="c1">#Download dataset if does not exist</span>
        <span class="n">util</span><span class="o">.</span><span class="n">http_get</span><span class="p">(</span><span class="s1">&#39;https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip&#39;</span><span class="p">,</span> <span class="s1">&#39;Flickr8k_Dataset.zip&#39;</span><span class="p">)</span>
        <span class="n">util</span><span class="o">.</span><span class="n">http_get</span><span class="p">(</span><span class="s1">&#39;https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip&#39;</span><span class="p">,</span> <span class="s1">&#39;Flickr8k_text.zip&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">folder</span><span class="p">,</span> <span class="n">file</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">img_folder</span><span class="p">,</span> <span class="s1">&#39;Flickr8k_Dataset.zip&#39;</span><span class="p">),</span> <span class="p">(</span><span class="n">caps_folder</span><span class="p">,</span> <span class="s1">&#39;Flickr8k_text.zip&#39;</span><span class="p">)]:</span>
        <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zf</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">member</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">zf</span><span class="o">.</span><span class="n">infolist</span><span class="p">(),</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Extracting&#39;</span><span class="p">):</span>
                <span class="n">zf</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">member</span><span class="p">,</span> <span class="n">folder</span><span class="p">)</span>
<span class="n">images</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">&#39;photos/Flicker8k_Dataset/*.jpg&#39;</span><span class="p">))</span>

<span class="c1"># Prepare dataframe</span>
<span class="n">captions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;captions/Flickr8k.lemma.token.txt&quot;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;img_id&quot;</span><span class="p">,</span><span class="s2">&quot;img_caption&quot;</span><span class="p">])</span>
<span class="n">captions</span><span class="o">.</span><span class="n">img_id</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="s2">&quot;photos/Flicker8k_Dataset/&quot;</span> <span class="o">+</span> <span class="n">row</span><span class="o">.</span><span class="n">img_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.jpg&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;.jpg&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">captions</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s2">&quot;img_id&quot;</span><span class="p">])[</span><span class="s2">&quot;img_caption&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">captions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">captions</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;img_id&quot;</span><span class="p">),</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;img_id&quot;</span><span class="p">)</span>

<span class="c1"># Extract images together with their documents/captions</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">img_id</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">img_caption</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>
</code></pre></div>
<p>Now that we have our images and captions, we need to generate our image embeddings:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">&#39;clip-ViT-B-32&#39;</span><span class="p">)</span>

<span class="c1"># Prepare images</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">nr_iterations</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">))</span>

<span class="c1"># Embed images per batch</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nr_iterations</span><span class="p">)):</span>
    <span class="n">start_index</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span>
    <span class="n">end_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">batch_size</span>

    <span class="n">images_to_embed</span> <span class="o">=</span> <span class="p">[</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span> <span class="k">for</span> <span class="n">filepath</span> <span class="ow">in</span> <span class="n">images</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="n">end_index</span><span class="p">]]</span>
    <span class="n">img_emb</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">images_to_embed</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">embeddings</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">img_emb</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

    <span class="c1"># Close images</span>
    <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images_to_embed</span><span class="p">:</span>
        <span class="n">image</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>
</code></pre></div>
<p>Finally, we can fit BERTopic the way we are used to, with documents and embeddings:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer_model</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s2">&quot;english&quot;</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">vectorizer_model</span><span class="o">=</span><span class="n">vectorizer_model</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
<span class="n">captions</span><span class="p">[</span><span class="s2">&quot;Topic&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">topics</span>
</code></pre></div>
<p>After fitting our model, let's inspect a topic about skateboarders:</p>
<div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">get_topic</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="p">[(</span><span class="s1">&#39;skateboard&#39;</span><span class="p">,</span> <span class="mf">0.09592033177340711</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;skateboarder&#39;</span><span class="p">,</span> <span class="mf">0.07792520092546491</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;trick&#39;</span><span class="p">,</span> <span class="mf">0.07481578896400298</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;ramp&#39;</span><span class="p">,</span> <span class="mf">0.056952605147927216</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;skate&#39;</span><span class="p">,</span> <span class="mf">0.03745127816149923</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;perform&#39;</span><span class="p">,</span> <span class="mf">0.036546213623432654</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;bicycle&#39;</span><span class="p">,</span> <span class="mf">0.03453483070441857</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;bike&#39;</span><span class="p">,</span> <span class="mf">0.033233021253898994</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;jump&#39;</span><span class="p">,</span> <span class="mf">0.026709362981948037</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">&#39;air&#39;</span><span class="p">,</span> <span class="mf">0.025422798170830936</span><span class="p">)]</span>
</code></pre></div>
<p>Based on the above output, we can take an image to see if the representation makes sense:</p>
<div class="highlight"><pre><span></span><code><span class="n">image</span> <span class="o">=</span> <span class="n">captions</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">captions</span><span class="o">.</span><span class="n">Topic</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;img_id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<p><img alt="" src="skateboarders.jpg" /></p>
<h2 id="keybert-bertopic"><strong>KeyBERT</strong> &amp; <strong>BERTopic</strong><a class="headerlink" href="#keybert-bertopic" title="Permanent link">&para;</a></h2>
<p>Although BERTopic focuses on topic extraction methods that does not assume specific structures for the generated clusters, it is possible to do this on a more local level. More specifically, we can use KeyBERT to generate a number of keywords for each document and then build a vocabulary on top of that as the input for BERTopic. This way, we can select words that we know have meaning to a topic, without focusing on the centroid of that cluster. This also allows more frequent words to pop-up regardless of the structure and density of a cluster. </p>
<p>To do this, we first need to run <a href="https://github.com/MaartenGr/KeyBERT">KeyBERT</a> on our data and create our vocabulary:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">keybert</span> <span class="kn">import</span> <span class="n">KeyBERT</span>

<span class="c1"># Prepare documents </span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">,</span>  <span class="n">remove</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;headers&#39;</span><span class="p">,</span> <span class="s1">&#39;footers&#39;</span><span class="p">,</span> <span class="s1">&#39;quotes&#39;</span><span class="p">))[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>

<span class="c1"># Extract keywords</span>
<span class="n">kw_model</span> <span class="o">=</span> <span class="n">KeyBERT</span><span class="p">()</span>
<span class="n">keywords</span> <span class="o">=</span> <span class="n">kw_model</span><span class="o">.</span><span class="n">extract_keywords</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>

<span class="c1"># Create our vocabulary</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keyword</span><span class="p">]</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">))</span>
</code></pre></div>
<p>Then, we pass our <code>vocabulary</code> to BERTopic and train the model:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer_model</span><span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">vocabulary</span><span class="o">=</span><span class="n">vocabulary</span><span class="p">)</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">vectorizer_model</span><span class="o">=</span><span class="n">vectorizer_model</span><span class="p">)</span>
<span class="n">topics</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 Maintained by <a href="https://github.com/MaartenGr">Maarten Grootendorst</a>.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.instant", "navigation.top", "navigation.tracking", "toc.follow", "content.code.copy"], "search": "../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.aecac24b.min.js"></script>
      
    
  </body>
</html>