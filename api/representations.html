
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Leveraging BERT and a class-based TF-IDF to create easily interpretable topics.">
      
      
        <meta name="author" content="Maarten P. Grootendorst">
      
      
        <link rel="canonical" href="https://maartengr.github.io/BERTopic/api/representations.html">
      
      
        <link rel="prev" href="ctfidf.html">
      
      
        <link rel="next" href="plotting/barchart.html">
      
      
      <link rel="icon" href="../icon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.44">
    
    
      
        <title>6. Fine-Tune Topic Representation - BERTopic</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="black" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#representations" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="BERTopic" class="md-header__button md-logo" aria-label="BERTopic" data-md-component="logo">
      
  <img src="../img/icon.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            BERTopic
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              6. Fine-Tune Topic Representation
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="black" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/MaartenGr/BERTopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../index.html" class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../algorithm/algorithm.html" class="md-tabs__link">
        
  
    
  
  The Algorithm

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../getting_started/quickstart/quickstart.html" class="md-tabs__link">
          
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../faq.html" class="md-tabs__link">
        
  
    
  
  FAQ

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../usecases.html" class="md-tabs__link">
        
  
    
  
  Use Cases

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="bertopic.html" class="md-tabs__link">
          
  
  API

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../changelog.html" class="md-tabs__link">
        
  
    
  
  Changelog

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="BERTopic" class="md-nav__button md-logo" aria-label="BERTopic" data-md-component="logo">
      
  <img src="../img/icon.png" alt="logo">

    </a>
    BERTopic
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/MaartenGr/BERTopic" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../algorithm/algorithm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The Algorithm
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Getting Started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/quickstart/quickstart.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quick Start
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/serialization/serialization.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Serialization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/search/search.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Search Topics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/best_practices/best_practices.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Best Practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    In-depth
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            In-depth
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5_1" >
        
          
          <label class="md-nav__link" for="__nav_3_5_1" id="__nav_3_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Visualizations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5_1">
            <span class="md-nav__icon md-icon"></span>
            Visualizations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/visualization/visualize_topics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/visualization/visualize_documents.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/visualization/visualize_terms.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Terms
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/visualization/visualize_hierarchy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchy
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5_2" >
        
          
          <label class="md-nav__link" for="__nav_3_5_2" id="__nav_3_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Update Topics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5_2">
            <span class="md-nav__icon md-icon"></span>
            Update Topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/topicreduction/topicreduction.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topic Reduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/topicrepresentation/topicrepresentation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Update Topic Representations
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/outlier_reduction/outlier_reduction.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Outlier reduction
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/parameter%20tuning/parametertuning.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parameter tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/tips_and_tricks/tips_and_tricks.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tips & Tricks
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
        
          
          <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Sub-models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            Sub-models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/embeddings/embeddings.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. Embeddings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/dim_reduction/dim_reduction.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. Dimensionality Reduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/clustering/clustering.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. Clustering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/vectorizers/vectorizers.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. Vectorizers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/ctfidf/ctfidf.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. c-TF-IDF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6_6" >
        
          
          <label class="md-nav__link" for="__nav_3_6_6" id="__nav_3_6_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    6. Fine-tune Topics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6_6">
            <span class="md-nav__icon md-icon"></span>
            6. Fine-tune Topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/representation/representation.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6A. Representation Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/representation/llm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6B. LLM & Generative AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/multiaspect/multiaspect.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6C. Multiple Representations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
        
          
          <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Variations
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            Variations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/topicsovertime/topicsovertime.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dynamic Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/hierarchicaltopics/hierarchicaltopics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchical Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/multimodal/multimodal.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Multimodal Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/online/online.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Online Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/merge/merge.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Merge Multiple Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7_6" >
        
          
          <label class="md-nav__link" for="__nav_3_7_6" id="__nav_3_7_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    (semi)-supervised
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_7_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7_6">
            <span class="md-nav__icon md-icon"></span>
            (semi)-supervised
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/semisupervised/semisupervised.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semi-supervised Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/supervised/supervised.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Supervised Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/manual/manual.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Manual Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/guided/guided.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Guided Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/zeroshot/zeroshot.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Zero-shot Topic Modeling
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/distribution/distribution.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topic Distributions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/topicsperclass/topicsperclass.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topics per Class
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/seed_words/seed_words.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Seed Words
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../faq.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../usecases.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Use Cases
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="bertopic.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BERTopic
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" checked>
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Sub-models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            Sub-models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="backends.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. Backends
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="dimensionality.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2. Dimensionality Reduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="cluster.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. Clustering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="vectorizers.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. Vectorizers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="ctfidf.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. c-TF-IDF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    6. Fine-Tune Topic Representation
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="representations.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    6. Fine-Tune Topic Representation
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation" class="md-nav__link">
    <span class="md-ellipsis">
      representation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.BaseRepresentation" class="md-nav__link">
    <span class="md-ellipsis">
      BaseRepresentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BaseRepresentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.BaseRepresentation.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.Cohere" class="md-nav__link">
    <span class="md-ellipsis">
      Cohere
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cohere">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.Cohere.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.KeyBERTInspired" class="md-nav__link">
    <span class="md-ellipsis">
      KeyBERTInspired
    </span>
  </a>
  
    <nav class="md-nav" aria-label="KeyBERTInspired">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.KeyBERTInspired.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.KeyBERTInspired.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.LangChain" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LangChain">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.LangChain.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.LiteLLM" class="md-nav__link">
    <span class="md-ellipsis">
      LiteLLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LiteLLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.LiteLLM.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.LlamaCPP" class="md-nav__link">
    <span class="md-ellipsis">
      LlamaCPP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LlamaCPP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.LlamaCPP.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.MaximalMarginalRelevance" class="md-nav__link">
    <span class="md-ellipsis">
      MaximalMarginalRelevance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MaximalMarginalRelevance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.MaximalMarginalRelevance.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.OpenAI" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OpenAI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.OpenAI.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.PartOfSpeech" class="md-nav__link">
    <span class="md-ellipsis">
      PartOfSpeech
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PartOfSpeech">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.PartOfSpeech.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.TextGeneration" class="md-nav__link">
    <span class="md-ellipsis">
      TextGeneration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TextGeneration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.TextGeneration.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.VisualRepresentation" class="md-nav__link">
    <span class="md-ellipsis">
      VisualRepresentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VisualRepresentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.VisualRepresentation.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.VisualRepresentation.image_to_text" class="md-nav__link">
    <span class="md-ellipsis">
      image_to_text
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.ZeroShotClassification" class="md-nav__link">
    <span class="md-ellipsis">
      ZeroShotClassification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ZeroShotClassification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.ZeroShotClassification.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_3" >
        
          
          <label class="md-nav__link" for="__nav_6_3" id="__nav_6_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Plotting
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_3">
            <span class="md-nav__icon md-icon"></span>
            Plotting
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/barchart.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Barchart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/documents.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/document_datamap.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Documents with DataMapPlot
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/dtm.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DTM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/hierarchical_documents.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchical documents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/hierarchy.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hierarchical topics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/distribution.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distribution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/heatmap.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Heatmap
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/term.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Term Scores
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/topics.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topics
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="plotting/topics_per_class.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Topics per Class
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Changelog
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation" class="md-nav__link">
    <span class="md-ellipsis">
      representation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.BaseRepresentation" class="md-nav__link">
    <span class="md-ellipsis">
      BaseRepresentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BaseRepresentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.BaseRepresentation.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.Cohere" class="md-nav__link">
    <span class="md-ellipsis">
      Cohere
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Cohere">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.Cohere.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.KeyBERTInspired" class="md-nav__link">
    <span class="md-ellipsis">
      KeyBERTInspired
    </span>
  </a>
  
    <nav class="md-nav" aria-label="KeyBERTInspired">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.KeyBERTInspired.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.KeyBERTInspired.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.LangChain" class="md-nav__link">
    <span class="md-ellipsis">
      LangChain
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LangChain">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.LangChain.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.LiteLLM" class="md-nav__link">
    <span class="md-ellipsis">
      LiteLLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LiteLLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.LiteLLM.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.LlamaCPP" class="md-nav__link">
    <span class="md-ellipsis">
      LlamaCPP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LlamaCPP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.LlamaCPP.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.MaximalMarginalRelevance" class="md-nav__link">
    <span class="md-ellipsis">
      MaximalMarginalRelevance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MaximalMarginalRelevance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.MaximalMarginalRelevance.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.OpenAI" class="md-nav__link">
    <span class="md-ellipsis">
      OpenAI
    </span>
  </a>
  
    <nav class="md-nav" aria-label="OpenAI">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.OpenAI.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.PartOfSpeech" class="md-nav__link">
    <span class="md-ellipsis">
      PartOfSpeech
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PartOfSpeech">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.PartOfSpeech.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.TextGeneration" class="md-nav__link">
    <span class="md-ellipsis">
      TextGeneration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TextGeneration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.TextGeneration.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.VisualRepresentation" class="md-nav__link">
    <span class="md-ellipsis">
      VisualRepresentation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VisualRepresentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.VisualRepresentation.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.VisualRepresentation.image_to_text" class="md-nav__link">
    <span class="md-ellipsis">
      image_to_text
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bertopic.representation.ZeroShotClassification" class="md-nav__link">
    <span class="md-ellipsis">
      ZeroShotClassification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ZeroShotClassification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bertopic.representation.ZeroShotClassification.extract_topics" class="md-nav__link">
    <span class="md-ellipsis">
      extract_topics
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="representations"><code>Representations</code><a class="headerlink" href="#representations" title="Permanent link">&para;</a></h1>


<div class="doc doc-object doc-module">



<a id="bertopic.representation"></a>
    <div class="doc doc-contents first">








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.BaseRepresentation" class="doc doc-heading">
            <code>BaseRepresentation</code>


<a href="#bertopic.representation.BaseRepresentation" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="sklearn.base.BaseEstimator">BaseEstimator</span></code></p>


        <p>The base representation model for fine-tuning topic representations.</p>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_base.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BaseRepresentation</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The base representation model for fine-tuning topic representations.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">        Each representation model that inherits this class will have</span>
<span class="sd">        its arguments (topic_model, documents, c_tf_idf, topics)</span>
<span class="sd">        automatically passed. Therefore, the representation model</span>
<span class="sd">        will only have access to the information about topics related</span>
<span class="sd">        to those arguments.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: The BERTopic model that is fitted until topic</span>
<span class="sd">                         representations are calculated.</span>
<span class="sd">            documents: A dataframe with columns &quot;Document&quot; and &quot;Topic&quot;</span>
<span class="sd">                       that contains all documents with each corresponding</span>
<span class="sd">                       topic.</span>
<span class="sd">            c_tf_idf: A c-TF-IDF representation that is typically</span>
<span class="sd">                      identical to `topic_model.c_tf_idf_` except for</span>
<span class="sd">                      dynamic, class-based, and hierarchical topic modeling</span>
<span class="sd">                      where it is calculated on a subset of the documents.</span>
<span class="sd">            topics: A dictionary with topic (key) and tuple of word and</span>
<span class="sd">                    weight (value) as calculated by c-TF-IDF. This is the</span>
<span class="sd">                    default topics that are returned if no representation</span>
<span class="sd">                    model is used.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">topic_representations_</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.BaseRepresentation.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.BaseRepresentation.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topics.</p>
<p>Each representation model that inherits this class will have
its arguments (topic_model, documents, c_tf_idf, topics)
automatically passed. Therefore, the representation model
will only have access to the information about topics related
to those arguments.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The BERTopic model that is fitted until topic
         representations are calculated.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dataframe with columns "Document" and "Topic"
       that contains all documents with each corresponding
       topic.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A c-TF-IDF representation that is typically
      identical to <code>topic_model.c_tf_idf_</code> except for
      dynamic, class-based, and hierarchical topic modeling
      where it is calculated on a subset of the documents.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary with topic (key) and tuple of word and
    weight (value) as calculated by c-TF-IDF. This is the
    default topics that are returned if no representation
    model is used.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_base.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">    Each representation model that inherits this class will have</span>
<span class="sd">    its arguments (topic_model, documents, c_tf_idf, topics)</span>
<span class="sd">    automatically passed. Therefore, the representation model</span>
<span class="sd">    will only have access to the information about topics related</span>
<span class="sd">    to those arguments.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: The BERTopic model that is fitted until topic</span>
<span class="sd">                     representations are calculated.</span>
<span class="sd">        documents: A dataframe with columns &quot;Document&quot; and &quot;Topic&quot;</span>
<span class="sd">                   that contains all documents with each corresponding</span>
<span class="sd">                   topic.</span>
<span class="sd">        c_tf_idf: A c-TF-IDF representation that is typically</span>
<span class="sd">                  identical to `topic_model.c_tf_idf_` except for</span>
<span class="sd">                  dynamic, class-based, and hierarchical topic modeling</span>
<span class="sd">                  where it is calculated on a subset of the documents.</span>
<span class="sd">        topics: A dictionary with topic (key) and tuple of word and</span>
<span class="sd">                weight (value) as calculated by c-TF-IDF. This is the</span>
<span class="sd">                default topics that are returned if no representation</span>
<span class="sd">                model is used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">topic_representations_</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.Cohere" class="doc doc-heading">
            <code>Cohere</code>


<a href="#bertopic.representation.Cohere" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>Use the Cohere API to generate topic labels based on their
generative model.</p>
<p>Find more about their models here:
https://docs.cohere.ai/docs</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>client</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A <code>cohere.Client</code></p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model to use within Cohere, defaults to <code>"xlarge"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;command-r&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The prompt to be used in the model. If no prompt is given,
    <code>self.default_prompt_</code> is used instead.
    NOTE: Use <code>"[KEYWORDS]"</code> and <code>"[DOCUMENTS]"</code> in the prompt
    to decide where the keywords and documents need to be
    inserted.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>system_prompt</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The system prompt to be used in the model. If no system prompt is given,
           <code>self.default_system_prompt_</code> is used instead.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delay_in_seconds</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The delay in seconds between consecutive prompts
                    in order to prevent RateLimitErrors.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nr_docs</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of documents to pass to OpenAI if a prompt
     with the <code>["DOCUMENTS"]</code> tag is used.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>diversity</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The diversity of documents to pass to OpenAI.
       Accepts values between 0 and 1. A higher
       values results in passing more diverse documents
       whereas lower values passes more similar documents.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>doc_length</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The maximum length of each document. If a document is longer,
        it will be truncated. If None, the entire document is passed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tokenizer used to calculate to split the document into segments
       used to count the length of a document.
           * If tokenizer is 'char', then the document is split up
             into characters which are counted to adhere to <code>doc_length</code>
           * If tokenizer is 'whitespace', the document is split up
             into words separated by whitespaces. These words are counted
             and truncated depending on <code>doc_length</code>
           * If tokenizer is 'vectorizer', then the internal CountVectorizer
             is used to tokenize the document. These tokens are counted
             and truncated depending on <code>doc_length</code>
           * If tokenizer is a callable, then that callable is used to tokenize
             the document. These tokens are counted and truncated depending
             on <code>doc_length</code></p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<p>To use this, you will need to install cohere first:</p>
<p><code>pip install cohere</code></p>
<p>Then, get yourself an API key and use Cohere's API as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">cohere</span>
<span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">Cohere</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1"># Create your representation model</span>
<span class="n">co</span> <span class="o">=</span> <span class="n">cohere</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">my_api_key</span><span class="p">)</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">Cohere</span><span class="p">(</span><span class="n">co</span><span class="p">)</span>

<span class="c1"># Use the representation model in BERTopic on top of the default pipeline</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>
<p>You can also use a custom prompt:</p>
<div class="highlight"><pre><span></span><code><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;I have the following documents: [DOCUMENTS]. What topic do they contain?&quot;</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">Cohere</span><span class="p">(</span><span class="n">co</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_cohere.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Cohere</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Use the Cohere API to generate topic labels based on their</span>
<span class="sd">    generative model.</span>

<span class="sd">    Find more about their models here:</span>
<span class="sd">    https://docs.cohere.ai/docs</span>

<span class="sd">    Arguments:</span>
<span class="sd">        client: A `cohere.Client`</span>
<span class="sd">        model: Model to use within Cohere, defaults to `&quot;xlarge&quot;`.</span>
<span class="sd">        prompt: The prompt to be used in the model. If no prompt is given,</span>
<span class="sd">                `self.default_prompt_` is used instead.</span>
<span class="sd">                NOTE: Use `&quot;[KEYWORDS]&quot;` and `&quot;[DOCUMENTS]&quot;` in the prompt</span>
<span class="sd">                to decide where the keywords and documents need to be</span>
<span class="sd">                inserted.</span>
<span class="sd">        system_prompt: The system prompt to be used in the model. If no system prompt is given,</span>
<span class="sd">                       `self.default_system_prompt_` is used instead.</span>
<span class="sd">        delay_in_seconds: The delay in seconds between consecutive prompts</span>
<span class="sd">                                in order to prevent RateLimitErrors.</span>
<span class="sd">        nr_docs: The number of documents to pass to OpenAI if a prompt</span>
<span class="sd">                 with the `[&quot;DOCUMENTS&quot;]` tag is used.</span>
<span class="sd">        diversity: The diversity of documents to pass to OpenAI.</span>
<span class="sd">                   Accepts values between 0 and 1. A higher</span>
<span class="sd">                   values results in passing more diverse documents</span>
<span class="sd">                   whereas lower values passes more similar documents.</span>
<span class="sd">        doc_length: The maximum length of each document. If a document is longer,</span>
<span class="sd">                    it will be truncated. If None, the entire document is passed.</span>
<span class="sd">        tokenizer: The tokenizer used to calculate to split the document into segments</span>
<span class="sd">                   used to count the length of a document.</span>
<span class="sd">                       * If tokenizer is &#39;char&#39;, then the document is split up</span>
<span class="sd">                         into characters which are counted to adhere to `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;whitespace&#39;, the document is split up</span>
<span class="sd">                         into words separated by whitespaces. These words are counted</span>
<span class="sd">                         and truncated depending on `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;vectorizer&#39;, then the internal CountVectorizer</span>
<span class="sd">                         is used to tokenize the document. These tokens are counted</span>
<span class="sd">                         and truncated depending on `doc_length`</span>
<span class="sd">                       * If tokenizer is a callable, then that callable is used to tokenize</span>
<span class="sd">                         the document. These tokens are counted and truncated depending</span>
<span class="sd">                         on `doc_length`</span>

<span class="sd">    Usage:</span>

<span class="sd">    To use this, you will need to install cohere first:</span>

<span class="sd">    `pip install cohere`</span>

<span class="sd">    Then, get yourself an API key and use Cohere&#39;s API as follows:</span>

<span class="sd">    ```python</span>
<span class="sd">    import cohere</span>
<span class="sd">    from bertopic.representation import Cohere</span>
<span class="sd">    from bertopic import BERTopic</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    co = cohere.Client(my_api_key)</span>
<span class="sd">    representation_model = Cohere(co)</span>

<span class="sd">    # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">    ```</span>

<span class="sd">    You can also use a custom prompt:</span>

<span class="sd">    ```python</span>
<span class="sd">    prompt = &quot;I have the following documents: [DOCUMENTS]. What topic do they contain?&quot;</span>
<span class="sd">    representation_model = Cohere(co, prompt=prompt)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">client</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;command-r&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">delay_in_seconds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">nr_docs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">diversity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">doc_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">client</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span> <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">system_prompt</span> <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_SYSTEM_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_prompt_</span> <span class="o">=</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_system_prompt_</span> <span class="o">=</span> <span class="n">DEFAULT_SYSTEM_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span> <span class="o">=</span> <span class="n">delay_in_seconds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span> <span class="o">=</span> <span class="n">nr_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span> <span class="o">=</span> <span class="n">diversity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span> <span class="o">=</span> <span class="n">doc_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">validate_truncate_document_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: Not used</span>
<span class="sd">            documents: Not used</span>
<span class="sd">            c_tf_idf: Not used</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Extract the top 4 representative documents per topic</span>
        <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
            <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
        <span class="p">)</span>

        <span class="c1"># Generate using Cohere&#39;s Language Model</span>
        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
            <span class="n">truncated_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">truncated_docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

            <span class="c1"># Delay</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">:</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">)</span>

            <span class="n">request</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="n">preamble</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">,</span>
                <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
                <span class="n">max_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                <span class="n">stop_sequences</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">updated_topics</span>

    <span class="k">def</span> <span class="nf">_create_prompt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">):</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Use the Default Chat Prompt</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">==</span> <span class="n">DEFAULT_PROMPT</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">)</span>

        <span class="c1"># Use a custom prompt that leverages keywords, documents or both using</span>
        <span class="c1"># custom tags, namely [KEYWORDS] and [DOCUMENTS] respectively</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span>
            <span class="k">if</span> <span class="s2">&quot;[KEYWORDS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
            <span class="k">if</span> <span class="s2">&quot;[DOCUMENTS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">prompt</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">):</span>
        <span class="n">to_replace</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
            <span class="n">to_replace</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;- </span><span class="si">{</span><span class="n">doc</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[DOCUMENTS]&quot;</span><span class="p">,</span> <span class="n">to_replace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prompt</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.Cohere.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.Cohere.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topics.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_cohere.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: Not used</span>
<span class="sd">        documents: Not used</span>
<span class="sd">        c_tf_idf: Not used</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract the top 4 representative documents per topic</span>
    <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
        <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
    <span class="p">)</span>

    <span class="c1"># Generate using Cohere&#39;s Language Model</span>
    <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
        <span class="n">truncated_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">truncated_docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

        <span class="c1"># Delay</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">:</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">)</span>

        <span class="n">request</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">preamble</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">,</span>
            <span class="n">message</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">stop_sequences</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.KeyBERTInspired" class="doc doc-heading">
            <code>KeyBERTInspired</code>


<a href="#bertopic.representation.KeyBERTInspired" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>







              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_keybert.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">KeyBERTInspired</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">top_n_words</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">nr_repr_docs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">nr_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
        <span class="n">nr_candidate_words</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Use a KeyBERT-like model to fine-tune the topic representations.</span>

<span class="sd">        The algorithm follows KeyBERT but does some optimization in</span>
<span class="sd">        order to speed up inference.</span>

<span class="sd">        The steps are as follows. First, we extract the top n representative</span>
<span class="sd">        documents per topic. To extract the representative documents, we</span>
<span class="sd">        randomly sample a number of candidate documents per cluster</span>
<span class="sd">        which is controlled by the `nr_samples` parameter. Then,</span>
<span class="sd">        the top n representative documents  are extracted by calculating</span>
<span class="sd">        the c-TF-IDF representation for the  candidate documents and finding,</span>
<span class="sd">        through cosine similarity, which are closest to the topic c-TF-IDF representation.</span>
<span class="sd">        Next, the top n words per topic are extracted based on their</span>
<span class="sd">        c-TF-IDF representation, which is controlled by the `nr_repr_docs`</span>
<span class="sd">        parameter.</span>

<span class="sd">        Then, we extract the embeddings for words and representative documents</span>
<span class="sd">        and create topic embeddings by averaging the representative documents.</span>
<span class="sd">        Finally, the most similar words to each topic are extracted by</span>
<span class="sd">        calculating the cosine similarity between word and topic embeddings.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            top_n_words: The top n words to extract per topic.</span>
<span class="sd">            nr_repr_docs: The number of representative documents to extract per cluster.</span>
<span class="sd">            nr_samples: The number of candidate documents to extract per cluster.</span>
<span class="sd">            nr_candidate_words: The number of candidate words per cluster.</span>
<span class="sd">            random_state: The random state for randomly sampling candidate documents.</span>

<span class="sd">        Usage:</span>

<span class="sd">        ```python</span>
<span class="sd">        from bertopic.representation import KeyBERTInspired</span>
<span class="sd">        from bertopic import BERTopic</span>

<span class="sd">        # Create your representation model</span>
<span class="sd">        representation_model = KeyBERTInspired()</span>

<span class="sd">        # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">        topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="o">=</span> <span class="n">top_n_words</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_repr_docs</span> <span class="o">=</span> <span class="n">nr_repr_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_samples</span> <span class="o">=</span> <span class="n">nr_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_candidate_words</span> <span class="o">=</span> <span class="n">nr_candidate_words</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            documents: All input documents</span>
<span class="sd">            c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We extract the top n representative documents per class</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">representative_docs</span><span class="p">,</span> <span class="n">repr_doc_indices</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
            <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_repr_docs</span>
        <span class="p">)</span>

        <span class="c1"># We extract the top n words per class</span>
        <span class="n">topics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_candidate_words</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>

        <span class="c1"># We calculate the similarity between word and document embeddings and create</span>
        <span class="c1"># topic embeddings from the representative document embeddings</span>
        <span class="n">sim_matrix</span><span class="p">,</span> <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="n">representative_docs</span><span class="p">,</span> <span class="n">repr_doc_indices</span><span class="p">)</span>

        <span class="c1"># Find the best matching words based on the similarity matrix for each topic</span>
        <span class="n">updated_topics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_top_words</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="n">sim_matrix</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">updated_topics</span>

    <span class="k">def</span> <span class="nf">_extract_candidate_words</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;For each topic, extract candidate words based on the c-TF-IDF</span>
<span class="sd">        representation.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">            topics: The top words per topic</span>

<span class="sd">        Returns:</span>
<span class="sd">            topics: The `self.top_n_words` per topic</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()))]</span>

        <span class="c1"># Scikit-Learn Deprecation: get_feature_names is deprecated in 1.0</span>
        <span class="c1"># and will be removed in 1.2. Please use get_feature_names_out instead.</span>
        <span class="k">if</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;1.0.0&quot;</span><span class="p">):</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">vectorizer_model</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">vectorizer_model</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_top_n_idx_sparse</span><span class="p">(</span><span class="n">c_tf_idf</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_candidate_words</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_top_n_values_sparse</span><span class="p">(</span><span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
        <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">sorted_indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">take_along_axis</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">sorted_indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Get top 30 words per topic based on c-TF-IDF score</span>
        <span class="n">topics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">label</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">word_index</span><span class="p">],</span> <span class="n">score</span><span class="p">)</span> <span class="k">if</span> <span class="n">word_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mf">0.00001</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">word_index</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">index</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">scores</span><span class="p">[</span><span class="n">index</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">]</span>
            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="n">topics</span> <span class="o">=</span> <span class="p">{</span><span class="n">label</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">values</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_candidate_words</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="k">return</span> <span class="n">topics</span>

    <span class="k">def</span> <span class="nf">_extract_embeddings</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
        <span class="n">representative_docs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">repr_doc_indices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract the representative document embeddings and create topic embeddings.</span>
<span class="sd">        Then extract word embeddings and calculate the cosine similarity between topic</span>
<span class="sd">        embeddings and the word embeddings. Topic embeddings are the average of</span>
<span class="sd">        representative document embeddings.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            topics: The top words per topic</span>
<span class="sd">            representative_docs: A flat list of representative documents</span>
<span class="sd">            repr_doc_indices: The indices of representative documents</span>
<span class="sd">                              that belong to each topic</span>

<span class="sd">        Returns:</span>
<span class="sd">            sim: The similarity matrix between word and topic embeddings</span>
<span class="sd">            vocab: The complete vocabulary of input documents</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Calculate representative docs embeddings and create topic embeddings</span>
        <span class="n">repr_embeddings</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="n">representative_docs</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;document&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">topic_embeddings</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">repr_embeddings</span><span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="n">i</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">repr_doc_indices</span><span class="p">]</span>

        <span class="c1"># Calculate word embeddings and extract best matching with updated topic_embeddings</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="n">word</span> <span class="k">for</span> <span class="n">words</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]))</span>
        <span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;document&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">sim</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">topic_embeddings</span><span class="p">,</span> <span class="n">word_embeddings</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">sim</span><span class="p">,</span> <span class="n">vocab</span>

    <span class="k">def</span> <span class="nf">_extract_top_words</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vocab</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
        <span class="n">sim</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract the top n words per topic based on the</span>
<span class="sd">        similarity matrix between topics and words.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            vocab: The complete vocabulary of input documents</span>
<span class="sd">            labels: All topic labels</span>
<span class="sd">            topics: The top words per topic</span>
<span class="sd">            sim: The similarity matrix between word and topic embeddings</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: The updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()))]</span>
        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">topic</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]]</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">sim</span><span class="p">[:,</span> <span class="n">indices</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
            <span class="n">word_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">values</span><span class="p">)[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="p">:]]</span>
            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">values</span><span class="p">)[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="p">:],</span> <span class="n">word_indices</span><span class="p">)</span>
            <span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.KeyBERTInspired.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">top_n_words</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">nr_repr_docs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">nr_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">nr_candidate_words</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span></code>

<a href="#bertopic.representation.KeyBERTInspired.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Use a KeyBERT-like model to fine-tune the topic representations.</p>
<p>The algorithm follows KeyBERT but does some optimization in
order to speed up inference.</p>
<p>The steps are as follows. First, we extract the top n representative
documents per topic. To extract the representative documents, we
randomly sample a number of candidate documents per cluster
which is controlled by the <code>nr_samples</code> parameter. Then,
the top n representative documents  are extracted by calculating
the c-TF-IDF representation for the  candidate documents and finding,
through cosine similarity, which are closest to the topic c-TF-IDF representation.
Next, the top n words per topic are extracted based on their
c-TF-IDF representation, which is controlled by the <code>nr_repr_docs</code>
parameter.</p>
<p>Then, we extract the embeddings for words and representative documents
and create topic embeddings by averaging the representative documents.
Finally, the most similar words to each topic are extracted by
calculating the cosine similarity between word and topic embeddings.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>top_n_words</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The top n words to extract per topic.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nr_repr_docs</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of representative documents to extract per cluster.</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nr_samples</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of candidate documents to extract per cluster.</p>
              </div>
            </td>
            <td>
                  <code>500</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nr_candidate_words</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of candidate words per cluster.</p>
              </div>
            </td>
            <td>
                  <code>100</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>random_state</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The random state for randomly sampling candidate documents.</p>
              </div>
            </td>
            <td>
                  <code>42</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">KeyBERTInspired</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1"># Create your representation model</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">KeyBERTInspired</span><span class="p">()</span>

<span class="c1"># Use the representation model in BERTopic on top of the default pipeline</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_keybert.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">top_n_words</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">nr_repr_docs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="n">nr_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
    <span class="n">nr_candidate_words</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Use a KeyBERT-like model to fine-tune the topic representations.</span>

<span class="sd">    The algorithm follows KeyBERT but does some optimization in</span>
<span class="sd">    order to speed up inference.</span>

<span class="sd">    The steps are as follows. First, we extract the top n representative</span>
<span class="sd">    documents per topic. To extract the representative documents, we</span>
<span class="sd">    randomly sample a number of candidate documents per cluster</span>
<span class="sd">    which is controlled by the `nr_samples` parameter. Then,</span>
<span class="sd">    the top n representative documents  are extracted by calculating</span>
<span class="sd">    the c-TF-IDF representation for the  candidate documents and finding,</span>
<span class="sd">    through cosine similarity, which are closest to the topic c-TF-IDF representation.</span>
<span class="sd">    Next, the top n words per topic are extracted based on their</span>
<span class="sd">    c-TF-IDF representation, which is controlled by the `nr_repr_docs`</span>
<span class="sd">    parameter.</span>

<span class="sd">    Then, we extract the embeddings for words and representative documents</span>
<span class="sd">    and create topic embeddings by averaging the representative documents.</span>
<span class="sd">    Finally, the most similar words to each topic are extracted by</span>
<span class="sd">    calculating the cosine similarity between word and topic embeddings.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        top_n_words: The top n words to extract per topic.</span>
<span class="sd">        nr_repr_docs: The number of representative documents to extract per cluster.</span>
<span class="sd">        nr_samples: The number of candidate documents to extract per cluster.</span>
<span class="sd">        nr_candidate_words: The number of candidate words per cluster.</span>
<span class="sd">        random_state: The random state for randomly sampling candidate documents.</span>

<span class="sd">    Usage:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic.representation import KeyBERTInspired</span>
<span class="sd">    from bertopic import BERTopic</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    representation_model = KeyBERTInspired()</span>

<span class="sd">    # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="o">=</span> <span class="n">top_n_words</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nr_repr_docs</span> <span class="o">=</span> <span class="n">nr_repr_docs</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nr_samples</span> <span class="o">=</span> <span class="n">nr_samples</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">nr_candidate_words</span> <span class="o">=</span> <span class="n">nr_candidate_words</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.KeyBERTInspired.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.KeyBERTInspired.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topics.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A BERTopic model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>All input documents</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The topic c-TF-IDF representation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_keybert.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: A BERTopic model</span>
<span class="sd">        documents: All input documents</span>
<span class="sd">        c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># We extract the top n representative documents per class</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">representative_docs</span><span class="p">,</span> <span class="n">repr_doc_indices</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
        <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_repr_docs</span>
    <span class="p">)</span>

    <span class="c1"># We extract the top n words per class</span>
    <span class="n">topics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_candidate_words</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>

    <span class="c1"># We calculate the similarity between word and document embeddings and create</span>
    <span class="c1"># topic embeddings from the representative document embeddings</span>
    <span class="n">sim_matrix</span><span class="p">,</span> <span class="n">words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="n">representative_docs</span><span class="p">,</span> <span class="n">repr_doc_indices</span><span class="p">)</span>

    <span class="c1"># Find the best matching words based on the similarity matrix for each topic</span>
    <span class="n">updated_topics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extract_top_words</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="n">sim_matrix</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.LangChain" class="doc doc-heading">
            <code>LangChain</code>


<a href="#bertopic.representation.LangChain" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>Using chains in langchain to generate topic labels.</p>
<p>The classic example uses <code>langchain.chains.question_answering.load_qa_chain</code>.
This returns a chain that takes a list of documents and a question as input.</p>
<p>You can also use Runnables such as those composed using the LangChain Expression Language.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>chain</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The langchain chain or Runnable with a <code>batch</code> method.
   Input keys must be <code>input_documents</code> and <code>question</code>.
   Output key must be <code>output_text</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The prompt to be used in the model. If no prompt is given,
    <code>self.default_prompt_</code> is used instead.
     NOTE: Use <code>"[KEYWORDS]"</code> in the prompt
     to decide where the keywords need to be
     inserted. Keywords won't be included unless
     indicated. Unlike other representation models,
     Langchain does not use the <code>"[DOCUMENTS]"</code> tag
     to insert documents into the prompt. The load_qa_chain function
     formats the representative documents within the prompt.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nr_docs</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of documents to pass to LangChain</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>diversity</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The diversity of documents to pass to LangChain.
       Accepts values between 0 and 1. A higher
       values results in passing more diverse documents
       whereas lower values passes more similar documents.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>doc_length</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The maximum length of each document. If a document is longer,
        it will be truncated. If None, the entire document is passed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tokenizer used to calculate to split the document into segments
       used to count the length of a document.
           * If tokenizer is 'char', then the document is split up
             into characters which are counted to adhere to <code>doc_length</code>
           * If tokenizer is 'whitespace', the document is split up
             into words separated by whitespaces. These words are counted
             and truncated depending on <code>doc_length</code>
           * If tokenizer is 'vectorizer', then the internal CountVectorizer
             is used to tokenize the document. These tokens are counted
             and truncated depending on <code>doc_length</code>. They are decoded with
             whitespaces.
           * If tokenizer is a callable, then that callable is used to tokenize
             the document. These tokens are counted and truncated depending
             on <code>doc_length</code></p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>chain_config</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The configuration for the langchain chain. Can be used to set options
          like max_concurrency to avoid rate limiting errors.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<p>To use this, you will need to install the langchain package first.
Additionally, you will need an underlying LLM to support langchain,
like openai:</p>
<p><code>pip install langchain</code>
<code>pip install openai</code></p>
<p>Then, you can create your chain as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.chains.question_answering</span> <span class="kn">import</span> <span class="n">load_qa_chain</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">load_qa_chain</span><span class="p">(</span><span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">openai_api_key</span><span class="o">=</span><span class="n">my_openai_api_key</span><span class="p">),</span> <span class="n">chain_type</span><span class="o">=</span><span class="s2">&quot;stuff&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Finally, you can pass the chain to BERTopic as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">LangChain</span>

<span class="c1"># Create your representation model</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">LangChain</span><span class="p">(</span><span class="n">chain</span><span class="p">)</span>

<span class="c1"># Use the representation model in BERTopic on top of the default pipeline</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>
<p>You can also use a custom prompt:</p>
<div class="highlight"><pre><span></span><code><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;What are these documents about? Please give a single label.&quot;</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">LangChain</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
</code></pre></div>
<p>You can also use a Runnable instead of a chain.
The example below uses the LangChain Expression Language:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">LangChain</span>
<span class="kn">from</span> <span class="nn">langchain.chains.question_answering</span> <span class="kn">import</span> <span class="n">load_qa_chain</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatAnthropic</span>
<span class="kn">from</span> <span class="nn">langchain.schema.document</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">langchain.schema.runnable</span> <span class="kn">import</span> <span class="n">RunnablePassthrough</span>
<span class="kn">from</span> <span class="nn">langchain_experimental.data_anonymizer.presidio</span> <span class="kn">import</span> <span class="n">PresidioReversibleAnonymizer</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">llm</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># We will construct a special privacy-preserving chain using Microsoft Presidio</span>

<span class="n">pii_handler</span> <span class="o">=</span> <span class="n">PresidioReversibleAnonymizer</span><span class="p">(</span><span class="n">analyzed_fields</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;PERSON&quot;</span><span class="p">])</span>

<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;input_documents&quot;</span><span class="p">:</span> <span class="p">(</span>
            <span class="k">lambda</span> <span class="n">inp</span><span class="p">:</span> <span class="p">[</span>
                <span class="n">Document</span><span class="p">(</span>
                    <span class="n">page_content</span><span class="o">=</span><span class="n">pii_handler</span><span class="o">.</span><span class="n">anonymize</span><span class="p">(</span>
                        <span class="n">d</span><span class="o">.</span><span class="n">page_content</span><span class="p">,</span>
                        <span class="n">language</span><span class="o">=</span><span class="s2">&quot;en&quot;</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">inp</span><span class="p">[</span><span class="s2">&quot;input_documents&quot;</span><span class="p">]</span>
            <span class="p">]</span>
        <span class="p">),</span>
        <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">(),</span>
    <span class="p">}</span>
    <span class="o">|</span> <span class="n">load_qa_chain</span><span class="p">(</span><span class="n">representation_llm</span><span class="p">,</span> <span class="n">chain_type</span><span class="o">=</span><span class="s2">&quot;stuff&quot;</span><span class="p">)</span>
    <span class="o">|</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">output</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;output_text&quot;</span><span class="p">:</span> <span class="n">pii_handler</span><span class="o">.</span><span class="n">deanonymize</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s2">&quot;output_text&quot;</span><span class="p">])})</span>
<span class="p">)</span>

<span class="n">representation_model</span> <span class="o">=</span> <span class="n">LangChain</span><span class="p">(</span><span class="n">chain</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">representation_prompt</span><span class="p">)</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_langchain.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LangChain</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Using chains in langchain to generate topic labels.</span>

<span class="sd">    The classic example uses `langchain.chains.question_answering.load_qa_chain`.</span>
<span class="sd">    This returns a chain that takes a list of documents and a question as input.</span>

<span class="sd">    You can also use Runnables such as those composed using the LangChain Expression Language.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        chain: The langchain chain or Runnable with a `batch` method.</span>
<span class="sd">               Input keys must be `input_documents` and `question`.</span>
<span class="sd">               Output key must be `output_text`.</span>
<span class="sd">        prompt: The prompt to be used in the model. If no prompt is given,</span>
<span class="sd">                `self.default_prompt_` is used instead.</span>
<span class="sd">                 NOTE: Use `&quot;[KEYWORDS]&quot;` in the prompt</span>
<span class="sd">                 to decide where the keywords need to be</span>
<span class="sd">                 inserted. Keywords won&#39;t be included unless</span>
<span class="sd">                 indicated. Unlike other representation models,</span>
<span class="sd">                 Langchain does not use the `&quot;[DOCUMENTS]&quot;` tag</span>
<span class="sd">                 to insert documents into the prompt. The load_qa_chain function</span>
<span class="sd">                 formats the representative documents within the prompt.</span>
<span class="sd">        nr_docs: The number of documents to pass to LangChain</span>
<span class="sd">        diversity: The diversity of documents to pass to LangChain.</span>
<span class="sd">                   Accepts values between 0 and 1. A higher</span>
<span class="sd">                   values results in passing more diverse documents</span>
<span class="sd">                   whereas lower values passes more similar documents.</span>
<span class="sd">        doc_length: The maximum length of each document. If a document is longer,</span>
<span class="sd">                    it will be truncated. If None, the entire document is passed.</span>
<span class="sd">        tokenizer: The tokenizer used to calculate to split the document into segments</span>
<span class="sd">                   used to count the length of a document.</span>
<span class="sd">                       * If tokenizer is &#39;char&#39;, then the document is split up</span>
<span class="sd">                         into characters which are counted to adhere to `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;whitespace&#39;, the document is split up</span>
<span class="sd">                         into words separated by whitespaces. These words are counted</span>
<span class="sd">                         and truncated depending on `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;vectorizer&#39;, then the internal CountVectorizer</span>
<span class="sd">                         is used to tokenize the document. These tokens are counted</span>
<span class="sd">                         and truncated depending on `doc_length`. They are decoded with</span>
<span class="sd">                         whitespaces.</span>
<span class="sd">                       * If tokenizer is a callable, then that callable is used to tokenize</span>
<span class="sd">                         the document. These tokens are counted and truncated depending</span>
<span class="sd">                         on `doc_length`</span>
<span class="sd">        chain_config: The configuration for the langchain chain. Can be used to set options</span>
<span class="sd">                      like max_concurrency to avoid rate limiting errors.</span>
<span class="sd">    Usage:</span>

<span class="sd">    To use this, you will need to install the langchain package first.</span>
<span class="sd">    Additionally, you will need an underlying LLM to support langchain,</span>
<span class="sd">    like openai:</span>

<span class="sd">    `pip install langchain`</span>
<span class="sd">    `pip install openai`</span>

<span class="sd">    Then, you can create your chain as follows:</span>

<span class="sd">    ```python</span>
<span class="sd">    from langchain.chains.question_answering import load_qa_chain</span>
<span class="sd">    from langchain.llms import OpenAI</span>
<span class="sd">    chain = load_qa_chain(OpenAI(temperature=0, openai_api_key=my_openai_api_key), chain_type=&quot;stuff&quot;)</span>
<span class="sd">    ```</span>

<span class="sd">    Finally, you can pass the chain to BERTopic as follows:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic.representation import LangChain</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    representation_model = LangChain(chain)</span>

<span class="sd">    # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">    ```</span>

<span class="sd">    You can also use a custom prompt:</span>

<span class="sd">    ```python</span>
<span class="sd">    prompt = &quot;What are these documents about? Please give a single label.&quot;</span>
<span class="sd">    representation_model = LangChain(chain, prompt=prompt)</span>
<span class="sd">    ```</span>

<span class="sd">    You can also use a Runnable instead of a chain.</span>
<span class="sd">    The example below uses the LangChain Expression Language:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic.representation import LangChain</span>
<span class="sd">    from langchain.chains.question_answering import load_qa_chain</span>
<span class="sd">    from langchain.chat_models import ChatAnthropic</span>
<span class="sd">    from langchain.schema.document import Document</span>
<span class="sd">    from langchain.schema.runnable import RunnablePassthrough</span>
<span class="sd">    from langchain_experimental.data_anonymizer.presidio import PresidioReversibleAnonymizer</span>

<span class="sd">    prompt = ...</span>
<span class="sd">    llm = ...</span>

<span class="sd">    # We will construct a special privacy-preserving chain using Microsoft Presidio</span>

<span class="sd">    pii_handler = PresidioReversibleAnonymizer(analyzed_fields=[&quot;PERSON&quot;])</span>

<span class="sd">    chain = (</span>
<span class="sd">        {</span>
<span class="sd">            &quot;input_documents&quot;: (</span>
<span class="sd">                lambda inp: [</span>
<span class="sd">                    Document(</span>
<span class="sd">                        page_content=pii_handler.anonymize(</span>
<span class="sd">                            d.page_content,</span>
<span class="sd">                            language=&quot;en&quot;,</span>
<span class="sd">                        ),</span>
<span class="sd">                    )</span>
<span class="sd">                    for d in inp[&quot;input_documents&quot;]</span>
<span class="sd">                ]</span>
<span class="sd">            ),</span>
<span class="sd">            &quot;question&quot;: RunnablePassthrough(),</span>
<span class="sd">        }</span>
<span class="sd">        | load_qa_chain(representation_llm, chain_type=&quot;stuff&quot;)</span>
<span class="sd">        | (lambda output: {&quot;output_text&quot;: pii_handler.deanonymize(output[&quot;output_text&quot;])})</span>
<span class="sd">    )</span>

<span class="sd">    representation_model = LangChain(chain, prompt=representation_prompt)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">chain</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">nr_docs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">diversity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">doc_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">chain_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chain</span> <span class="o">=</span> <span class="n">chain</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span> <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_prompt_</span> <span class="o">=</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chain_config</span> <span class="o">=</span> <span class="n">chain_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span> <span class="o">=</span> <span class="n">nr_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span> <span class="o">=</span> <span class="n">diversity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span> <span class="o">=</span> <span class="n">doc_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">validate_truncate_document_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            documents: All input documents</span>
<span class="sd">            c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Extract the top 4 representative documents per topic</span>
        <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
            <span class="n">c_tf_idf</span><span class="o">=</span><span class="n">c_tf_idf</span><span class="p">,</span>
            <span class="n">documents</span><span class="o">=</span><span class="n">documents</span><span class="p">,</span>
            <span class="n">topics</span><span class="o">=</span><span class="n">topics</span><span class="p">,</span>
            <span class="n">nr_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
            <span class="n">nr_repr_docs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span>
            <span class="n">diversity</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">diversity</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Generate label using langchain&#39;s batch functionality</span>
        <span class="n">chain_docs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span>
                <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">))</span>
                <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span>
            <span class="p">]</span>
            <span class="k">for</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
        <span class="p">]</span>

        <span class="c1"># `self.chain` must take `input_documents` and `question` as input keys</span>
        <span class="c1"># Use a custom prompt that leverages keywords, using the tag: [KEYWORDS]</span>
        <span class="k">if</span> <span class="s2">&quot;[KEYWORDS]&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="p">:</span>
            <span class="n">prompts</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">:</span>
                <span class="n">keywords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
                <span class="n">prompts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;input_documents&quot;</span><span class="p">:</span> <span class="n">docs</span><span class="p">,</span> <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}</span> <span class="k">for</span> <span class="n">docs</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chain_docs</span><span class="p">,</span> <span class="n">prompts</span><span class="p">)]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;input_documents&quot;</span><span class="p">:</span> <span class="n">docs</span><span class="p">,</span> <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="p">}</span> <span class="k">for</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">chain_docs</span><span class="p">]</span>

        <span class="c1"># `self.chain` must return a dict with an `output_text` key</span>
        <span class="c1"># same output key as the `StuffDocumentsChain` returned by `load_qa_chain`</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">chain_config</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="p">[</span><span class="s2">&quot;output_text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>

        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">topic</span><span class="p">:</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)]</span> <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">labels</span><span class="p">)</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.LangChain.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.LangChain.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topics.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A BERTopic model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>All input documents</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The topic c-TF-IDF representation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, int]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_langchain.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: A BERTopic model</span>
<span class="sd">        documents: All input documents</span>
<span class="sd">        c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract the top 4 representative documents per topic</span>
    <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
        <span class="n">c_tf_idf</span><span class="o">=</span><span class="n">c_tf_idf</span><span class="p">,</span>
        <span class="n">documents</span><span class="o">=</span><span class="n">documents</span><span class="p">,</span>
        <span class="n">topics</span><span class="o">=</span><span class="n">topics</span><span class="p">,</span>
        <span class="n">nr_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">nr_repr_docs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span>
        <span class="n">diversity</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">diversity</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Generate label using langchain&#39;s batch functionality</span>
    <span class="n">chain_docs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Document</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[</span>
            <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
    <span class="p">]</span>

    <span class="c1"># `self.chain` must take `input_documents` and `question` as input keys</span>
    <span class="c1"># Use a custom prompt that leverages keywords, using the tag: [KEYWORDS]</span>
    <span class="k">if</span> <span class="s2">&quot;[KEYWORDS]&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="p">:</span>
        <span class="n">prompts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">:</span>
            <span class="n">keywords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
            <span class="n">prompts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;input_documents&quot;</span><span class="p">:</span> <span class="n">docs</span><span class="p">,</span> <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}</span> <span class="k">for</span> <span class="n">docs</span><span class="p">,</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">chain_docs</span><span class="p">,</span> <span class="n">prompts</span><span class="p">)]</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;input_documents&quot;</span><span class="p">:</span> <span class="n">docs</span><span class="p">,</span> <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="p">}</span> <span class="k">for</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">chain_docs</span><span class="p">]</span>

    <span class="c1"># `self.chain` must return a dict with an `output_text` key</span>
    <span class="c1"># same output key as the `StuffDocumentsChain` returned by `load_qa_chain`</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">chain_config</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="p">[</span><span class="s2">&quot;output_text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>

    <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">topic</span><span class="p">:</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)]</span> <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">labels</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.LiteLLM" class="doc doc-heading">
            <code>LiteLLM</code>


<a href="#bertopic.representation.LiteLLM" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>Using the LiteLLM API to generate topic labels.</p>
<div class="highlight"><pre><span></span><code>For an overview of models see:
https://docs.litellm.ai/docs/providers

Arguments:
    model: Model to use. Defaults to OpenAI&#39;s &quot;gpt-3.5-turbo&quot;.
    generator_kwargs: Kwargs passed to `litellm.completion`.
    prompt: The prompt to be used in the model. If no prompt is given,
            `self.default_prompt_` is used instead.
            NOTE: Use `&quot;[KEYWORDS]&quot;` and `&quot;[DOCUMENTS]&quot;` in the prompt
            to decide where the keywords and documents need to be
            inserted.
    delay_in_seconds: The delay in seconds between consecutive prompts
                      in order to prevent RateLimitErrors.
    exponential_backoff: Retry requests with a random exponential backoff.
                         A short sleep is used when a rate limit error is hit,
                         then the requests is retried. Increase the sleep length
                         if errors are hit until 10 unsuccesfull requests.
                         If True, overrides `delay_in_seconds`.
    nr_docs: The number of documents to pass to LiteLLM if a prompt
             with the `[&quot;DOCUMENTS&quot;]` tag is used.
    diversity: The diversity of documents to pass to LiteLLM.
               Accepts values between 0 and 1. A higher
               values results in passing more diverse documents
               whereas lower values passes more similar documents.

Usage:

To use this, you will need to install the litellm package first:

`pip install litellm`

Then, get yourself an API key of any provider (for instance OpenAI) and use it as follows:

```python
import os
from bertopic.representation import LiteLLM
from bertopic import BERTopic

# set ENV variables
os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-key&quot;

# Create your representation model
representation_model = LiteLLM(model=&quot;gpt-3.5-turbo&quot;)

# Use the representation model in BERTopic on top of the default pipeline
topic_model = BERTopic(representation_model=representation_model)
```

You can also use a custom prompt:

```python
prompt = &quot;I have the following documents: [DOCUMENTS]
</code></pre></div>
<p>These documents are about the following topic: '"
    representation_model = LiteLLM(model="gpt", prompt=prompt)
    ```</p>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_litellm.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LiteLLM</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Using the LiteLLM API to generate topic labels.</span>

<span class="sd">    For an overview of models see:</span>
<span class="sd">    https://docs.litellm.ai/docs/providers</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model: Model to use. Defaults to OpenAI&#39;s &quot;gpt-3.5-turbo&quot;.</span>
<span class="sd">        generator_kwargs: Kwargs passed to `litellm.completion`.</span>
<span class="sd">        prompt: The prompt to be used in the model. If no prompt is given,</span>
<span class="sd">                `self.default_prompt_` is used instead.</span>
<span class="sd">                NOTE: Use `&quot;[KEYWORDS]&quot;` and `&quot;[DOCUMENTS]&quot;` in the prompt</span>
<span class="sd">                to decide where the keywords and documents need to be</span>
<span class="sd">                inserted.</span>
<span class="sd">        delay_in_seconds: The delay in seconds between consecutive prompts</span>
<span class="sd">                          in order to prevent RateLimitErrors.</span>
<span class="sd">        exponential_backoff: Retry requests with a random exponential backoff.</span>
<span class="sd">                             A short sleep is used when a rate limit error is hit,</span>
<span class="sd">                             then the requests is retried. Increase the sleep length</span>
<span class="sd">                             if errors are hit until 10 unsuccesfull requests.</span>
<span class="sd">                             If True, overrides `delay_in_seconds`.</span>
<span class="sd">        nr_docs: The number of documents to pass to LiteLLM if a prompt</span>
<span class="sd">                 with the `[&quot;DOCUMENTS&quot;]` tag is used.</span>
<span class="sd">        diversity: The diversity of documents to pass to LiteLLM.</span>
<span class="sd">                   Accepts values between 0 and 1. A higher</span>
<span class="sd">                   values results in passing more diverse documents</span>
<span class="sd">                   whereas lower values passes more similar documents.</span>

<span class="sd">    Usage:</span>

<span class="sd">    To use this, you will need to install the litellm package first:</span>

<span class="sd">    `pip install litellm`</span>

<span class="sd">    Then, get yourself an API key of any provider (for instance OpenAI) and use it as follows:</span>

<span class="sd">    ```python</span>
<span class="sd">    import os</span>
<span class="sd">    from bertopic.representation import LiteLLM</span>
<span class="sd">    from bertopic import BERTopic</span>

<span class="sd">    # set ENV variables</span>
<span class="sd">    os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-key&quot;</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    representation_model = LiteLLM(model=&quot;gpt-3.5-turbo&quot;)</span>

<span class="sd">    # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">    ```</span>

<span class="sd">    You can also use a custom prompt:</span>

<span class="sd">    ```python</span>
<span class="sd">    prompt = &quot;I have the following documents: [DOCUMENTS] \nThese documents are about the following topic: &#39;&quot;</span>
<span class="sd">    representation_model = LiteLLM(model=&quot;gpt&quot;, prompt=prompt)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>  <span class="c1"># noqa: D301</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">generator_kwargs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
        <span class="n">delay_in_seconds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exponential_backoff</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">nr_docs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">diversity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span> <span class="k">if</span> <span class="n">prompt</span> <span class="k">else</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_prompt_</span> <span class="o">=</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span> <span class="o">=</span> <span class="n">delay_in_seconds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exponential_backoff</span> <span class="o">=</span> <span class="n">exponential_backoff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span> <span class="o">=</span> <span class="n">nr_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span> <span class="o">=</span> <span class="n">diversity</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span> <span class="o">=</span> <span class="n">generator_kwargs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">generator_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span> <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            documents: All input documents</span>
<span class="sd">            c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Extract the top n representative documents per topic</span>
        <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
            <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
        <span class="p">)</span>

        <span class="c1"># Generate using a (Large) Language Model</span>
        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>

            <span class="c1"># Delay</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">:</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">)</span>

            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">},</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
            <span class="p">]</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="p">}</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponential_backoff</span><span class="p">:</span>
                <span class="n">response</span> <span class="o">=</span> <span class="n">chat_completions_with_backoff</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">response</span> <span class="o">=</span> <span class="n">completion</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;message&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;topic: &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">updated_topics</span>

    <span class="k">def</span> <span class="nf">_create_prompt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">):</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Use the Default Chat Prompt</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">==</span> <span class="n">DEFAULT_PROMPT</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">)</span>

        <span class="c1"># Use a custom prompt that leverages keywords, documents or both using</span>
        <span class="c1"># custom tags, namely [KEYWORDS] and [DOCUMENTS] respectively</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span>
            <span class="k">if</span> <span class="s2">&quot;[KEYWORDS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
            <span class="k">if</span> <span class="s2">&quot;[DOCUMENTS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">prompt</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">):</span>
        <span class="n">to_replace</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
            <span class="n">to_replace</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;- </span><span class="si">{</span><span class="n">doc</span><span class="p">[:</span><span class="mi">255</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[DOCUMENTS]&quot;</span><span class="p">,</span> <span class="n">to_replace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prompt</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.LiteLLM.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.LiteLLM.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topics.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A BERTopic model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>All input documents</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The topic c-TF-IDF representation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_litellm.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span> <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: A BERTopic model</span>
<span class="sd">        documents: All input documents</span>
<span class="sd">        c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract the top n representative documents per topic</span>
    <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
        <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
    <span class="p">)</span>

    <span class="c1"># Generate using a (Large) Language Model</span>
    <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>

        <span class="c1"># Delay</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">:</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">)</span>

        <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
        <span class="p">]</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponential_backoff</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">chat_completions_with_backoff</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">completion</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;message&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;topic: &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.LlamaCPP" class="doc doc-heading">
            <code>LlamaCPP</code>


<a href="#bertopic.representation.LlamaCPP" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>A llama.cpp implementation to use as a representation model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="llama_cpp.Llama">Llama</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either a string pointing towards a local LLM or a
    <code>llama_cpp.Llama</code> object.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The prompt to be used in the model. If no prompt is given,
    <code>self.default_prompt_</code> is used instead.
    NOTE: Use <code>"[KEYWORDS]"</code> and <code>"[DOCUMENTS]"</code> in the prompt
    to decide where the keywords and documents need to be
    inserted.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>system_prompt</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The system prompt to be used in the model. If no system prompt is given,
           <code>self.default_system_prompt_</code> is used instead.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Kwargs that you can pass to the <code>llama_cpp.Llama</code>
             when it is called such as <code>max_tokens</code> to be generated.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nr_docs</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of documents to pass to OpenAI if a prompt
     with the <code>["DOCUMENTS"]</code> tag is used.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>diversity</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The diversity of documents to pass to OpenAI.
       Accepts values between 0 and 1. A higher
       values results in passing more diverse documents
       whereas lower values passes more similar documents.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>doc_length</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The maximum length of each document. If a document is longer,
        it will be truncated. If None, the entire document is passed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tokenizer used to calculate to split the document into segments
       used to count the length of a document.
           * If tokenizer is 'char', then the document is split up
             into characters which are counted to adhere to <code>doc_length</code>
           * If tokenizer is 'whitespace', the the document is split up
             into words separated by whitespaces. These words are counted
             and truncated depending on <code>doc_length</code>
           * If tokenizer is 'vectorizer', then the internal CountVectorizer
             is used to tokenize the document. These tokens are counted
             and truncated depending on <code>doc_length</code>
           * If tokenizer is a callable, then that callable is used to tokenize
             the document. These tokens are counted and truncated depending
             on <code>doc_length</code></p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<p>To use a llama.cpp, first download the LLM:</p>
<div class="highlight"><pre><span></span><code>wget<span class="w"> </span>https://huggingface.co/TheBloke/zephyr-7B-alpha-GGUF/resolve/main/zephyr-7b-alpha.Q4_K_M.gguf
</code></pre></div>
<p>Then, we can now use the model the model with BERTopic in just a couple of lines:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">LlamaCPP</span>

<span class="c1"># Use llama.cpp to load in a 4-bit quantized version of Zephyr 7B Alpha</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">LlamaCPP</span><span class="p">(</span><span class="s2">&quot;zephyr-7b-alpha.Q4_K_M.gguf&quot;</span><span class="p">)</span>

<span class="c1"># Create our BERTopic model</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p>If you want to have more control over the LLMs parameters, you can run it like so:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>
<span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">LlamaCPP</span>
<span class="kn">from</span> <span class="nn">llama_cpp</span> <span class="kn">import</span> <span class="n">Llama</span>

<span class="c1"># Use llama.cpp to load in a 4-bit quantized version of Zephyr 7B Alpha</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">Llama</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;zephyr-7b-alpha.Q4_K_M.gguf&quot;</span><span class="p">,</span> <span class="n">n_gpu_layers</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_ctx</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="s2">&quot;Q:&quot;</span><span class="p">)</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">LlamaCPP</span><span class="p">(</span><span class="n">llm</span><span class="p">)</span>

<span class="c1"># Create our BERTopic model</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_llamacpp.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LlamaCPP</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A llama.cpp implementation to use as a representation model.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model: Either a string pointing towards a local LLM or a</span>
<span class="sd">                `llama_cpp.Llama` object.</span>
<span class="sd">        prompt: The prompt to be used in the model. If no prompt is given,</span>
<span class="sd">                `self.default_prompt_` is used instead.</span>
<span class="sd">                NOTE: Use `&quot;[KEYWORDS]&quot;` and `&quot;[DOCUMENTS]&quot;` in the prompt</span>
<span class="sd">                to decide where the keywords and documents need to be</span>
<span class="sd">                inserted.</span>
<span class="sd">        system_prompt: The system prompt to be used in the model. If no system prompt is given,</span>
<span class="sd">                       `self.default_system_prompt_` is used instead.</span>
<span class="sd">        pipeline_kwargs: Kwargs that you can pass to the `llama_cpp.Llama`</span>
<span class="sd">                         when it is called such as `max_tokens` to be generated.</span>
<span class="sd">        nr_docs: The number of documents to pass to OpenAI if a prompt</span>
<span class="sd">                 with the `[&quot;DOCUMENTS&quot;]` tag is used.</span>
<span class="sd">        diversity: The diversity of documents to pass to OpenAI.</span>
<span class="sd">                   Accepts values between 0 and 1. A higher</span>
<span class="sd">                   values results in passing more diverse documents</span>
<span class="sd">                   whereas lower values passes more similar documents.</span>
<span class="sd">        doc_length: The maximum length of each document. If a document is longer,</span>
<span class="sd">                    it will be truncated. If None, the entire document is passed.</span>
<span class="sd">        tokenizer: The tokenizer used to calculate to split the document into segments</span>
<span class="sd">                   used to count the length of a document.</span>
<span class="sd">                       * If tokenizer is &#39;char&#39;, then the document is split up</span>
<span class="sd">                         into characters which are counted to adhere to `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;whitespace&#39;, the the document is split up</span>
<span class="sd">                         into words separated by whitespaces. These words are counted</span>
<span class="sd">                         and truncated depending on `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;vectorizer&#39;, then the internal CountVectorizer</span>
<span class="sd">                         is used to tokenize the document. These tokens are counted</span>
<span class="sd">                         and truncated depending on `doc_length`</span>
<span class="sd">                       * If tokenizer is a callable, then that callable is used to tokenize</span>
<span class="sd">                         the document. These tokens are counted and truncated depending</span>
<span class="sd">                         on `doc_length`</span>

<span class="sd">    Usage:</span>

<span class="sd">    To use a llama.cpp, first download the LLM:</span>

<span class="sd">    ```bash</span>
<span class="sd">    wget https://huggingface.co/TheBloke/zephyr-7B-alpha-GGUF/resolve/main/zephyr-7b-alpha.Q4_K_M.gguf</span>
<span class="sd">    ```</span>

<span class="sd">    Then, we can now use the model the model with BERTopic in just a couple of lines:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic import BERTopic</span>
<span class="sd">    from bertopic.representation import LlamaCPP</span>

<span class="sd">    # Use llama.cpp to load in a 4-bit quantized version of Zephyr 7B Alpha</span>
<span class="sd">    representation_model = LlamaCPP(&quot;zephyr-7b-alpha.Q4_K_M.gguf&quot;)</span>

<span class="sd">    # Create our BERTopic model</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model, verbose=True)</span>
<span class="sd">    ```</span>

<span class="sd">    If you want to have more control over the LLMs parameters, you can run it like so:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic import BERTopic</span>
<span class="sd">    from bertopic.representation import LlamaCPP</span>
<span class="sd">    from llama_cpp import Llama</span>

<span class="sd">    # Use llama.cpp to load in a 4-bit quantized version of Zephyr 7B Alpha</span>
<span class="sd">    llm = Llama(model_path=&quot;zephyr-7b-alpha.Q4_K_M.gguf&quot;, n_gpu_layers=-1, n_ctx=4096, stop=&quot;Q:&quot;)</span>
<span class="sd">    representation_model = LlamaCPP(llm)</span>

<span class="sd">    # Create our BERTopic model</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model, verbose=True)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Llama</span><span class="p">],</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pipeline_kwargs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
        <span class="n">nr_docs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">diversity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">doc_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">Llama</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">n_gpu_layers</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">stop</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">chat_format</span><span class="o">=</span><span class="s2">&quot;ChatML&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Llama</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Make sure that the model that you&quot;</span>
                <span class="s2">&quot;pass is either a string referring to a&quot;</span>
                <span class="s2">&quot;local LLM or a ` llama_cpp.Llama` object.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span> <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">system_prompt</span> <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_SYSTEM_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_prompt_</span> <span class="o">=</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_system_prompt_</span> <span class="o">=</span> <span class="n">DEFAULT_SYSTEM_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span> <span class="o">=</span> <span class="n">pipeline_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span> <span class="o">=</span> <span class="n">nr_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span> <span class="o">=</span> <span class="n">diversity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span> <span class="o">=</span> <span class="n">doc_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">validate_truncate_document_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topic representations and return a single label.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            documents: Not used</span>
<span class="sd">            c_tf_idf: Not used</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Extract the top 4 representative documents per topic</span>
        <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
            <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
        <span class="p">)</span>

        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
            <span class="c1"># Prepare prompt</span>
            <span class="n">truncated_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">truncated_docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

            <span class="c1"># Extract result from generator and use that as label</span>
            <span class="c1"># topic_description = self.model(prompt, **self.pipeline_kwargs)[&quot;choices&quot;]</span>
            <span class="n">topic_description</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">create_chat_completion</span><span class="p">(</span>
                <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">topic_description</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;message&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">updated_topics</span>

    <span class="k">def</span> <span class="nf">_create_prompt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">):</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Use the Default Chat Prompt</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">==</span> <span class="n">DEFAULT_PROMPT</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">)</span>

        <span class="c1"># Use a custom prompt that leverages keywords, documents or both using</span>
        <span class="c1"># custom tags, namely [KEYWORDS] and [DOCUMENTS] respectively</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span>
            <span class="k">if</span> <span class="s2">&quot;[KEYWORDS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
            <span class="k">if</span> <span class="s2">&quot;[DOCUMENTS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">prompt</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">):</span>
        <span class="n">to_replace</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
            <span class="n">to_replace</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;- </span><span class="si">{</span><span class="n">doc</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[DOCUMENTS]&quot;</span><span class="p">,</span> <span class="n">to_replace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prompt</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.LlamaCPP.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.LlamaCPP.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topic representations and return a single label.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A BERTopic model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_llamacpp.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topic representations and return a single label.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: A BERTopic model</span>
<span class="sd">        documents: Not used</span>
<span class="sd">        c_tf_idf: Not used</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract the top 4 representative documents per topic</span>
    <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
        <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
    <span class="p">)</span>

    <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
        <span class="c1"># Prepare prompt</span>
        <span class="n">truncated_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">truncated_docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

        <span class="c1"># Extract result from generator and use that as label</span>
        <span class="c1"># topic_description = self.model(prompt, **self.pipeline_kwargs)[&quot;choices&quot;]</span>
        <span class="n">topic_description</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">create_chat_completion</span><span class="p">(</span>
            <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">topic_description</span><span class="p">[</span><span class="s2">&quot;choices&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;message&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.MaximalMarginalRelevance" class="doc doc-heading">
            <code>MaximalMarginalRelevance</code>


<a href="#bertopic.representation.MaximalMarginalRelevance" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>Calculate Maximal Marginal Relevance (MMR)
between candidate keywords and the document.</p>
<p>MMR considers the similarity of keywords/keyphrases with the
document, along with the similarity of already selected
keywords and keyphrases. This results in a selection of keywords
that maximize their within diversity with respect to the document.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>diversity</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>How diverse the select keywords/keyphrases are.
        Values range between 0 and 1 with 0 being not diverse at all
        and 1 being most diverse.</p>
              </div>
            </td>
            <td>
                  <code>0.1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>top_n_words</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of keywords/keyhprases to return</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">MaximalMarginalRelevance</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1"># Create your representation model</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">MaximalMarginalRelevance</span><span class="p">(</span><span class="n">diversity</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Use the representation model in BERTopic on top of the default pipeline</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_mmr.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MaximalMarginalRelevance</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate Maximal Marginal Relevance (MMR)</span>
<span class="sd">    between candidate keywords and the document.</span>

<span class="sd">    MMR considers the similarity of keywords/keyphrases with the</span>
<span class="sd">    document, along with the similarity of already selected</span>
<span class="sd">    keywords and keyphrases. This results in a selection of keywords</span>
<span class="sd">    that maximize their within diversity with respect to the document.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        diversity: How diverse the select keywords/keyphrases are.</span>
<span class="sd">                    Values range between 0 and 1 with 0 being not diverse at all</span>
<span class="sd">                    and 1 being most diverse.</span>
<span class="sd">        top_n_words: The number of keywords/keyhprases to return</span>

<span class="sd">    Usage:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic.representation import MaximalMarginalRelevance</span>
<span class="sd">    from bertopic import BERTopic</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    representation_model = MaximalMarginalRelevance(diversity=0.3)</span>

<span class="sd">    # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">diversity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">top_n_words</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span> <span class="o">=</span> <span class="n">diversity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="o">=</span> <span class="n">top_n_words</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topic representations.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: The BERTopic model</span>
<span class="sd">            documents: Not used</span>
<span class="sd">            c_tf_idf: Not used</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">embedding_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;MaximalMarginalRelevance can only be used BERTopic was instantiated&quot;</span>
                <span class="s2">&quot;with the `embedding_model` parameter.&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">topics</span>

        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topic_words</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">topic_words</span><span class="p">]</span>
            <span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">topic_embedding</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
            <span class="p">)</span>
            <span class="n">topic_words</span> <span class="o">=</span> <span class="n">mmr</span><span class="p">(</span>
                <span class="n">topic_embedding</span><span class="p">,</span>
                <span class="n">word_embeddings</span><span class="p">,</span>
                <span class="n">words</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">topic_words</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.MaximalMarginalRelevance.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.MaximalMarginalRelevance.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topic representations.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The BERTopic model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_mmr.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topic representations.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: The BERTopic model</span>
<span class="sd">        documents: Not used</span>
<span class="sd">        c_tf_idf: Not used</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">embedding_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;MaximalMarginalRelevance can only be used BERTopic was instantiated&quot;</span>
            <span class="s2">&quot;with the `embedding_model` parameter.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">topics</span>

    <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topic_words</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">topic_words</span><span class="p">]</span>
        <span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">topic_embedding</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_embeddings</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">topic_words</span> <span class="o">=</span> <span class="n">mmr</span><span class="p">(</span>
            <span class="n">topic_embedding</span><span class="p">,</span>
            <span class="n">word_embeddings</span><span class="p">,</span>
            <span class="n">words</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">word</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">topic_words</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.OpenAI" class="doc doc-heading">
            <code>OpenAI</code>


<a href="#bertopic.representation.OpenAI" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>Using the OpenAI API to generate topic labels based
on one of their Completion of ChatCompletion models.</p>
<p>For an overview see:
https://platform.openai.com/docs/models</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>client</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A <code>openai.OpenAI</code> client</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model to use within OpenAI, defaults to <code>"gpt-4o-mini"</code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;gpt-4o-mini&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>generator_kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Kwargs passed to <code>openai.Completion.create</code>
              for fine-tuning the output.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The prompt to be used in the model. If no prompt is given,
    <code>self.default_prompt_</code> is used instead.
    NOTE: Use <code>"[KEYWORDS]"</code> and <code>"[DOCUMENTS]"</code> in the prompt
    to decide where the keywords and documents need to be
    inserted.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>system_prompt</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The system prompt to be used in the model. If no system prompt is given,
           <code>self.default_system_prompt_</code> is used instead.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delay_in_seconds</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The delay in seconds between consecutive prompts
              in order to prevent RateLimitErrors.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>exponential_backoff</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Retry requests with a random exponential backoff.
                 A short sleep is used when a rate limit error is hit,
                 then the requests is retried. Increase the sleep length
                 if errors are hit until 10 unsuccessful requests.
                 If True, overrides <code>delay_in_seconds</code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nr_docs</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of documents to pass to OpenAI if a prompt
     with the <code>["DOCUMENTS"]</code> tag is used.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>diversity</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The diversity of documents to pass to OpenAI.
       Accepts values between 0 and 1. A higher
       values results in passing more diverse documents
       whereas lower values passes more similar documents.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>doc_length</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The maximum length of each document. If a document is longer,
        it will be truncated. If None, the entire document is passed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tokenizer used to calculate to split the document into segments
       used to count the length of a document.
           * If tokenizer is 'char', then the document is split up
             into characters which are counted to adhere to <code>doc_length</code>
           * If tokenizer is 'whitespace', the document is split up
             into words separated by whitespaces. These words are counted
             and truncated depending on <code>doc_length</code>
           * If tokenizer is 'vectorizer', then the internal CountVectorizer
             is used to tokenize the document. These tokens are counted
             and truncated depending on <code>doc_length</code>
           * If tokenizer is a callable, then that callable is used to tokenize
             the document. These tokens are counted and truncated depending
             on <code>doc_length</code></p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<p>To use this, you will need to install the openai package first:</p>
<p><code>pip install openai</code></p>
<p>Then, get yourself an API key and use OpenAI's API as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">openai</span>
<span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1"># Create your representation model</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">OpenAI</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="n">MY_API_KEY</span><span class="p">)</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">delay_in_seconds</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Use the representation model in BERTopic on top of the default pipeline</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>
<p>You can also use a custom prompt:</p>
<div class="highlight"><pre><span></span><code><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;I have the following documents: [DOCUMENTS] </span><span class="se">\n</span><span class="s2">These documents are about the following topic: &#39;&quot;</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">delay_in_seconds</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>
<p>To choose a model:</p>
<div class="highlight"><pre><span></span><code><span class="n">representation_model</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span> <span class="n">delay_in_seconds</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_openai.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">OpenAI</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Using the OpenAI API to generate topic labels based</span>
<span class="sd">    on one of their Completion of ChatCompletion models.</span>

<span class="sd">    For an overview see:</span>
<span class="sd">    https://platform.openai.com/docs/models</span>

<span class="sd">    Arguments:</span>
<span class="sd">        client: A `openai.OpenAI` client</span>
<span class="sd">        model: Model to use within OpenAI, defaults to `&quot;gpt-4o-mini&quot;`.</span>
<span class="sd">        generator_kwargs: Kwargs passed to `openai.Completion.create`</span>
<span class="sd">                          for fine-tuning the output.</span>
<span class="sd">        prompt: The prompt to be used in the model. If no prompt is given,</span>
<span class="sd">                `self.default_prompt_` is used instead.</span>
<span class="sd">                NOTE: Use `&quot;[KEYWORDS]&quot;` and `&quot;[DOCUMENTS]&quot;` in the prompt</span>
<span class="sd">                to decide where the keywords and documents need to be</span>
<span class="sd">                inserted.</span>
<span class="sd">        system_prompt: The system prompt to be used in the model. If no system prompt is given,</span>
<span class="sd">                       `self.default_system_prompt_` is used instead.</span>
<span class="sd">        delay_in_seconds: The delay in seconds between consecutive prompts</span>
<span class="sd">                          in order to prevent RateLimitErrors.</span>
<span class="sd">        exponential_backoff: Retry requests with a random exponential backoff.</span>
<span class="sd">                             A short sleep is used when a rate limit error is hit,</span>
<span class="sd">                             then the requests is retried. Increase the sleep length</span>
<span class="sd">                             if errors are hit until 10 unsuccessful requests.</span>
<span class="sd">                             If True, overrides `delay_in_seconds`.</span>
<span class="sd">        nr_docs: The number of documents to pass to OpenAI if a prompt</span>
<span class="sd">                 with the `[&quot;DOCUMENTS&quot;]` tag is used.</span>
<span class="sd">        diversity: The diversity of documents to pass to OpenAI.</span>
<span class="sd">                   Accepts values between 0 and 1. A higher</span>
<span class="sd">                   values results in passing more diverse documents</span>
<span class="sd">                   whereas lower values passes more similar documents.</span>
<span class="sd">        doc_length: The maximum length of each document. If a document is longer,</span>
<span class="sd">                    it will be truncated. If None, the entire document is passed.</span>
<span class="sd">        tokenizer: The tokenizer used to calculate to split the document into segments</span>
<span class="sd">                   used to count the length of a document.</span>
<span class="sd">                       * If tokenizer is &#39;char&#39;, then the document is split up</span>
<span class="sd">                         into characters which are counted to adhere to `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;whitespace&#39;, the document is split up</span>
<span class="sd">                         into words separated by whitespaces. These words are counted</span>
<span class="sd">                         and truncated depending on `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;vectorizer&#39;, then the internal CountVectorizer</span>
<span class="sd">                         is used to tokenize the document. These tokens are counted</span>
<span class="sd">                         and truncated depending on `doc_length`</span>
<span class="sd">                       * If tokenizer is a callable, then that callable is used to tokenize</span>
<span class="sd">                         the document. These tokens are counted and truncated depending</span>
<span class="sd">                         on `doc_length`</span>

<span class="sd">    Usage:</span>

<span class="sd">    To use this, you will need to install the openai package first:</span>

<span class="sd">    `pip install openai`</span>

<span class="sd">    Then, get yourself an API key and use OpenAI&#39;s API as follows:</span>

<span class="sd">    ```python</span>
<span class="sd">    import openai</span>
<span class="sd">    from bertopic.representation import OpenAI</span>
<span class="sd">    from bertopic import BERTopic</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    client = openai.OpenAI(api_key=MY_API_KEY)</span>
<span class="sd">    representation_model = OpenAI(client, delay_in_seconds=5)</span>

<span class="sd">    # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">    ```</span>

<span class="sd">    You can also use a custom prompt:</span>

<span class="sd">    ```python</span>
<span class="sd">    prompt = &quot;I have the following documents: [DOCUMENTS] \nThese documents are about the following topic: &#39;&quot;</span>
<span class="sd">    representation_model = OpenAI(client, prompt=prompt, delay_in_seconds=5)</span>
<span class="sd">    ```</span>

<span class="sd">    To choose a model:</span>

<span class="sd">    ```python</span>
<span class="sd">    representation_model = OpenAI(client, model=&quot;gpt-4o-mini&quot;, delay_in_seconds=10)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">client</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">generator_kwargs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
        <span class="n">delay_in_seconds</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exponential_backoff</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">nr_docs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">diversity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">doc_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">client</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">DEFAULT_CHAT_PROMPT</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span>

        <span class="k">if</span> <span class="n">system_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">DEFAULT_SYSTEM_PROMPT</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span> <span class="o">=</span> <span class="n">system_prompt</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">default_prompt_</span> <span class="o">=</span> <span class="n">DEFAULT_CHAT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_system_prompt_</span> <span class="o">=</span> <span class="n">DEFAULT_SYSTEM_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span> <span class="o">=</span> <span class="n">delay_in_seconds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exponential_backoff</span> <span class="o">=</span> <span class="n">exponential_backoff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span> <span class="o">=</span> <span class="n">nr_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span> <span class="o">=</span> <span class="n">diversity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span> <span class="o">=</span> <span class="n">doc_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">validate_truncate_document_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span> <span class="o">=</span> <span class="n">generator_kwargs</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">generator_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">)</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prompt&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;stop&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="p">[</span><span class="s2">&quot;stop&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            documents: All input documents</span>
<span class="sd">            c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Extract the top n representative documents per topic</span>
        <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
            <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
        <span class="p">)</span>

        <span class="c1"># Generate using OpenAI&#39;s Language Model</span>
        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
            <span class="n">truncated_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">truncated_docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

            <span class="c1"># Delay</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">:</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">)</span>

            <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">},</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
            <span class="p">]</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">,</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponential_backoff</span><span class="p">:</span>
                <span class="n">response</span> <span class="o">=</span> <span class="n">chat_completions_with_backoff</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="c1"># Check whether content was actually generated</span>
            <span class="c1"># Addresses #1570 for potential issues with OpenAI&#39;s content filter</span>
            <span class="c1"># Addresses #2176 for potential issues when openAI returns a None type object</span>
            <span class="k">if</span> <span class="n">response</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">):</span>
                <span class="n">label</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;topic: &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;No label returned&quot;</span>

            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

        <span class="k">return</span> <span class="n">updated_topics</span>

    <span class="k">def</span> <span class="nf">_create_prompt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">):</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Use the Default Chat Prompt</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">==</span> <span class="n">DEFAULT_CHAT_PROMPT</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">)</span>

        <span class="c1"># Use a custom prompt that leverages keywords, documents or both using</span>
        <span class="c1"># custom tags, namely [KEYWORDS] and [DOCUMENTS] respectively</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span>
            <span class="k">if</span> <span class="s2">&quot;[KEYWORDS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keywords</span><span class="p">))</span>
            <span class="k">if</span> <span class="s2">&quot;[DOCUMENTS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">prompt</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_replace_documents</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">docs</span><span class="p">):</span>
        <span class="n">to_replace</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
            <span class="n">to_replace</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;- </span><span class="si">{</span><span class="n">doc</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[DOCUMENTS]&quot;</span><span class="p">,</span> <span class="n">to_replace</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prompt</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.OpenAI.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.OpenAI.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topics.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A BERTopic model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>All input documents</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The topic c-TF-IDF representation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_openai.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: A BERTopic model</span>
<span class="sd">        documents: All input documents</span>
<span class="sd">        c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract the top n representative documents per topic</span>
    <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
        <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
    <span class="p">)</span>

    <span class="c1"># Generate using OpenAI&#39;s Language Model</span>
    <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
        <span class="n">truncated_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">truncated_docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

        <span class="c1"># Delay</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">:</span>
            <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay_in_seconds</span><span class="p">)</span>

        <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">system_prompt</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
        <span class="p">]</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="n">messages</span><span class="p">,</span>
            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">generator_kwargs</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">exponential_backoff</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">chat_completions_with_backoff</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Check whether content was actually generated</span>
        <span class="c1"># Addresses #1570 for potential issues with OpenAI&#39;s content filter</span>
        <span class="c1"># Addresses #2176 for potential issues when openAI returns a None type object</span>
        <span class="k">if</span> <span class="n">response</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">):</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;topic: &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;No label returned&quot;</span>

        <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">label</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>

    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.PartOfSpeech" class="doc doc-heading">
            <code>PartOfSpeech</code>


<a href="#bertopic.representation.PartOfSpeech" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>Extract Topic Keywords based on their Part-of-Speech.</p>
<p>DEFAULT_PATTERNS = [
            [{'POS': 'ADJ'}, {'POS': 'NOUN'}],
            [{'POS': 'NOUN'}],
            [{'POS': 'ADJ'}]
]</p>
<p>From candidate topics, as extracted with c-TF-IDF,
find documents that contain keywords found in the
candidate topics. These candidate documents then
serve as the representative set of documents from
which the Spacy model can extract a set of candidate
keywords for each topic.</p>
<p>These candidate keywords are first judged by whether
they fall within the DEFAULT_PATTERNS or the user-defined
pattern. Then, the resulting keywords are sorted by
their respective c-TF-IDF values.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="spacy.language.Language">Language</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Spacy model to use</p>
              </div>
            </td>
            <td>
                  <code>&#39;en_core_web_sm&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>top_n_words</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The top n words to extract</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pos_patterns</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Patterns for Spacy to use.
          See https://spacy.io/usage/rule-based-matching</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">PartOfSpeech</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1"># Create your representation model</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">PartOfSpeech</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">)</span>

<span class="c1"># Use the representation model in BERTopic on top of the default pipeline</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>
<p>You can define custom POS patterns to be extracted:</p>
<div class="highlight"><pre><span></span><code><span class="n">pos_patterns</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[{</span><span class="s1">&#39;POS&#39;</span><span class="p">:</span> <span class="s1">&#39;ADJ&#39;</span><span class="p">},</span> <span class="p">{</span><span class="s1">&#39;POS&#39;</span><span class="p">:</span> <span class="s1">&#39;NOUN&#39;</span><span class="p">}],</span>
            <span class="p">[{</span><span class="s1">&#39;POS&#39;</span><span class="p">:</span> <span class="s1">&#39;NOUN&#39;</span><span class="p">}],</span> <span class="p">[{</span><span class="s1">&#39;POS&#39;</span><span class="p">:</span> <span class="s1">&#39;ADJ&#39;</span><span class="p">}]</span>
<span class="p">]</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">PartOfSpeech</span><span class="p">(</span><span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">,</span> <span class="n">pos_patterns</span><span class="o">=</span><span class="n">pos_patterns</span><span class="p">)</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_pos.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PartOfSpeech</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract Topic Keywords based on their Part-of-Speech.</span>

<span class="sd">    DEFAULT_PATTERNS = [</span>
<span class="sd">                [{&#39;POS&#39;: &#39;ADJ&#39;}, {&#39;POS&#39;: &#39;NOUN&#39;}],</span>
<span class="sd">                [{&#39;POS&#39;: &#39;NOUN&#39;}],</span>
<span class="sd">                [{&#39;POS&#39;: &#39;ADJ&#39;}]</span>
<span class="sd">    ]</span>

<span class="sd">    From candidate topics, as extracted with c-TF-IDF,</span>
<span class="sd">    find documents that contain keywords found in the</span>
<span class="sd">    candidate topics. These candidate documents then</span>
<span class="sd">    serve as the representative set of documents from</span>
<span class="sd">    which the Spacy model can extract a set of candidate</span>
<span class="sd">    keywords for each topic.</span>

<span class="sd">    These candidate keywords are first judged by whether</span>
<span class="sd">    they fall within the DEFAULT_PATTERNS or the user-defined</span>
<span class="sd">    pattern. Then, the resulting keywords are sorted by</span>
<span class="sd">    their respective c-TF-IDF values.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model: The Spacy model to use</span>
<span class="sd">        top_n_words: The top n words to extract</span>
<span class="sd">        pos_patterns: Patterns for Spacy to use.</span>
<span class="sd">                      See https://spacy.io/usage/rule-based-matching</span>

<span class="sd">    Usage:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic.representation import PartOfSpeech</span>
<span class="sd">    from bertopic import BERTopic</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    representation_model = PartOfSpeech(&quot;en_core_web_sm&quot;)</span>

<span class="sd">    # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">    ```</span>

<span class="sd">    You can define custom POS patterns to be extracted:</span>

<span class="sd">    ```python</span>
<span class="sd">    pos_patterns = [</span>
<span class="sd">                [{&#39;POS&#39;: &#39;ADJ&#39;}, {&#39;POS&#39;: &#39;NOUN&#39;}],</span>
<span class="sd">                [{&#39;POS&#39;: &#39;NOUN&#39;}], [{&#39;POS&#39;: &#39;ADJ&#39;}]</span>
<span class="sd">    ]</span>
<span class="sd">    representation_model = PartOfSpeech(&quot;en_core_web_sm&quot;, pos_patterns=pos_patterns)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Language</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;en_core_web_sm&quot;</span><span class="p">,</span>
        <span class="n">top_n_words</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">pos_patterns</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Language</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Make sure that the Spacy model that you&quot;</span>
                <span class="s2">&quot;pass is either a string referring to a&quot;</span>
                <span class="s2">&quot;Spacy model or a Spacy nlp object.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="o">=</span> <span class="n">top_n_words</span>

        <span class="k">if</span> <span class="n">pos_patterns</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pos_patterns</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">[{</span><span class="s2">&quot;POS&quot;</span><span class="p">:</span> <span class="s2">&quot;ADJ&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;POS&quot;</span><span class="p">:</span> <span class="s2">&quot;NOUN&quot;</span><span class="p">}],</span>
                <span class="p">[{</span><span class="s2">&quot;POS&quot;</span><span class="p">:</span> <span class="s2">&quot;NOUN&quot;</span><span class="p">}],</span>
                <span class="p">[{</span><span class="s2">&quot;POS&quot;</span><span class="p">:</span> <span class="s2">&quot;ADJ&quot;</span><span class="p">}],</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pos_patterns</span> <span class="o">=</span> <span class="n">pos_patterns</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            documents: All input documents</span>
<span class="sd">            c_tf_idf: Not used</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">matcher</span> <span class="o">=</span> <span class="n">Matcher</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
        <span class="n">matcher</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;Pattern&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_patterns</span><span class="p">)</span>

        <span class="n">candidate_topics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">keywords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">values</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># Extract candidate documents</span>
            <span class="n">candidate_documents</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">:</span>
                <span class="n">selection</span> <span class="o">=</span> <span class="n">documents</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">documents</span><span class="o">.</span><span class="n">Topic</span> <span class="o">==</span> <span class="n">topic</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">selection</span> <span class="o">=</span> <span class="n">selection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">selection</span><span class="o">.</span><span class="n">Document</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">keyword</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="s2">&quot;Document&quot;</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">selection</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">selection</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
                        <span class="n">candidate_documents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
            <span class="n">candidate_documents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">candidate_documents</span><span class="p">))</span>

            <span class="c1"># Extract keywords</span>
            <span class="n">docs_pipeline</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">candidate_documents</span><span class="p">)</span>
            <span class="n">updated_keywords</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs_pipeline</span><span class="p">:</span>
                <span class="n">matches</span> <span class="o">=</span> <span class="n">matcher</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
                    <span class="n">updated_keywords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
            <span class="n">candidate_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">updated_keywords</span><span class="p">))</span>

        <span class="c1"># Scikit-Learn Deprecation: get_feature_names is deprecated in 1.0</span>
        <span class="c1"># and will be removed in 1.2. Please use get_feature_names_out instead.</span>
        <span class="k">if</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;1.0.0&quot;</span><span class="p">):</span>
            <span class="n">words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">topic_model</span><span class="o">.</span><span class="n">vectorizer_model</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">topic_model</span><span class="o">.</span><span class="n">vectorizer_model</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>

        <span class="c1"># Match updated keywords with c-TF-IDF values</span>
        <span class="n">words_lookup</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))))</span>
        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{</span><span class="n">topic</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>

        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">candidate_keywords</span> <span class="ow">in</span> <span class="n">candidate_topics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">word_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span>
                <span class="p">[</span><span class="n">words_lookup</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">keyword</span><span class="p">)</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">candidate_keywords</span> <span class="k">if</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">words_lookup</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">c_tf_idf_</span><span class="p">[:,</span> <span class="n">word_indices</span><span class="p">][</span><span class="n">topic</span> <span class="o">+</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_outliers</span><span class="p">]</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vals</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">])[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="p">:][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vals</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">])[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="p">:][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">topic_words</span> <span class="o">=</span> <span class="p">[(</span><span class="n">words</span><span class="p">[</span><span class="n">word_indices</span><span class="p">[</span><span class="n">index</span><span class="p">]],</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">vals</span><span class="p">)]</span>
            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic_words</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">])</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span><span class="p">:</span>
                <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">+=</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))]</span>

        <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.PartOfSpeech.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.PartOfSpeech.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topics.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A BERTopic model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>All input documents</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_pos.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: A BERTopic model</span>
<span class="sd">        documents: All input documents</span>
<span class="sd">        c_tf_idf: Not used</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">matcher</span> <span class="o">=</span> <span class="n">Matcher</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>
    <span class="n">matcher</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;Pattern&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_patterns</span><span class="p">)</span>

    <span class="n">candidate_topics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">values</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Extract candidate documents</span>
        <span class="n">candidate_documents</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">:</span>
            <span class="n">selection</span> <span class="o">=</span> <span class="n">documents</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">documents</span><span class="o">.</span><span class="n">Topic</span> <span class="o">==</span> <span class="n">topic</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">selection</span> <span class="o">=</span> <span class="n">selection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">selection</span><span class="o">.</span><span class="n">Document</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">keyword</span><span class="p">,</span> <span class="n">regex</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="s2">&quot;Document&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">selection</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">selection</span><span class="p">[:</span><span class="mi">2</span><span class="p">]:</span>
                    <span class="n">candidate_documents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>
        <span class="n">candidate_documents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">candidate_documents</span><span class="p">))</span>

        <span class="c1"># Extract keywords</span>
        <span class="n">docs_pipeline</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">candidate_documents</span><span class="p">)</span>
        <span class="n">updated_keywords</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs_pipeline</span><span class="p">:</span>
            <span class="n">matches</span> <span class="o">=</span> <span class="n">matcher</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
                <span class="n">updated_keywords</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
        <span class="n">candidate_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">updated_keywords</span><span class="p">))</span>

    <span class="c1"># Scikit-Learn Deprecation: get_feature_names is deprecated in 1.0</span>
    <span class="c1"># and will be removed in 1.2. Please use get_feature_names_out instead.</span>
    <span class="k">if</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">sklearn_version</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">&quot;1.0.0&quot;</span><span class="p">):</span>
        <span class="n">words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">topic_model</span><span class="o">.</span><span class="n">vectorizer_model</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">topic_model</span><span class="o">.</span><span class="n">vectorizer_model</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>

    <span class="c1"># Match updated keywords with c-TF-IDF values</span>
    <span class="n">words_lookup</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">))))</span>
    <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{</span><span class="n">topic</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>

    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">candidate_keywords</span> <span class="ow">in</span> <span class="n">candidate_topics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">word_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span>
            <span class="p">[</span><span class="n">words_lookup</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">keyword</span><span class="p">)</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">candidate_keywords</span> <span class="k">if</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">words_lookup</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">c_tf_idf_</span><span class="p">[:,</span> <span class="n">word_indices</span><span class="p">][</span><span class="n">topic</span> <span class="o">+</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_outliers</span><span class="p">]</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vals</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">])[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="p">:][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vals</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">])[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="p">:][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">topic_words</span> <span class="o">=</span> <span class="p">[(</span><span class="n">words</span><span class="p">[</span><span class="n">word_indices</span><span class="p">[</span><span class="n">index</span><span class="p">]],</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">vals</span><span class="p">)]</span>
        <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic_words</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">])</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span><span class="p">:</span>
            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">+=</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">top_n_words</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))]</span>

    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.TextGeneration" class="doc doc-heading">
            <code>TextGeneration</code>


<a href="#bertopic.representation.TextGeneration" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>Text2Text or text generation with transformers.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="transformers.pipeline">pipeline</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A transformers pipeline that should be initialized as "text-generation"
   for gpt-like models or "text2text-generation" for T5-like models.
   For example, <code>pipeline('text-generation', model='gpt2')</code>. If a string
   is passed, "text-generation" will be selected by default.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prompt</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The prompt to be used in the model. If no prompt is given,
    <code>self.default_prompt_</code> is used instead.
    NOTE: Use <code>"[KEYWORDS]"</code> and <code>"[DOCUMENTS]"</code> in the prompt
    to decide where the keywords and documents need to be
    inserted.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Kwargs that you can pass to the transformers.pipeline
             when it is called.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>random_state</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A random state to be passed to <code>transformers.set_seed</code></p>
              </div>
            </td>
            <td>
                  <code>42</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nr_docs</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of documents to pass to OpenAI if a prompt
     with the <code>["DOCUMENTS"]</code> tag is used.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>diversity</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The diversity of documents to pass to OpenAI.
       Accepts values between 0 and 1. A higher
       values results in passing more diverse documents
       whereas lower values passes more similar documents.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>doc_length</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The maximum length of each document. If a document is longer,
        it will be truncated. If None, the entire document is passed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tokenizer</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="typing.Callable">Callable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The tokenizer used to calculate to split the document into segments
       used to count the length of a document.
           * If tokenizer is 'char', then the document is split up
             into characters which are counted to adhere to <code>doc_length</code>
           * If tokenizer is 'whitespace', the document is split up
             into words separated by whitespaces. These words are counted
             and truncated depending on <code>doc_length</code>
           * If tokenizer is 'vectorizer', then the internal CountVectorizer
             is used to tokenize the document. These tokens are counted
             and truncated depending on <code>doc_length</code>
           * If tokenizer is a callable, then that callable is used to tokenize
             the document. These tokens are counted and truncated depending
             on <code>doc_length</code></p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<p>To use a gpt-like model:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">TextGeneration</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1"># Create your representation model</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;text-generation&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;gpt2&#39;</span><span class="p">)</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">TextGeneration</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>

<span class="c1"># Use the representation model in BERTopic on top of the default pipeline</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTo</span> <span class="n">pic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>
<p>You can use a custom prompt and decide where the keywords should
be inserted by using the <code>[KEYWORDS]</code> or documents with thte <code>[DOCUMENTS]</code> tag:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">TextGeneration</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;I have a topic described by the following keywords: [KEYWORDS]. Based on the previous keywords, what is this topic about?&quot;&quot;</span>

<span class="c1"># Create your representation model</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s1">&#39;text2text-generation&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s1">&#39;google/flan-t5-base&#39;</span><span class="p">)</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">TextGeneration</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_textgeneration.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">TextGeneration</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Text2Text or text generation with transformers.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model: A transformers pipeline that should be initialized as &quot;text-generation&quot;</span>
<span class="sd">               for gpt-like models or &quot;text2text-generation&quot; for T5-like models.</span>
<span class="sd">               For example, `pipeline(&#39;text-generation&#39;, model=&#39;gpt2&#39;)`. If a string</span>
<span class="sd">               is passed, &quot;text-generation&quot; will be selected by default.</span>
<span class="sd">        prompt: The prompt to be used in the model. If no prompt is given,</span>
<span class="sd">                `self.default_prompt_` is used instead.</span>
<span class="sd">                NOTE: Use `&quot;[KEYWORDS]&quot;` and `&quot;[DOCUMENTS]&quot;` in the prompt</span>
<span class="sd">                to decide where the keywords and documents need to be</span>
<span class="sd">                inserted.</span>
<span class="sd">        pipeline_kwargs: Kwargs that you can pass to the transformers.pipeline</span>
<span class="sd">                         when it is called.</span>
<span class="sd">        random_state: A random state to be passed to `transformers.set_seed`</span>
<span class="sd">        nr_docs: The number of documents to pass to OpenAI if a prompt</span>
<span class="sd">                 with the `[&quot;DOCUMENTS&quot;]` tag is used.</span>
<span class="sd">        diversity: The diversity of documents to pass to OpenAI.</span>
<span class="sd">                   Accepts values between 0 and 1. A higher</span>
<span class="sd">                   values results in passing more diverse documents</span>
<span class="sd">                   whereas lower values passes more similar documents.</span>
<span class="sd">        doc_length: The maximum length of each document. If a document is longer,</span>
<span class="sd">                    it will be truncated. If None, the entire document is passed.</span>
<span class="sd">        tokenizer: The tokenizer used to calculate to split the document into segments</span>
<span class="sd">                   used to count the length of a document.</span>
<span class="sd">                       * If tokenizer is &#39;char&#39;, then the document is split up</span>
<span class="sd">                         into characters which are counted to adhere to `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;whitespace&#39;, the document is split up</span>
<span class="sd">                         into words separated by whitespaces. These words are counted</span>
<span class="sd">                         and truncated depending on `doc_length`</span>
<span class="sd">                       * If tokenizer is &#39;vectorizer&#39;, then the internal CountVectorizer</span>
<span class="sd">                         is used to tokenize the document. These tokens are counted</span>
<span class="sd">                         and truncated depending on `doc_length`</span>
<span class="sd">                       * If tokenizer is a callable, then that callable is used to tokenize</span>
<span class="sd">                         the document. These tokens are counted and truncated depending</span>
<span class="sd">                         on `doc_length`</span>

<span class="sd">    Usage:</span>

<span class="sd">    To use a gpt-like model:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic.representation import TextGeneration</span>
<span class="sd">    from bertopic import BERTopic</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    generator = pipeline(&#39;text-generation&#39;, model=&#39;gpt2&#39;)</span>
<span class="sd">    representation_model = TextGeneration(generator)</span>

<span class="sd">    # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">    topic_model = BERTo pic(representation_model=representation_model)</span>
<span class="sd">    ```</span>

<span class="sd">    You can use a custom prompt and decide where the keywords should</span>
<span class="sd">    be inserted by using the `[KEYWORDS]` or documents with thte `[DOCUMENTS]` tag:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic.representation import TextGeneration</span>

<span class="sd">    prompt = &quot;I have a topic described by the following keywords: [KEYWORDS]. Based on the previous keywords, what is this topic about?&quot;&quot;</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    generator = pipeline(&#39;text2text-generation&#39;, model=&#39;google/flan-t5-base&#39;)</span>
<span class="sd">    representation_model = TextGeneration(generator)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">],</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pipeline_kwargs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
        <span class="n">nr_docs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">diversity</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">doc_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="n">set_seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;text-generation&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Make sure that the HF model that you&quot;</span>
                <span class="s2">&quot;pass is either a string referring to a&quot;</span>
                <span class="s2">&quot;HF model or a `transformers.pipeline` object.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span> <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_prompt_</span> <span class="o">=</span> <span class="n">DEFAULT_PROMPT</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span> <span class="o">=</span> <span class="n">pipeline_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span> <span class="o">=</span> <span class="n">nr_docs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span> <span class="o">=</span> <span class="n">diversity</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span> <span class="o">=</span> <span class="n">doc_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="n">validate_truncate_document_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topic representations and return a single label.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            documents: Not used</span>
<span class="sd">            c_tf_idf: Not used</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Extract the top 4 representative documents per topic</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">!=</span> <span class="n">DEFAULT_PROMPT</span> <span class="ow">and</span> <span class="s2">&quot;[DOCUMENTS]&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="p">:</span>
            <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
                <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">repr_docs_mappings</span> <span class="o">=</span> <span class="p">{</span><span class="n">topic</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>

        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
            <span class="c1"># Prepare prompt</span>
            <span class="n">truncated_docs</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">[</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">docs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="n">docs</span>
            <span class="p">)</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">truncated_docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

            <span class="c1"># Extract result from generator and use that as label</span>
            <span class="n">topic_description</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span><span class="p">)</span>
            <span class="n">topic_description</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span><span class="n">description</span><span class="p">[</span><span class="s2">&quot;generated_text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">description</span> <span class="ow">in</span> <span class="n">topic_description</span>
            <span class="p">]</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
                <span class="n">topic_description</span> <span class="o">+=</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">))]</span>

            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic_description</span>

        <span class="k">return</span> <span class="n">updated_topics</span>

    <span class="k">def</span> <span class="nf">_create_prompt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">):</span>
        <span class="n">keywords</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Use the default prompt and replace keywords</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">==</span> <span class="n">DEFAULT_PROMPT</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="n">keywords</span><span class="p">)</span>

        <span class="c1"># Use a prompt that leverages either keywords or documents in</span>
        <span class="c1"># a custom location</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span>
            <span class="k">if</span> <span class="s2">&quot;[KEYWORDS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[KEYWORDS]&quot;</span><span class="p">,</span> <span class="n">keywords</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;[DOCUMENTS]&quot;</span> <span class="ow">in</span> <span class="n">prompt</span><span class="p">:</span>
                <span class="n">to_replace</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
                    <span class="n">to_replace</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;- </span><span class="si">{</span><span class="n">doc</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;[DOCUMENTS]&quot;</span><span class="p">,</span> <span class="n">to_replace</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">prompt</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.TextGeneration.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.TextGeneration.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topic representations and return a single label.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A BERTopic model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_textgeneration.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topic representations and return a single label.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: A BERTopic model</span>
<span class="sd">        documents: Not used</span>
<span class="sd">        c_tf_idf: Not used</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract the top 4 representative documents per topic</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span> <span class="o">!=</span> <span class="n">DEFAULT_PROMPT</span> <span class="ow">and</span> <span class="s2">&quot;[DOCUMENTS]&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt</span><span class="p">:</span>
        <span class="n">repr_docs_mappings</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
            <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">topics</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nr_docs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">diversity</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">repr_docs_mappings</span> <span class="o">=</span> <span class="p">{</span><span class="n">topic</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>

    <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">docs</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">repr_docs_mappings</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">verbose</span><span class="p">):</span>
        <span class="c1"># Prepare prompt</span>
        <span class="n">truncated_docs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">[</span><span class="n">truncate_document</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">doc_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">doc</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">docs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">docs</span>
        <span class="p">)</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_prompt</span><span class="p">(</span><span class="n">truncated_docs</span><span class="p">,</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompts_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>

        <span class="c1"># Extract result from generator and use that as label</span>
        <span class="n">topic_description</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span><span class="p">)</span>
        <span class="n">topic_description</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">description</span><span class="p">[</span><span class="s2">&quot;generated_text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">description</span> <span class="ow">in</span> <span class="n">topic_description</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="n">topic_description</span> <span class="o">+=</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">))]</span>

        <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic_description</span>

    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.VisualRepresentation" class="doc doc-heading">
            <code>VisualRepresentation</code>


<a href="#bertopic.representation.VisualRepresentation" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>From a collection of representative documents, extract
images to represent topics. These topics are represented by a
collage of images.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>nr_repr_images</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of representative images to extract</p>
              </div>
            </td>
            <td>
                  <code>9</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>nr_samples</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of candidate documents to extract per cluster.</p>
              </div>
            </td>
            <td>
                  <code>500</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_height</code>
            </td>
            <td>
                  <code><span title="typing.Tuple">Tuple</span>[int, int]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The height of the resulting collage</p>
              </div>
            </td>
            <td>
                  <code>600</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_square</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to resize each image in the collage
          to a square. This can be visually more appealing
          if all input images are all almost squares.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>image_to_text_model</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="transformers.pipelines.Pipeline">Pipeline</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model to caption images.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_size</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of images to pass to the
        <code>image_to_text_model</code>.</p>
              </div>
            </td>
            <td>
                  <code>32</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">VisualRepresentation</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1"># The visual representation is typically not a core representation</span>
<span class="c1"># and is advised to pass to BERTopic as an additional aspect.</span>
<span class="c1"># Aspects can be labeled with dictionaries as shown below:</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Visual_Aspect&quot;</span><span class="p">:</span> <span class="n">VisualRepresentation</span><span class="p">()</span>
<span class="p">}</span>

<span class="c1"># Use the representation model in BERTopic as a separate aspect</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_visual.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">VisualRepresentation</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;From a collection of representative documents, extract</span>
<span class="sd">    images to represent topics. These topics are represented by a</span>
<span class="sd">    collage of images.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        nr_repr_images: Number of representative images to extract</span>
<span class="sd">        nr_samples: The number of candidate documents to extract per cluster.</span>
<span class="sd">        image_height: The height of the resulting collage</span>
<span class="sd">        image_square: Whether to resize each image in the collage</span>
<span class="sd">                      to a square. This can be visually more appealing</span>
<span class="sd">                      if all input images are all almost squares.</span>
<span class="sd">        image_to_text_model: The model to caption images.</span>
<span class="sd">        batch_size: The number of images to pass to the</span>
<span class="sd">                    `image_to_text_model`.</span>

<span class="sd">    Usage:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic.representation import VisualRepresentation</span>
<span class="sd">    from bertopic import BERTopic</span>

<span class="sd">    # The visual representation is typically not a core representation</span>
<span class="sd">    # and is advised to pass to BERTopic as an additional aspect.</span>
<span class="sd">    # Aspects can be labeled with dictionaries as shown below:</span>
<span class="sd">    representation_model = {</span>
<span class="sd">        &quot;Visual_Aspect&quot;: VisualRepresentation()</span>
<span class="sd">    }</span>

<span class="sd">    # Use the representation model in BERTopic as a separate aspect</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">nr_repr_images</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span>
        <span class="n">nr_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
        <span class="n">image_height</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">600</span><span class="p">,</span>
        <span class="n">image_squares</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">image_to_text_model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_repr_images</span> <span class="o">=</span> <span class="n">nr_repr_images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nr_samples</span> <span class="o">=</span> <span class="n">nr_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_height</span> <span class="o">=</span> <span class="n">image_height</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_squares</span> <span class="o">=</span> <span class="n">image_squares</span>

        <span class="c1"># Text-to-image model</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_to_text_model</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_to_text_model</span> <span class="o">=</span> <span class="n">image_to_text_model</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_to_text_model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_to_text_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;image-to-text&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">image_to_text_model</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">image_to_text_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">image_to_text_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Please select a correct transformers pipeline. For example:&quot;</span>
                <span class="s2">&quot;pipeline(&#39;image-to-text&#39;, model=&#39;nlpconnect/vit-gpt2-image-captioning&#39;)&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: A BERTopic model</span>
<span class="sd">            documents: All input documents</span>
<span class="sd">            c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            representative_images: Representative images per topic</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Extract image ids of most representative documents</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">documents</span><span class="p">[</span><span class="s2">&quot;Image&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">repr_docs_ids</span><span class="p">)</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
            <span class="n">c_tf_idf</span><span class="p">,</span>
            <span class="n">documents</span><span class="p">,</span>
            <span class="n">topics</span><span class="p">,</span>
            <span class="n">nr_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nr_samples</span><span class="p">,</span>
            <span class="n">nr_repr_docs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nr_repr_images</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">unique_topics</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

        <span class="c1"># Combine representative images into a single representation</span>
        <span class="n">representative_images</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">unique_topics</span><span class="p">):</span>
            <span class="c1"># Get and order represetnative images</span>
            <span class="n">sliced_examplars</span> <span class="o">=</span> <span class="n">repr_docs_ids</span><span class="p">[</span><span class="n">topic</span> <span class="o">+</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_outliers</span><span class="p">]</span>
            <span class="n">sliced_examplars</span> <span class="o">=</span> <span class="p">[</span><span class="n">sliced_examplars</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sliced_examplars</span><span class="p">),</span> <span class="mi">3</span><span class="p">)]</span>
            <span class="n">images_to_combine</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">[</span>
                    <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">sub_indices</span>
                <span class="p">]</span>
                <span class="k">for</span> <span class="n">sub_indices</span> <span class="ow">in</span> <span class="n">sliced_examplars</span>
            <span class="p">]</span>

            <span class="c1"># Concatenate representative images</span>
            <span class="n">representative_image</span> <span class="o">=</span> <span class="n">get_concat_tile_resize</span><span class="p">(</span><span class="n">images_to_combine</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_height</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_squares</span><span class="p">)</span>
            <span class="n">representative_images</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">representative_image</span>

            <span class="c1"># Make sure to properly close images</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">image_list</span> <span class="ow">in</span> <span class="n">images_to_combine</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">image_list</span><span class="p">:</span>
                        <span class="n">image</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">representative_images</span>

    <span class="k">def</span> <span class="nf">_convert_image_to_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert a list of images to captions.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            images: A list of images or words to be converted to text.</span>
<span class="sd">            verbose: Controls the verbosity of the process</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of captions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Batch-wise image conversion</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">documents</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_chunks</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">):</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_to_text_model</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
                <span class="n">captions</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;generated_text&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
                <span class="n">documents</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span>

        <span class="c1"># Convert images to text</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_to_text_model</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;generated_text&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">documents</span>

    <span class="k">def</span> <span class="nf">image_to_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert images to text.&quot;&quot;&quot;</span>
        <span class="c1"># Create image topic embeddings</span>
        <span class="n">topics</span> <span class="o">=</span> <span class="n">documents</span><span class="o">.</span><span class="n">Topic</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">documents</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">topics</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">embeddings</span><span class="p">]))</span>
        <span class="n">image_topic_embeddings</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">values</span>

        <span class="c1"># Extract image centroids</span>
        <span class="n">image_centroids</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">unique_topics</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">topics</span><span class="p">)))</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topic_embedding</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique_topics</span><span class="p">,</span> <span class="n">image_topic_embeddings</span><span class="p">):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">index</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">topics</span><span class="p">)</span> <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="n">topic</span><span class="p">])</span>
            <span class="n">top_n</span> <span class="o">=</span> <span class="nb">min</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">nr_repr_images</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)])</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">mmr</span><span class="p">(</span>
                <span class="n">topic_embedding</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">embeddings</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span>
                <span class="n">indices</span><span class="p">,</span>
                <span class="n">top_n</span><span class="o">=</span><span class="n">top_n</span><span class="p">,</span>
                <span class="n">diversity</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">image_centroids</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">indices</span>

        <span class="c1"># Extract documents</span>
        <span class="n">documents</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Document&quot;</span><span class="p">,</span> <span class="s2">&quot;ID&quot;</span><span class="p">,</span> <span class="s2">&quot;Topic&quot;</span><span class="p">,</span> <span class="s2">&quot;Image&quot;</span><span class="p">])</span>
        <span class="n">current_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">image_ids</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">image_centroids</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">selected_images</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">image_ids</span>
            <span class="p">]</span>
            <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_image_to_text</span><span class="p">(</span><span class="n">selected_images</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">image_id</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">image_ids</span><span class="p">):</span>
                <span class="n">documents</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">documents</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">doc</span><span class="p">,</span>
                    <span class="n">current_id</span><span class="p">,</span>
                    <span class="n">topic</span><span class="p">,</span>
                    <span class="n">images</span><span class="p">[</span><span class="n">image_id</span><span class="p">],</span>
                <span class="p">]</span>
                <span class="n">current_id</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># Properly close images</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">image_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">selected_images</span><span class="p">:</span>
                    <span class="n">image</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">documents</span>

    <span class="k">def</span> <span class="nf">_chunks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">images</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.VisualRepresentation.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.VisualRepresentation.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topics.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A BERTopic model</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>All input documents</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The topic c-TF-IDF representation</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>representative_images</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Representative images per topic</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_visual.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: A BERTopic model</span>
<span class="sd">        documents: All input documents</span>
<span class="sd">        c_tf_idf: The topic c-TF-IDF representation</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        representative_images: Representative images per topic</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract image ids of most representative documents</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">documents</span><span class="p">[</span><span class="s2">&quot;Image&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">repr_docs_ids</span><span class="p">)</span> <span class="o">=</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_extract_representative_docs</span><span class="p">(</span>
        <span class="n">c_tf_idf</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">,</span>
        <span class="n">nr_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nr_samples</span><span class="p">,</span>
        <span class="n">nr_repr_docs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nr_repr_images</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">unique_topics</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

    <span class="c1"># Combine representative images into a single representation</span>
    <span class="n">representative_images</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">unique_topics</span><span class="p">):</span>
        <span class="c1"># Get and order represetnative images</span>
        <span class="n">sliced_examplars</span> <span class="o">=</span> <span class="n">repr_docs_ids</span><span class="p">[</span><span class="n">topic</span> <span class="o">+</span> <span class="n">topic_model</span><span class="o">.</span><span class="n">_outliers</span><span class="p">]</span>
        <span class="n">sliced_examplars</span> <span class="o">=</span> <span class="p">[</span><span class="n">sliced_examplars</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sliced_examplars</span><span class="p">),</span> <span class="mi">3</span><span class="p">)]</span>
        <span class="n">images_to_combine</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span>
                <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">sub_indices</span>
            <span class="p">]</span>
            <span class="k">for</span> <span class="n">sub_indices</span> <span class="ow">in</span> <span class="n">sliced_examplars</span>
        <span class="p">]</span>

        <span class="c1"># Concatenate representative images</span>
        <span class="n">representative_image</span> <span class="o">=</span> <span class="n">get_concat_tile_resize</span><span class="p">(</span><span class="n">images_to_combine</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_height</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_squares</span><span class="p">)</span>
        <span class="n">representative_images</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">representative_image</span>

        <span class="c1"># Make sure to properly close images</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">image_list</span> <span class="ow">in</span> <span class="n">images_to_combine</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">image_list</span><span class="p">:</span>
                    <span class="n">image</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">representative_images</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.VisualRepresentation.image_to_text" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">image_to_text</span><span class="p">(</span><span class="n">documents</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span></code>

<a href="#bertopic.representation.VisualRepresentation.image_to_text" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Convert images to text.</p>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_visual.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">image_to_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert images to text.&quot;&quot;&quot;</span>
    <span class="c1"># Create image topic embeddings</span>
    <span class="n">topics</span> <span class="o">=</span> <span class="n">documents</span><span class="o">.</span><span class="n">Topic</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">documents</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">topics</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">embeddings</span><span class="p">]))</span>
    <span class="n">image_topic_embeddings</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">values</span>

    <span class="c1"># Extract image centroids</span>
    <span class="n">image_centroids</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">unique_topics</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">topics</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">topic_embedding</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique_topics</span><span class="p">,</span> <span class="n">image_topic_embeddings</span><span class="p">):</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">index</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">topics</span><span class="p">)</span> <span class="k">if</span> <span class="n">t</span> <span class="o">==</span> <span class="n">topic</span><span class="p">])</span>
        <span class="n">top_n</span> <span class="o">=</span> <span class="nb">min</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">nr_repr_images</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)])</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">mmr</span><span class="p">(</span>
            <span class="n">topic_embedding</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">embeddings</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span>
            <span class="n">indices</span><span class="p">,</span>
            <span class="n">top_n</span><span class="o">=</span><span class="n">top_n</span><span class="p">,</span>
            <span class="n">diversity</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">image_centroids</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">indices</span>

    <span class="c1"># Extract documents</span>
    <span class="n">documents</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Document&quot;</span><span class="p">,</span> <span class="s2">&quot;ID&quot;</span><span class="p">,</span> <span class="s2">&quot;Topic&quot;</span><span class="p">,</span> <span class="s2">&quot;Image&quot;</span><span class="p">])</span>
    <span class="n">current_id</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">image_ids</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">image_centroids</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="n">selected_images</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">])</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">images</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">image_ids</span>
        <span class="p">]</span>
        <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_image_to_text</span><span class="p">(</span><span class="n">selected_images</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">image_id</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">image_ids</span><span class="p">):</span>
            <span class="n">documents</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">documents</span><span class="p">),</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">doc</span><span class="p">,</span>
                <span class="n">current_id</span><span class="p">,</span>
                <span class="n">topic</span><span class="p">,</span>
                <span class="n">images</span><span class="p">[</span><span class="n">image_id</span><span class="p">],</span>
            <span class="p">]</span>
            <span class="n">current_id</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Properly close images</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">image_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">selected_images</span><span class="p">:</span>
                <span class="n">image</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">documents</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="bertopic.representation.ZeroShotClassification" class="doc doc-heading">
            <code>ZeroShotClassification</code>


<a href="#bertopic.representation.ZeroShotClassification" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="bertopic.representation._base.BaseRepresentation" href="#bertopic.representation.BaseRepresentation">BaseRepresentation</a></code></p>


        <p>Zero-shot Classification on topic keywords with candidate labels.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>candidate_topics</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A list of labels to assign to the topics if they
              exceed <code>min_prob</code></p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A transformers pipeline that should be initialized as
   "zero-shot-classification". For example,
   <code>pipeline("zero-shot-classification", model="facebook/bart-large-mnli")</code></p>
              </div>
            </td>
            <td>
                  <code>&#39;facebook/bart-large-mnli&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pipeline_kwargs</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Kwargs that you can pass to the transformers.pipeline
             when it is called. NOTE: Use <code>{"multi_label": True}</code>
             to extract multiple labels for each topic.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>min_prob</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The minimum probability to assign a candidate label to a topic</p>
              </div>
            </td>
            <td>
                  <code>0.8</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Usage:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bertopic.representation</span> <span class="kn">import</span> <span class="n">ZeroShotClassification</span>
<span class="kn">from</span> <span class="nn">bertopic</span> <span class="kn">import</span> <span class="n">BERTopic</span>

<span class="c1"># Create your representation model</span>
<span class="n">candidate_topics</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;space and nasa&quot;</span><span class="p">,</span> <span class="s2">&quot;bicycles&quot;</span><span class="p">,</span> <span class="s2">&quot;sports&quot;</span><span class="p">]</span>
<span class="n">representation_model</span> <span class="o">=</span> <span class="n">ZeroShotClassification</span><span class="p">(</span><span class="n">candidate_topics</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;facebook/bart-large-mnli&quot;</span><span class="p">)</span>

<span class="c1"># Use the representation model in BERTopic on top of the default pipeline</span>
<span class="n">topic_model</span> <span class="o">=</span> <span class="n">BERTopic</span><span class="p">(</span><span class="n">representation_model</span><span class="o">=</span><span class="n">representation_model</span><span class="p">)</span>
</code></pre></div>






              <details class="quote">
                <summary>Source code in <code>bertopic\representation\_zeroshot.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ZeroShotClassification</span><span class="p">(</span><span class="n">BaseRepresentation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Zero-shot Classification on topic keywords with candidate labels.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        candidate_topics: A list of labels to assign to the topics if they</span>
<span class="sd">                          exceed `min_prob`</span>
<span class="sd">        model: A transformers pipeline that should be initialized as</span>
<span class="sd">               &quot;zero-shot-classification&quot;. For example,</span>
<span class="sd">               `pipeline(&quot;zero-shot-classification&quot;, model=&quot;facebook/bart-large-mnli&quot;)`</span>
<span class="sd">        pipeline_kwargs: Kwargs that you can pass to the transformers.pipeline</span>
<span class="sd">                         when it is called. NOTE: Use `{&quot;multi_label&quot;: True}`</span>
<span class="sd">                         to extract multiple labels for each topic.</span>
<span class="sd">        min_prob: The minimum probability to assign a candidate label to a topic</span>

<span class="sd">    Usage:</span>

<span class="sd">    ```python</span>
<span class="sd">    from bertopic.representation import ZeroShotClassification</span>
<span class="sd">    from bertopic import BERTopic</span>

<span class="sd">    # Create your representation model</span>
<span class="sd">    candidate_topics = [&quot;space and nasa&quot;, &quot;bicycles&quot;, &quot;sports&quot;]</span>
<span class="sd">    representation_model = ZeroShotClassification(candidate_topics, model=&quot;facebook/bart-large-mnli&quot;)</span>

<span class="sd">    # Use the representation model in BERTopic on top of the default pipeline</span>
<span class="sd">    topic_model = BERTopic(representation_model=representation_model)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">candidate_topics</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;facebook/bart-large-mnli&quot;</span><span class="p">,</span>
        <span class="n">pipeline_kwargs</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">{},</span>
        <span class="n">min_prob</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">candidate_topics</span> <span class="o">=</span> <span class="n">candidate_topics</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;zero-shot-classification&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Make sure that the HF model that you&quot;</span>
                <span class="s2">&quot;pass is either a string referring to a&quot;</span>
                <span class="s2">&quot;HF model or a `transformers.pipeline` object.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span> <span class="o">=</span> <span class="n">pipeline_kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_prob</span> <span class="o">=</span> <span class="n">min_prob</span>

    <span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">topic_model</span><span class="p">,</span>
        <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
        <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            topic_model: Not used</span>
<span class="sd">            documents: Not used</span>
<span class="sd">            c_tf_idf: Not used</span>
<span class="sd">            topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">        Returns:</span>
<span class="sd">            updated_topics: Updated topic representations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Classify topics</span>
        <span class="n">topic_descriptions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
        <span class="n">classifications</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">topic_descriptions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_topics</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span><span class="p">)</span>

        <span class="c1"># Extract labels</span>
        <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">classification</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">classifications</span><span class="p">):</span>
            <span class="n">topic_description</span> <span class="o">=</span> <span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span>

            <span class="c1"># Multi-label assignment</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;multi_label&quot;</span><span class="p">):</span>
                <span class="n">topic_description</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">classification</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">],</span> <span class="n">classification</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">]):</span>
                    <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prob</span><span class="p">:</span>
                        <span class="n">topic_description</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">label</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

            <span class="c1"># Single label assignment</span>
            <span class="k">elif</span> <span class="n">classification</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prob</span><span class="p">:</span>
                <span class="n">topic_description</span> <span class="o">=</span> <span class="p">[(</span><span class="n">classification</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">classification</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])]</span>

            <span class="c1"># Make sure that 10 items are returned</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">topic_description</span> <span class="o">=</span> <span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
                <span class="n">topic_description</span> <span class="o">+=</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">))]</span>
            <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic_description</span>

        <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="bertopic.representation.ZeroShotClassification.extract_topics" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">extract_topics</span><span class="p">(</span><span class="n">topic_model</span><span class="p">,</span> <span class="n">documents</span><span class="p">,</span> <span class="n">c_tf_idf</span><span class="p">,</span> <span class="n">topics</span><span class="p">)</span></code>

<a href="#bertopic.representation.ZeroShotClassification.extract_topics" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Extract topics.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>topic_model</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>documents</code>
            </td>
            <td>
                  <code><span title="pandas.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>c_tf_idf</code>
            </td>
            <td>
                  <code><span title="scipy.sparse.csr_matrix">csr_matrix</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Not used</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>topics</code>
            </td>
            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The candidate topics as calculated with c-TF-IDF</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>updated_topics</code></td>            <td>
                  <code><span title="typing.Mapping">Mapping</span>[str, <span title="typing.List">List</span>[<span title="typing.Tuple">Tuple</span>[str, float]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Updated topic representations</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>bertopic\representation\_zeroshot.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">extract_topics</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">topic_model</span><span class="p">,</span>
    <span class="n">documents</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">c_tf_idf</span><span class="p">:</span> <span class="n">csr_matrix</span><span class="p">,</span>
    <span class="n">topics</span><span class="p">:</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract topics.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        topic_model: Not used</span>
<span class="sd">        documents: Not used</span>
<span class="sd">        c_tf_idf: Not used</span>
<span class="sd">        topics: The candidate topics as calculated with c-TF-IDF</span>

<span class="sd">    Returns:</span>
<span class="sd">        updated_topics: Updated topic representations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Classify topics</span>
    <span class="n">topic_descriptions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]))[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">topic</span> <span class="ow">in</span> <span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
    <span class="n">classifications</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">topic_descriptions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">candidate_topics</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span><span class="p">)</span>

    <span class="c1"># Extract labels</span>
    <span class="n">updated_topics</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">topic</span><span class="p">,</span> <span class="n">classification</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">topics</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">classifications</span><span class="p">):</span>
        <span class="n">topic_description</span> <span class="o">=</span> <span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span>

        <span class="c1"># Multi-label assignment</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;multi_label&quot;</span><span class="p">):</span>
            <span class="n">topic_description</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">classification</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">],</span> <span class="n">classification</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prob</span><span class="p">:</span>
                    <span class="n">topic_description</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">label</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

        <span class="c1"># Single label assignment</span>
        <span class="k">elif</span> <span class="n">classification</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_prob</span><span class="p">:</span>
            <span class="n">topic_description</span> <span class="o">=</span> <span class="p">[(</span><span class="n">classification</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">classification</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])]</span>

        <span class="c1"># Make sure that 10 items are returned</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">topic_description</span> <span class="o">=</span> <span class="n">topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="n">topic_description</span> <span class="o">+=</span> <span class="p">[(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">topic_description</span><span class="p">))]</span>
        <span class="n">updated_topics</span><span class="p">[</span><span class="n">topic</span><span class="p">]</span> <span class="o">=</span> <span class="n">topic_description</span>

    <span class="k">return</span> <span class="n">updated_topics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 Maintained by <a href="https://github.com/MaartenGr">Maarten Grootendorst</a>.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.sections", "navigation.instant", "navigation.top", "navigation.tracking", "toc.follow", "content.code.copy"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>